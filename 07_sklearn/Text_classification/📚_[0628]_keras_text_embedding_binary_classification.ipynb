{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5231e28-0d05-420b-80b2-94ea0a2ed2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and sequence padding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00f29aa4-f330-419f-aed2-a1e3230f1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network layers (embedding, input, dense, flatten)\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c1cc144-e41d-4a63-85bd-22500d1648b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model construction (functional API, sequential model)\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28ffa964-4ba9-4507-8850-f3132f413e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "217cc704-786b-4139-ab3b-72f318b2f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer initiation\n",
    "tokenizer = Tokenizer()\n",
    "#Preparing training text\n",
    "train_text = \"The earth is an awesome place live\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "933e0ebf-076e-43f0-ae1e-6a562a3786ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building vocab  = analyzes the training text and assigns a unique integer index to each word (creating the word set)\n",
    "tokenizer.fit_on_texts([train_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61e1a2d5-9f1e-4926-86cb-ad54ca26ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing new text for encoding\n",
    "sub_text = \"The earth is an great place live\"\n",
    "sequences = tokenizer.texts_to_sequences([sub_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "023bffbe-ae4b-4a87-b46e-42f17e7729a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The reason for using a similar but slightly different text (for example, replacing \"awesome\" with \"great\") is to demonstrate how the tokenizer handles words that are not present in the learned vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa4c0e49-dd1c-4813-8be8-010201bc01f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integer encoding :  [1, 2, 3, 4, 6, 7]\n",
      "vocab :  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
     ]
    }
   ],
   "source": [
    "#Integer Encoding -> converts the new sentences into a sequence of integers \n",
    "print(\"integer encoding : \",sequences)\n",
    "print(\"vocab : \",tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e3488d2-8031-4d32-8c3a-4aaa008f65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a78cbdc2-37ec-4a54-a1be-658c09f9159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [0, 7, 8]], dtype=int32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], maxlen=3, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59339fe2-24dc-4ed6-911e-a96ed2d9dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embedding/embedding vector\n",
    "#embedding()= embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae22e498-cd4f-4d0a-ae71-55f6f5a2791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization: Split sentences into lists of words (tokens)\n",
    "tokenized_text = [['Hope', 'to', 'see', 'you', 'soon'], ['Nice', 'to', 'see', 'you', 'again']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "027fa966-eab2-4cdb-8118-c6e219aa297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer encoding: Each word is mapped to a unique integer\n",
    "encoded_text = [[0, 1, 2, 3, 4],[5, 1, 2, 3, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8366af4-7ea3-4081-a389-d28757a680d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer input parameters\n",
    "vocab_size = 7        # Total number of unique words (indices 0 to 6)\n",
    "embedding_dim = 2     # Each word will be represented by a 2-dimensional vector\n",
    "\n",
    "\n",
    "#define input layer that expects a sequence of length 5\n",
    "input_seq = Input(shape=(5,))  \n",
    "\n",
    "# Create an embedding layer that maps each integer (word index) to a 2-dimensional dense vector\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=5)(input_seq)\n",
    "\n",
    "#model construction : takes the input sequences and outputs corresponding sequence of embedding vectors\n",
    "model = Model(inputs=input_seq, outputs=embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "446a07a0-9cef-4dba-87b3-0b8fee9efae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[[[ 0.01385099  0.02003599]\n",
      "  [-0.02630205  0.02985834]\n",
      "  [-0.04212302  0.02316945]\n",
      "  [-0.00268266 -0.04340204]\n",
      "  [-0.00978275  0.02498985]]]\n"
     ]
    }
   ],
   "source": [
    "#Prepares a batch (of size 1) containing a single sequence of 5 word indices\n",
    "example = np.array([[0, 1, 2, 3, 4]])\n",
    "\n",
    "#model prediction converts each integer in the input sequence to its corresponding 2-dimensional embedding vector, resulting in a 3D output tensor with shape (1, 5, 2) — one batch, five words, two features per word.\n",
    "output = model.predict(example)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7850e36b-186e-41e8-96e8-9202b2b83bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "167e7d44-65c3-4790-aba0-ac185273fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "#initialize the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#add an embedding layer\n",
    "#input_dim =100 -> The size of the vocabulary \n",
    "#output_dim = 8 -> each word index will be mapped to an 8 dimensional dense vector\n",
    "#input_length =10 -> The input sequences are expected to be of length 10\n",
    "model.add(Embedding(input_dim=100, output_dim=8,input_shape=(10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b940c362-62de-4c03-b782-894fbea81c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the 3D embedding ouput to 10\n",
    "model.add(Flatten())\n",
    "\n",
    "#adds a fully connected (Dense) layer with 32 neurons and ReLU activation.\n",
    "model.add(Dense(32, activation='relu')) # 완전연결층\n",
    "\n",
    "#the output layer with 1 neuron and sigmoid activation, which is commonly used for binary classification tasks\n",
    "model.add(Dense(1, activation='sigmoid')) # 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "49988f91-aef5-403f-af3a-6fcdc2dd551e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,592</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,592\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,425</span> (13.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,425\u001b[0m (13.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,425</span> (13.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,425\u001b[0m (13.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4d6ce-8433-490f-8d90-e82e84ad6c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
