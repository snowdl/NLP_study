{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fbc8af8-98cd-494d-aeab-3bb6fbc8fcc3",
   "metadata": {},
   "source": [
    "This notebook implements a TF-IDF–based tiered inverted index for efficient top-K retrieval, demonstrated on toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9db5851-15c5-449a-a2f5-1d5526d9e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Pipeline Overview (Tiered Index with TF-IDF)\n",
    "# ==================================================\n",
    "# 0) Toy data\n",
    "#    docs = {doc_id: sentence}\n",
    "#\n",
    "# 1) Tokenizer (leveled-up)\n",
    "#    - lowercase\n",
    "#    - regex: extract alphanumeric tokens\n",
    "#    - (optional) remove stopwords\n",
    "#    - (optional) remove tokens of length <= 1\n",
    "#    -> doc_tokens = {doc_id: [term, term, ...]}\n",
    "#\n",
    "# 2) Build basic inverted index\n",
    "#    inv_index[term][doc_id] = tf\n",
    "#    -> term -> {doc_id: tf}\n",
    "#\n",
    "# 3) Compute DF & IDF\n",
    "#    df(term) = number of documents containing term\n",
    "#    idf(term) = log((N + 1) / (df + 1)) + 1   (toy smoothing)\n",
    "#    -> idf[term]\n",
    "#\n",
    "# 4) TF-IDF postings (sorted)\n",
    "#    score = tf * idf(term)\n",
    "#    tfidf_postings[term] = [(doc_id, score), ...] sorted desc\n",
    "#\n",
    "# 5) Split postings into tiers\n",
    "#    Toy:      tier1 top-1 / tier2 next-1 / tier3 rest\n",
    "#    Real-ish: tier1 top-50 / tier2 next-200 / rest\n",
    "#    -> tiered_index[term] = {\"tier1\": [...], \"tier2\": [...], \"tier3\": [...]}\n",
    "#\n",
    "# 6) Tiered search (top-K retrieval)\n",
    "#    - tokenize query\n",
    "#    - accumulate scores using tier1 postings first\n",
    "#    - if not enough candidates, expand to tier2, then tier3\n",
    "#    - return top-K using heapq.nlargest\n",
    "# ==================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c32185-97dc-4c64-863f-8169f307c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import heapq\n",
    "from typing import List\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff13b934-d82a-4e94-9dcb-a051824a82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0. Toy data\n",
    "docs = {\n",
    "    0: \"nlp search search model\",\n",
    "    1: \"search engine ranking\",\n",
    "    2: \"nlp language model\",\n",
    "    3: \"cat dog dog\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a8f645-b9a1-4057-b6cf-97324b836bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP = {\"the\", \"a\", \"an\", \"is\", \"and\", \"or\", \"to\", \"of\", \"in\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7da8707a-29ea-4e95-979c-5ec88a177de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Advanced tokenizer\n",
    "def tokenize(text: str) -> List[str]:\n",
    "\n",
    "    # 1) lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #2)Regex :extract alphanumeric tokens\n",
    "    tokens = re.findall(r\"[a-z0-9]+\", text)\n",
    "\n",
    "    # 3) remove stopwords and short tokens\n",
    "    tokens = [t for t in tokens if t not in STOP and len(t) > 1]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36d786b5-19b2-4585-848f-90169d90aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Apply tokenizer to each document (doc_id -> token list)\n",
    "# - Input:  docs = {doc_id: raw_text}\n",
    "# - Output: doc_tokens = {doc_id: [term1, term2, ...]}\n",
    "doc_tokens = {doc_id: tokenize(sentence) for doc_id, sentence in docs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2fd4794-3039-45b3-9675-0274f1836479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== doc_tokens ===\n",
      "0 : ['nlp', 'search', 'search', 'model']\n",
      "1 : ['search', 'engine', 'ranking']\n",
      "2 : ['nlp', 'language', 'model']\n",
      "3 : ['cat', 'dog', 'dog']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== doc_tokens ===\")\n",
    "for k, v in doc_tokens.items():\n",
    "    print(k, \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ddb8c6e-435f-46bd-9c6f-23efec613a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3.Build basic inverted index\n",
    "# - Input:  doc_tokens = {doc_id: [term, term, ...]}\n",
    "# - Output: inv_index = {term: {doc_id: tf}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80364413-e6d0-48f0-b89c-489f8dc9255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) empty space to store inv_index term → {doc_id: tf}\n",
    "inv_index = defaultdict(dict)\n",
    "\n",
    "# iterate doc_tokens which generated from step2\n",
    "for doc_id, tokens in doc_tokens.items():\n",
    "    tf = Counter(tokens)           # term frequency in this document\n",
    "    for term, freq in tf.items():  # iterate tf and extract term and freq\n",
    "        inv_index[term][doc_id] = freq  # store into inv_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73721875-bc9f-4077-94cb-9bc48abb5e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inverted Index (pretty view) ===\n",
      "Term: 'cat'\n",
      "  doc 3: tf = 1\n",
      "Term: 'dog'\n",
      "  doc 3: tf = 2\n",
      "Term: 'engine'\n",
      "  doc 1: tf = 1\n",
      "Term: 'language'\n",
      "  doc 2: tf = 1\n",
      "Term: 'model'\n",
      "  doc 0: tf = 1\n",
      "  doc 2: tf = 1\n",
      "Term: 'nlp'\n",
      "  doc 0: tf = 1\n",
      "  doc 2: tf = 1\n",
      "Term: 'ranking'\n",
      "  doc 1: tf = 1\n",
      "Term: 'search'\n",
      "  doc 0: tf = 2\n",
      "  doc 1: tf = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Inverted Index (pretty view) ===\")\n",
    "for term in sorted(inv_index.keys()):\n",
    "    print(f\"Term: '{term}'\")\n",
    "    for doc_id, tf in inv_index[term].items():\n",
    "        print(f\"  doc {doc_id}: tf = {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d069be91-1335-4db6-a178-10c0b1bbc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute DF & IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83539d0e-549a-4691-89a8-534a77574d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq_from_inv(inv_index):\n",
    "    \"\"\"\n",
    "    Compute document frequency (DF) from inverted index.\n",
    "    DF(term) = number of documents containing the term.\n",
    "    \"\"\"\n",
    "    return {term: len(postings) for term, postings in inv_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1147e2f7-668c-42ea-8c6f-4b5757826f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Document Frequency (DF) ===\n",
      "cat        -> df = 1\n",
      "dog        -> df = 1\n",
      "engine     -> df = 1\n",
      "language   -> df = 1\n",
      "model      -> df = 2\n",
      "nlp        -> df = 2\n",
      "ranking    -> df = 1\n",
      "search     -> df = 2\n"
     ]
    }
   ],
   "source": [
    "# Compute DF from inverted index\n",
    "df = doc_freq_from_inv(inv_index)\n",
    "\n",
    "print(\"=== Document Frequency (DF) ===\")\n",
    "for term in sorted(df.keys()):\n",
    "    print(f\"{term:10s} -> df = {df[term]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "792dbda3-94f7-4315-ac10-bacbade21b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = doc_freq_from_inv(inv_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c0c59c5-0555-4ee1-a48c-c26326dd8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute IDF with add-one smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b30f104-51bf-47b1-b60c-05259ef6a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Compute IDF with add-one smoothing\n",
    "# idf(term) = log((N + 1) / (df + 1)) + 1\n",
    "def compute_idf(df, N):\n",
    "    \"\"\"\n",
    "    Compute IDF values from document frequency.\n",
    "    N: total number of documents\n",
    "    \"\"\"\n",
    "    return {\n",
    "        term: math.log((N + 1) / (df_t + 1)) + 1.0\n",
    "        for term, df_t in df.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4532c69-55cd-415a-8f88-84e677dfb870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IDF values ===\n",
      "cat        -> idf = 1.9163\n",
      "dog        -> idf = 1.9163\n",
      "engine     -> idf = 1.9163\n",
      "language   -> idf = 1.9163\n",
      "model      -> idf = 1.5108\n",
      "nlp        -> idf = 1.5108\n",
      "ranking    -> idf = 1.9163\n",
      "search     -> idf = 1.5108\n"
     ]
    }
   ],
   "source": [
    "# total number of documents\n",
    "N = len(doc_tokens)\n",
    "\n",
    "# compute DF from inverted index\n",
    "df = doc_freq_from_inv(inv_index)\n",
    "\n",
    "# compute IDF\n",
    "idf = compute_idf(df, N)\n",
    "\n",
    "print(\"=== IDF values ===\")\n",
    "for term in sorted(idf.keys()):\n",
    "    print(f\"{term:10s} -> idf = {idf[term]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28b3e80f-fd93-48fa-82b8-008071c2b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. Build TF-IDF postings (term -> [(doc_id, score)])\n",
    "# - Input:  inv_index (term -> {doc_id: tf}), idf (term -> idf)\n",
    "# - Output: tfidf_postings (term -> [(doc_id, tf-idf), ...]) sorted desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0819dd1e-334e-4716-8a91-798e1d07219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_postings ={}\n",
    "for term, postings in inv_index.items():\n",
    "    list=[]\n",
    "    for doc_id,tf in postings.items():\n",
    "        score = tf * idf[term]\n",
    "        list.append((doc_id, score))\n",
    "\n",
    "    #sort by descending order\n",
    "    list.sort(key=lambda x: (-x[1], x[0]))\n",
    "    tfidf_postings[term] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "875da3c0-f14a-4f6d-a199-d31ee8a9f444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF Postings (term -> [(doc_id, score)]) ===\n",
      "cat        -> [(3, 1.9163)]\n",
      "dog        -> [(3, 3.8326)]\n",
      "engine     -> [(1, 1.9163)]\n",
      "language   -> [(2, 1.9163)]\n",
      "model      -> [(0, 1.5108), (2, 1.5108)]\n",
      "nlp        -> [(0, 1.5108), (2, 1.5108)]\n",
      "ranking    -> [(1, 1.9163)]\n",
      "search     -> [(0, 3.0217), (1, 1.5108)]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TF-IDF Postings (term -> [(doc_id, score)]) ===\")\n",
    "for term in sorted(tfidf_postings.keys()):\n",
    "    scores = [(d, round(s, 4)) for d, s in tfidf_postings[term]]\n",
    "    print(f\"{term:10s} -> {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e60396f7-0c8b-4716-9713-9d72329a369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tiered Index (term -> tier1/tier2/tier3) ===\n",
      "cat        -> {'tier1': [(3, 1.916290731874155)], 'tier2': [], 'tier3': []}\n",
      "dog        -> {'tier1': [(3, 3.83258146374831)], 'tier2': [], 'tier3': []}\n",
      "engine     -> {'tier1': [(1, 1.916290731874155)], 'tier2': [], 'tier3': []}\n",
      "language   -> {'tier1': [(2, 1.916290731874155)], 'tier2': [], 'tier3': []}\n",
      "model      -> {'tier1': [(0, 1.5108256237659907)], 'tier2': [(2, 1.5108256237659907)], 'tier3': []}\n",
      "nlp        -> {'tier1': [(0, 1.5108256237659907)], 'tier2': [(2, 1.5108256237659907)], 'tier3': []}\n",
      "ranking    -> {'tier1': [(1, 1.916290731874155)], 'tier2': [], 'tier3': []}\n",
      "search     -> {'tier1': [(0, 3.0216512475319814)], 'tier2': [(1, 1.5108256237659907)], 'tier3': []}\n"
     ]
    }
   ],
   "source": [
    "# Step 6. Split postings into tiers (toy rule: 1 / 1 / rest)\n",
    "def split_tiers(sorted_postings, t1=1, t2=1):\n",
    "    tier1 = sorted_postings[:t1]\n",
    "    tier2 = sorted_postings[t1:t1+t2]\n",
    "    tier3 = sorted_postings[t1+t2:]\n",
    "    return {\"tier1\": tier1, \"tier2\": tier2, \"tier3\": tier3}\n",
    "\n",
    "tiered_index = {\n",
    "    term: split_tiers(postings, t1=1, t2=1)\n",
    "    for term, postings in tfidf_postings.items()\n",
    "}\n",
    "\n",
    "# Print tiered index\n",
    "print(\"=== Tiered Index (term -> tier1/tier2/tier3) ===\")\n",
    "for term in sorted(tiered_index.keys()):\n",
    "    print(f\"{term:10s} -> {tiered_index[term]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c301f8e-1c37-44d3-864e-08f858a328c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tiered Index (docs only) ===\n",
      "cat        -> {'tier1': [3], 'tier2': [], 'tier3': []}\n",
      "dog        -> {'tier1': [3], 'tier2': [], 'tier3': []}\n",
      "engine     -> {'tier1': [1], 'tier2': [], 'tier3': []}\n",
      "language   -> {'tier1': [2], 'tier2': [], 'tier3': []}\n",
      "model      -> {'tier1': [0], 'tier2': [2], 'tier3': []}\n",
      "nlp        -> {'tier1': [0], 'tier2': [2], 'tier3': []}\n",
      "ranking    -> {'tier1': [1], 'tier2': [], 'tier3': []}\n",
      "search     -> {'tier1': [0], 'tier2': [1], 'tier3': []}\n"
     ]
    }
   ],
   "source": [
    "tiered_docs_only = {\n",
    "    term: {\n",
    "        \"tier1\": [d for d, s in tiers[\"tier1\"]],\n",
    "        \"tier2\": [d for d, s in tiers[\"tier2\"]],\n",
    "        \"tier3\": [d for d, s in tiers[\"tier3\"]],\n",
    "    }\n",
    "    for term, tiers in tiered_index.items()\n",
    "}\n",
    "\n",
    "print(\"=== Tiered Index (docs only) ===\")\n",
    "for term in sorted(tiered_docs_only.keys()):\n",
    "    print(f\"{term:10s} -> {tiered_docs_only[term]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49a12545-8e22-4e8f-a20a-95ffc92e1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7. Tiered search (tier1 -> tier2 -> tier3), with edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fad908e4-24e5-467d-857d-199e8480df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate document scores from the specified tier and return the number of postings processed.\n",
    "def accumulate_scores_from_tier(q_terms, tiered_index, tier_name, scores):\n",
    "    \"\"\"\n",
    "    Accumulate scores into `scores` using postings from a specified tier.\n",
    "    Returns the number of postings processed.\n",
    "    \"\"\"\n",
    "    num_postings = 0\n",
    "    for t in q_terms:\n",
    "        postings_by_tier = tiered_index.get(t)\n",
    "        if postings_by_tier is None:   # OOV term\n",
    "            continue\n",
    "        for doc_id, score in postings_by_tier[tier_name]:\n",
    "            scores[doc_id] += score\n",
    "            num_postings += 1\n",
    "    return num_postings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bfe24e3-cd4f-48ad-8c2d-19b927be317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tiered(query: str, K: int, tiered_index, *, verbose: bool=False):\n",
    "\n",
    "    #handle edge cases such as empty queries and non-positive K \n",
    "    if K <= 0:\n",
    "        return []\n",
    "    if query is None or query.strip() == \"\":\n",
    "        return []\n",
    "        \n",
    "    # Step 1. Tokenize / transform the query into the same term format\n",
    "    # used for documents (for consistent matching).\n",
    "    q_terms = tokenize(query)\n",
    "    if not q_terms:\n",
    "        return []\n",
    "    #Step 2.Accumulate relevance scores per document\n",
    "    scores = defaultdict(float)\n",
    "\n",
    "    # Process tier1 postings (most important candidates first)\n",
    "    a1 = accumulate_scores_from_tier(q_terms, tiered_index, \"tier1\", scores)\n",
    "    if verbose:\n",
    "        print(\"tier1 postings processed:\", a1, \"unique docs:\", len(scores))\n",
    "\n",
    "    #Expand to tier2 only if we still have fewer than K candidates\n",
    "    if len(scores) < K:\n",
    "        a2 = accumulate_scores_from_tier(q_terms, tiered_index, \"tier2\", scores)\n",
    "        if verbose:\n",
    "            print(\"tier2 postings processed:\", a2, \"unique docs:\", len(scores))\n",
    "\n",
    "    #Expand to tier3 only if the candidate set is still insufficient\n",
    "    if len(scores) < K:\n",
    "        a3 = accumulate_scores_from_tier(q_terms, tiered_index, \"tier3\", scores)\n",
    "        if verbose:\n",
    "            print(\"tier3 postings processed:\", a3, \"unique docs:\", len(scores))\n",
    "\n",
    "    ## return top-K documents ranked by accumulated TF-IDF scores\n",
    "    return heapq.nlargest(K, scores.items(), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4b6ab85-5db9-485e-b825-2eea42c68f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1) query='search', K=5\n",
      "tier1 postings processed: 1 unique docs: 1\n",
      "tier2 postings processed: 1 unique docs: 2\n",
      "tier3 postings processed: 0 unique docs: 2\n",
      "-> top results: [(0, 3.0216512475319814), (1, 1.5108256237659907)]\n",
      "\n",
      "Q2) query='nlp search', K=5\n",
      "tier1 postings processed: 2 unique docs: 1\n",
      "tier2 postings processed: 2 unique docs: 3\n",
      "tier3 postings processed: 0 unique docs: 3\n",
      "-> top results: [(0, 4.532476871297972), (2, 1.5108256237659907), (1, 1.5108256237659907)]\n",
      "\n",
      "Q3) OOV-only query='zzzz', K=5 (should be [])\n",
      "tier1 postings processed: 0 unique docs: 0\n",
      "tier2 postings processed: 0 unique docs: 0\n",
      "tier3 postings processed: 0 unique docs: 0\n",
      "-> []\n",
      "\n",
      "Q4) empty query='   ', K=5 (should be [])\n",
      "-> []\n",
      "\n",
      "Q5) K=0 (should be [])\n",
      "-> []\n",
      "\n",
      "Q6) Show doc texts for top results of 'nlp search'\n",
      "doc 0 | score=4.5325 | text='nlp search search model'\n",
      "doc 2 | score=1.5108 | text='nlp language model'\n",
      "doc 1 | score=1.5108 | text='search engine ranking'\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Quick sanity run / demo\n",
    "# ============================\n",
    "\n",
    "# 1) Basic queries\n",
    "print(\"Q1) query='search', K=5\")\n",
    "res = search_tiered(\"search\", 5, tiered_index, verbose=True)\n",
    "print(\"-> top results:\", res)\n",
    "print()\n",
    "\n",
    "print(\"Q2) query='nlp search', K=5\")\n",
    "res = search_tiered(\"nlp search\", 5, tiered_index, verbose=True)\n",
    "print(\"-> top results:\", res)\n",
    "print()\n",
    "\n",
    "# 2) Edge cases\n",
    "print(\"Q3) OOV-only query='zzzz', K=5 (should be [])\")\n",
    "print(\"->\", search_tiered(\"zzzz\", 5, tiered_index, verbose=True))\n",
    "print()\n",
    "\n",
    "print(\"Q4) empty query='   ', K=5 (should be [])\")\n",
    "print(\"->\", search_tiered(\"   \", 5, tiered_index, verbose=True))\n",
    "print()\n",
    "\n",
    "print(\"Q5) K=0 (should be [])\")\n",
    "print(\"->\", search_tiered(\"search\", 0, tiered_index, verbose=True))\n",
    "print()\n",
    "\n",
    "# 3) Optional: show doc text (if you still have `docs` dict)\n",
    "print(\"Q6) Show doc texts for top results of 'nlp search'\")\n",
    "res = search_tiered(\"nlp search\", 3, tiered_index)\n",
    "for doc_id, score in res:\n",
    "    print(f\"doc {doc_id} | score={score:.4f} | text='{docs[doc_id]}'\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9145fbbc-2949-4bee-8a17-b22dbbfa4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed ✅\n"
     ]
    }
   ],
   "source": [
    "# Minimal tests (toy data)\n",
    "# 1) Empty query\n",
    "assert search_tiered(\"\", 3, tiered_index) == []\n",
    "assert search_tiered(\"   \", 3, tiered_index) == []\n",
    "\n",
    "# 2) K <= 0\n",
    "assert search_tiered(\"nlp\", 0, tiered_index) == []\n",
    "\n",
    "# 3) OOV-only query\n",
    "assert search_tiered(\"zzzz\", 3, tiered_index) == []\n",
    "\n",
    "# 4) Known query should return something and include expected doc\n",
    "res = search_tiered(\"search\", 2, tiered_index)\n",
    "assert len(res) == 2\n",
    "assert res[0][0] == 0   # doc 0 should rank above doc 1 for \"search\" (tf=2 vs tf=1)\n",
    "\n",
    "# 5) Multi-term query should include doc 0 (nlp+search appears strongly in doc 0)\n",
    "res2 = search_tiered(\"nlp search\", 2, tiered_index)\n",
    "assert len(res2) == 2\n",
    "assert any(doc_id == 0 for doc_id, _ in res2)\n",
    "\n",
    "print(\"All tests passed ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50dd522-6237-4313-b953-ed78cf30d0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
