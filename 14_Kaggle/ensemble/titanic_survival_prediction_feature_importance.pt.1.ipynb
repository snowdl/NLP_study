{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cdf6ec6f-46ed-4f7b-804c-384a103be91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccf1fcfb-8703-4d8e-a276-af2ba21ff289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e4a05584-70e9-4eb6-ad95-8c1fd83ca276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports stackingclasifier for combining multiple models into an ensemble\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00601e0d-8eb8-4dc9-85dc-4513f4d3f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../12_data/titanic/train.csv')\n",
    "test = pd.read_csv('../../12_data/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7203d52-07c2-4e3a-9649-5e68baaf6b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "762362e2-019a-4f89-8f17-1de29ac9901a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a31c1b6-d1db-4da5-83a0-68998a560146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts the target variables (survived) from the training set and store it in y\n",
    "y = train['Survived']\n",
    "\n",
    "#Drops survived(target)and passenserId(idenfier) from training data and stores the remaining features in X\n",
    "# Drop survived in X because X should only contain inut features not the answers.\n",
    "# including survied in X would be like giving the model the correct answer in advance = lead to data leakage and invalid training\n",
    "X = train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "X_test = test.drop(['PassengerId'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc4ee1be-62ea-4488-8815-db6f5e9d9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2eaeb531-cfc6-404f-a6a1-70df1e0b96c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. improve model performance :Properly handling missing values and transforming key features (like sex and family size) allows the model to learn data patterns better, resulting in higher prediction accuracy.\\n2. Consistent Data processing : Applying the exact same preprocessing logic to both training and test data reduces errors and biases caused by differences in data handling.\\n3. Code Reusability and Maintainability L\\\\:Modularizing preprocessing steps into functions allows to reuse code easily and update methods in one place, making maintenance much simpler.\\n4. Easy Experimentation and Comparison : can quickly test various combinations and systematically evaluate which works best.\\n'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing functions - use multiple functions, because i aim to achieve\n",
    "\"\"\"\n",
    "1. improve model performance :Properly handling missing values and transforming key features (like sex and family size) allows the model to learn data patterns better, resulting in higher prediction accuracy.\n",
    "2. Consistent Data processing : Applying the exact same preprocessing logic to both training and test data reduces errors and biases caused by differences in data handling.\n",
    "3. Code Reusability and Maintainability L\\:Modularizing preprocessing steps into functions allows to reuse code easily and update methods in one place, making maintenance much simpler.\n",
    "4. Easy Experimentation and Comparison : can quickly test various combinations and systematically evaluate which works best.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e3f99950-6d47-4c62-9632-75dae2e8637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_age(df, strategy='median'):\n",
    "    \"\"\"\n",
    "    Fill missing values in the 'Age' column of the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe with 'Age' column\n",
    "        strategy (str): Method to fill missing values. Options:\n",
    "                        - 'median': fill with median age (default)\n",
    "                        - 'mean': fill with mean age\n",
    "                        - 'zero': fill with 0\n",
    "                        - 'random': fill with random sampled ages from existing data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing 'Age' values filled.\n",
    "    \"\"\"\n",
    "    \n",
    "    if strategy == 'median':\n",
    "        fill_value = df['Age'].median()\n",
    "        df['Age'] = df['Age'].fillna(fill_value)\n",
    "    elif strategy == 'mean':\n",
    "        fill_value = df['Age'].mean()\n",
    "        df['Age'] = df['Age'].fillna(fill_value)\n",
    "    elif strategy == 'zero':\n",
    "        df['Age'] = df['Age'].fillna(0)\n",
    "    elif strategy == 'random':\n",
    "        # Randomly sample ages from non-missing age values for imputing\n",
    "        ages = df['Age'].dropna()\n",
    "        df['Age'] = df['Age'].apply(lambda x: np.random.choice(ages) if pd.isnull(x) else x)\n",
    "    else:\n",
    "        raise ValueError(\"Strategy not recognized. Choose from 'median', 'mean', 'zero', 'random'.\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f6baecb0-99c5-4d22-af54-bc3eed17003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "74b33381-a05e-45b9-9e8f-17c875871d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../12_data/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b310a382-b2d5-43ce-b399-672984c10435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61e6a621-f8ec-4654-91fb-24a81ea9014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fill_age:\n",
      "177\n"
     ]
    }
   ],
   "source": [
    "# Check number of missing values in 'Age' before filling\n",
    "print(\"Before fill_age:\")\n",
    "print(train['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4153cb0-5a33-44e3-8e96-89711e21ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fill_age function with median strategy\n",
    "#Creates a copy of the train dataframe and applies the fill_age function on it= preserves the original train dataframe unchanged and stores the filled dataframe in train_filled.\n",
    "train_filled = fill_age(train.copy(), strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "572c800c-f1f0-4e39-a211-77feeb0da47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fill_age:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check number of missing values in 'Age' after filling\n",
    "print(\"\\nAfter fill_age:\")\n",
    "print(train_filled['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25df1593-c1cf-409c-a943-e4fb1af7725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age\n",
      "0  22.0\n",
      "1  38.0\n",
      "2  26.0\n",
      "3  35.0\n",
      "4  35.0\n"
     ]
    }
   ],
   "source": [
    "# Show top 5 samples of 'Age' column\n",
    "print(train_filled[['Age']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7f133fff-2e63-4950-8b53-5f67b05f0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sex(df):\n",
    "    \"\"\"\n",
    "    Convert 'Sex' from categorical string to numeric encoding.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'Sex' column\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: New DataFrame with 'Sex' column encoded as 0 (male), 1 (female).\n",
    "    \"\"\"\n",
    "    # 복사본 생성 (원본 보존)\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Sex'] = df_copy['Sex'].map({'male': 0, 'female': 1})\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e8ad0b66-4e77-4de3-bd95-f8113177949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encode_sex:\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of 'Sex' column before running encode_sex\n",
    "print(\"Before encode_sex:\")\n",
    "print(train['Sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e717dae3-81bd-419c-954e-9bed2bd3e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encode_sex:\n",
      "Sex\n",
      "male      3\n",
      "female    2\n",
      "Name: count, dtype: int64\n",
      "0      male\n",
      "1    female\n",
      "2    female\n",
      "3      male\n",
      "4      male\n",
      "Name: Sex, dtype: object\n",
      "\n",
      "[Inside encode_sex] Before mapping:\n",
      "0      male\n",
      "1    female\n",
      "2    female\n",
      "3      male\n",
      "4      male\n",
      "Name: Sex, dtype: object\n",
      "\n",
      "[Inside encode_sex] After mapping:\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "After encode_sex:\n",
      "Sex\n",
      "0    3\n",
      "1    2\n",
      "Name: count, dtype: int64\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "Original train data after encoding function call:\n",
      "0      male\n",
      "1    female\n",
      "2    female\n",
      "3      male\n",
      "4      male\n",
      "Name: Sex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame({'Sex': ['male', 'female', 'female', 'male', 'male']})\n",
    "\n",
    "print(\"Before encode_sex:\")\n",
    "print(train['Sex'].value_counts())\n",
    "print(train['Sex'].head())\n",
    "\n",
    "def encode_sex(df):\n",
    "    df_copy = df.copy()\n",
    "    print(\"\\n[Inside encode_sex] Before mapping:\")\n",
    "    print(df_copy['Sex'].head())\n",
    "    df_copy['Sex'] = df_copy['Sex'].map({'male': 0, 'female': 1})\n",
    "    print(\"\\n[Inside encode_sex] After mapping:\")\n",
    "    print(df_copy['Sex'].head())\n",
    "    return df_copy\n",
    "\n",
    "train_encoded = encode_sex(train.copy())\n",
    "\n",
    "print(\"\\nAfter encode_sex:\")\n",
    "print(train_encoded['Sex'].value_counts())\n",
    "print(train_encoded['Sex'].head())\n",
    "\n",
    "print(\"\\nOriginal train data after encoding function call:\")\n",
    "print(train['Sex'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5bc54e55-6a8d-450a-b556-4d6a99f33183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_embarked(train_df, test_df):\n",
    "    \"\"\"\n",
    "    One-hot encode 'Embarked' column in both train and test datasets,\n",
    "    ensuring the same columns and encoding scheme for both.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training data\n",
    "        test_df (pd.DataFrame): Test data\n",
    "\n",
    "    Returns:\n",
    "        train_df_encoded, test_df_encoded (pd.DataFrame): DataFrames with one-hot encoded 'Embarked' columns\n",
    "\n",
    "    Note:\n",
    "        One-hot encoding transforms categorical variables into binary vectors.\n",
    "        For example, if 'Embarked' has categories C, Q, S,\n",
    "        one-hot encoding will create three new columns: Embarked_C, Embarked_Q, Embarked_S,\n",
    "        where each column indicates presence (1) or absence (0) of the category.\n",
    "        This helps machine learning models treat categories as independent features,\n",
    "        avoiding unintended ordinal relationships.\n",
    "    \"\"\"\n",
    "    # Initialize OneHotEncoder to ignore unknown categories and output dense array\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    \n",
    "    # Extract 'Embarked' column from train and test data\n",
    "    embarked_train = train_df[['Embarked']]\n",
    "    embarked_test = test_df[['Embarked']]\n",
    "\n",
    "    # Fit the encoder on training 'Embarked' data\n",
    "    encoder.fit(embarked_train)\n",
    "    \n",
    "    # Transform both train and test 'Embarked' data into one-hot encoded arrays\n",
    "    train_encoded = encoder.transform(embarked_train)\n",
    "    test_encoded = encoder.transform(embarked_test)\n",
    "\n",
    "    # Get the generated one-hot encoded column names\n",
    "    cols = encoder.get_feature_names_out(['Embarked'])\n",
    "\n",
    "    # Convert the one-hot encoded arrays to DataFrames with appropriate column names and indices\n",
    "    train_encoded_df = pd.DataFrame(train_encoded, columns=cols, index=train_df.index)\n",
    "    test_encoded_df = pd.DataFrame(test_encoded, columns=cols, index=test_df.index)\n",
    "\n",
    "    # Drop original 'Embarked' column from train and test DataFrames\n",
    "    train_df = train_df.drop('Embarked', axis=1).join(train_encoded_df)\n",
    "    test_df = test_df.drop('Embarked', axis=1).join(test_encoded_df)\n",
    "\n",
    "    # Return modified train and test DataFrames with one-hot encoded 'Embarked' columns\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "def2f7db-5b37-4db3-80ba-034f52be7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data:\n",
      "   PassengerId Embarked  Age\n",
      "0            1        S   22\n",
      "1            2        C   38\n",
      "2            3        Q   26\n",
      "3            4        S   35\n"
     ]
    }
   ],
   "source": [
    "# Example data for train and test with 'Embarked' column\n",
    "train_sample = pd.DataFrame({\n",
    "    'PassengerId': [1, 2, 3, 4],\n",
    "    'Embarked': ['S', 'C', 'Q', 'S'],\n",
    "    'Age': [22, 38, 26, 35]\n",
    "})\n",
    "\n",
    "test_sample = pd.DataFrame({\n",
    "    'PassengerId': [5, 6, 7],\n",
    "    'Embarked': ['Q', 'S', 'C'],\n",
    "    'Age': [28, 19, 40]\n",
    "})\n",
    "\n",
    "print(\"Original train data:\")\n",
    "print(train_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "20486fb1-1fc1-4bda-8d99-dffe012a16b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original test data:\n",
      "   PassengerId Embarked  Age\n",
      "0            5        Q   28\n",
      "1            6        S   19\n",
      "2            7        C   40\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal test data:\")\n",
    "print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ca728f12-5a49-4d70-bb12-f5782d9ecefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data columns after one-hot encoding 'Embarked':\n",
      "Index(['PassengerId', 'Age', 'Embarked_C', 'Embarked_Q', 'Embarked_S'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Assuming encode_embarked function is already defined as before\n",
    "train_encoded, test_encoded = encode_embarked(train_sample, test_sample)\n",
    "\n",
    "# Check the columns of train data after encoding\n",
    "print(\"\\nTrain data columns after one-hot encoding 'Embarked':\")\n",
    "print(train_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "160775fe-9be1-4538-af03-96d3bba39eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data after encoding:\n",
      "   PassengerId  Age  Embarked_C  Embarked_Q  Embarked_S\n",
      "0            1   22         0.0         0.0         1.0\n",
      "1            2   38         1.0         0.0         0.0\n",
      "2            3   26         0.0         1.0         0.0\n",
      "3            4   35         0.0         0.0         1.0\n"
     ]
    }
   ],
   "source": [
    "# Display the train data after encoding\n",
    "print(\"\\nTrain data after encoding:\")\n",
    "print(train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "25627516-fec2-4966-a45b-13708f161cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data columns after one-hot encoding 'Embarked':\n",
      "Index(['PassengerId', 'Age', 'Embarked_C', 'Embarked_Q', 'Embarked_S'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the columns of test data after encoding\n",
    "print(\"\\nTest data columns after one-hot encoding 'Embarked':\")\n",
    "print(test_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7fa122a0-aa0b-4465-ab8f-05c008878c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data after encoding:\n",
      "   PassengerId  Age  Embarked_C  Embarked_Q  Embarked_S\n",
      "0            5   28         0.0         1.0         0.0\n",
      "1            6   19         0.0         0.0         1.0\n",
      "2            7   40         1.0         0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# Display the test data after encoding\n",
    "print(\"\\nTest data after encoding:\")\n",
    "print(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e10592af-f187-4d17-a8fc-70b7068a1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_family_features(df):\n",
    "    \"\"\"\n",
    "    Create family-related features:\n",
    "    - 'FamilySize': number of family members aboard (including self)\n",
    "    - 'IsAlone': whether passenger was alone (1 if alone, else 0)\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with new family features\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Calculate family size by summing siblings/spouses and parents/children aboard plus self\n",
    "    df_copy['FamilySize'] = df_copy['SibSp'] + df_copy['Parch'] + 1\n",
    "\n",
    "    # Create 'IsAlone' feature: 1 if family size is 1 (alone), otherwise 0\n",
    "    df_copy['IsAlone'] = (df_copy['FamilySize'] == 1).astype(int)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "08118c20-c3eb-4df3-9d11-d1ea754a7938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample data:\n",
      "   SibSp  Parch\n",
      "0      0      0\n",
      "1      1      0\n",
      "2      0      2\n",
      "3      2      1\n"
     ]
    }
   ],
   "source": [
    "# Sample data to test create_family_features function\n",
    "sample_data = pd.DataFrame({\n",
    "    'SibSp': [0, 1, 0, 2],\n",
    "    'Parch': [0, 0, 2, 1]\n",
    "})\n",
    "\n",
    "print(\"Original sample data:\")\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f603e36f-5ce0-4d0b-bba5-e8e2565b1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after creating family features:\n",
      "   SibSp  Parch  FamilySize  IsAlone\n",
      "0      0      0           1        1\n",
      "1      1      0           2        0\n",
      "2      0      2           3        0\n",
      "3      2      1           4        0\n"
     ]
    }
   ],
   "source": [
    "# Apply the function\n",
    "sample_with_family = create_family_features(sample_data)\n",
    "\n",
    "print(\"\\nData after creating family features:\")\n",
    "print(sample_with_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ab53eb62-875e-4ec3-b46f-cf1c949e9c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'FamilySize': [1 2 3 4]\n",
      "Unique values in 'IsAlone': [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in 'FamilySize' and 'IsAlone'\n",
    "print(\"\\nUnique values in 'FamilySize':\", sample_with_family['FamilySize'].unique())\n",
    "print(\"Unique values in 'IsAlone':\", sample_with_family['IsAlone'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ddd7158-5ddd-424f-b8a8-88851e2b33ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SibSp  Parch  FamilySize  IsAlone\n",
      "0      0      0           1        1\n"
     ]
    }
   ],
   "source": [
    "alone_passengers = sample_with_family[sample_with_family['IsAlone'] == 1]\n",
    "print(alone_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "258f0207-cac6-4424-84fe-e196783854e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Name  FamilySize  IsAlone\n",
      "0          101  John           1        1\n"
     ]
    }
   ],
   "source": [
    "# Assuming original data includes 'PassengerId' and 'Name' columns\n",
    "sample_data = pd.DataFrame({\n",
    "    'PassengerId': [101, 102, 103, 104],\n",
    "    'Name': ['John', 'Anna', 'Mike', 'Sara'],\n",
    "    'SibSp': [0, 1, 0, 2],\n",
    "    'Parch': [0, 0, 2, 1]\n",
    "})\n",
    "\n",
    "# Create family features while preserving all original columns and index\n",
    "sample_with_family = create_family_features(sample_data)\n",
    "\n",
    "# Filter passengers who are alone (IsAlone == 1)\n",
    "alone_passengers = sample_with_family[sample_with_family['IsAlone'] == 1]\n",
    "\n",
    "# Display selected columns to identify who is alone\n",
    "print(alone_passengers[['PassengerId', 'Name', 'FamilySize', 'IsAlone']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0d17005f-a7ed-4d8a-b279-1acbbca959ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_embarked_onehot(df):\n",
    "    # One-hot encode the 'Embarked' categorical variable\n",
    "    # This avoids imposing any ordinal relationship and helps the model interpret each port equally.\n",
    "    return pd.get_dummies(df, columns=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a770c3cb-1e3b-443d-a447-3f7259604cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df, cols):\n",
    "    # Drop columns that are either unstructured, have many missing values,\n",
    "    # or are not directly useful without further feature engineering.\n",
    "    # For Titanic dataset, 'Name', 'Ticket', 'Cabin' are dropped for simplicity.\n",
    "    return df.drop(cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2dd50d55-169f-44c1-83a2-7f2d389853a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Inside encode_sex] Before mapping:\n",
      "0      male\n",
      "1    female\n",
      "2    female\n",
      "3    female\n",
      "4      male\n",
      "Name: Sex, dtype: object\n",
      "\n",
      "[Inside encode_sex] After mapping:\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "[Inside encode_sex] Before mapping:\n",
      "0      male\n",
      "1    female\n",
      "2      male\n",
      "3      male\n",
      "4    female\n",
      "Name: Sex, dtype: object\n",
      "\n",
      "[Inside encode_sex] After mapping:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: Sex, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_3901/61765182.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna(df['Embarked'].mode()[0] if strategy == 'mode' else 'Missing', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing functions to train and test sets\n",
    "\n",
    "# Fill missing 'Age' values using the median strategy\n",
    "X_train = fill_age(X_train, strategy='median')\n",
    "X_test = fill_age(X_test, strategy='median')\n",
    "\n",
    "# Convert 'Sex' column to numeric values (e.g., male: 0, female: 1)\n",
    "X_train = encode_sex(X_train)\n",
    "X_test = encode_sex(X_test)\n",
    "\n",
    "# Fill missing 'Embarked' values using the most frequent value (mode)\n",
    "X_train = fill_embarked(X_train, strategy='mode')\n",
    "X_test = fill_embarked(X_test, strategy='mode')\n",
    "\n",
    "# Create new 'FamilySize' and 'IsAlone' features based on 'SibSp' and 'Parch'\n",
    "X_train = create_family_size(X_train)\n",
    "X_test = create_family_size(X_test)\n",
    "\n",
    "# One-hot encode the 'Embarked' column (e.g., C, Q, S)\n",
    "X_train = encode_embarked_onehot(X_train)\n",
    "X_test = encode_embarked_onehot(X_test)\n",
    "\n",
    "# Drop columns that are not useful for modeling\n",
    "columns_to_drop = ['Name', 'Ticket', 'Cabin']\n",
    "X_train = drop_columns(X_train, columns_to_drop)\n",
    "X_test = drop_columns(X_test, columns_to_drop)\n",
    "\n",
    "# Align the columns of X_test to match X_train, filling any missing columns with 0\n",
    "# This ensures consistency in features between train and test sets,\n",
    "# especially after one-hot encoding where some categories may be missing in X_test\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b30471de-c3a0-4d1b-9b38-4c4047e1968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "78a38ed0-5e45-435b-af0f-98d5392b7bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9789325842696629\n",
      "Validation Accuracy: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data into training and validation sets (if needed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set and evaluate accuracy\n",
    "train_preds = model.predict(X_train)\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, train_preds))\n",
    "\n",
    "# Predict on the validation set and evaluate accuracy\n",
    "val_preds = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
    "\n",
    "# Predict on the test set\n",
    "test_preds = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6a39a3a3-b766-4c14-acd9-0db4214d1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"overfitting issue\" = overcome with  cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "37683dab-00f6-4824-84f2-c4f3d3304e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy: 0.7865359992120555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation Accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8adacb66-121d-4b2d-ad8e-968b32044a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCurrent situation : \\nTraining Accuracy: 0.979\\n→ The model fits the training data almost perfectly.\\n\\nCross-validation Accuracy: 0.805\\n→ This reflects the actual performance, indicating low generalization ability.\\n\\nOverfitting issue:\\nThe model is overly focused on the training data and has essentially memorized patterns rather than learning generalizable rules.\\nAs a result, it may perform poorly when predicting on new, unseen data (e.g., the test set).\\n\\nRecommendations to address overfitting:\\n- Perform hyperparameter tuning, such as limiting tree depth (max_depth), increasing minimum samples per leaf (min_samples_leaf), or reducing the number of features considered (max_features).\\n- Use cross-validation more extensively or with more folds to get a reliable estimate of model performance.\\n- Consider feature engineering: remove irrelevant features or create meaningful new features.\\n- Try alternative models like Gradient Boosting, XGBoost, or LightGBM that often generalize better.\\n- If possible, gather more training data or apply data augmentation techniques.\\n- Apply regularization techniques or early stopping if supported by the chosen model.\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Current situation : \n",
    "Training Accuracy: 0.979\n",
    "→ The model fits the training data almost perfectly.\n",
    "\n",
    "Cross-validation Accuracy: 0.805\n",
    "→ This reflects the actual performance, indicating low generalization ability.\n",
    "\n",
    "Overfitting issue:\n",
    "The model is overly focused on the training data and has essentially memorized patterns rather than learning generalizable rules.\n",
    "As a result, it may perform poorly when predicting on new, unseen data (e.g., the test set).\n",
    "\n",
    "Recommendations to address overfitting:\n",
    "- Perform hyperparameter tuning, such as limiting tree depth (max_depth), increasing minimum samples per leaf (min_samples_leaf), or reducing the number of features considered (max_features).\n",
    "- Use cross-validation more extensively or with more folds to get a reliable estimate of model performance.\n",
    "- Consider feature engineering: remove irrelevant features or create meaningful new features.\n",
    "- Try alternative models like Gradient Boosting, XGBoost, or LightGBM that often generalize better.\n",
    "- If possible, gather more training data or apply data augmentation techniques.\n",
    "- Apply regularization techniques or early stopping if supported by the chosen model.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21013cc-cf95-4092-ad8f-42b58dfb7203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57a0e2-5ed3-4e60-861d-fc6ed466b053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
