{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695c2afd-7594-442e-86e3-dd377555e02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicahong/.pyenv/versions/bpd_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0572542-0fc1-4c8b-a10f-97c6490825d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d47a76-546f-40cc-a3c7-863d17e2fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토크나이저와 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1098fac-f15a-4279-baf4-2be676096935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2513da6-1f30-4ec2-a7d4-b06128d8de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76e3e64-32ea-4a3b-89ef-4a611e384f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: In a distant future,\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In a distant future,\"\n",
    "print(\"prompt:\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504c909a-9e0d-419d-9d63-41220898e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAD/EOS 설정 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7bac3d0-31c9-4a2a-936a-6b726b444c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|endoftext|>\n",
      "eos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# distilgpt2는 기본 pad_token이 없어서 eos로 맞춰줍니다.\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "print(\"pad_token:\", tok.pad_token)\n",
    "print(\"eos_token:\", tok.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa235b84-b534-45ac-8d3d-b2b8f800f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 컨텍스트 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adfcd17a-ae8d-46f5-9b97-f9eb0d8408de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctx shape: torch.Size([1, 5])\n",
      "ctx tokens: [818, 257, 12899, 2003, 11]\n",
      "ctx decoded: In a distant future,\n"
     ]
    }
   ],
   "source": [
    "ctx = tok(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "print(\"ctx shape:\", ctx.shape)\n",
    "print(\"ctx tokens:\", ctx[0].tolist())\n",
    "print(\"ctx decoded:\", tok.decode(ctx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a6093fd-ccea-4b02-a2d1-fd8ba08b7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draft_block (점검용: drafter도 그리디로만 1블록 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e5ec0e-4124-459d-99ab-bc405dc40599",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def draft_block_greedy(drafter, input_ids, block_size=3, pad_token_id=None):\n",
    "    # CPU에서 돌아가니 디바이스 정렬만 가볍게\n",
    "    input_ids = input_ids.to(\"cpu\")\n",
    "    # pad==eos 환경에서는 attention_mask를 명시해주는 게 안전\n",
    "    attn = (input_ids != tok.pad_token_id)\n",
    "\n",
    "    out = drafter.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attn,\n",
    "        max_new_tokens=block_size,\n",
    "        do_sample=False,          # ← 샘플링 끔 (sanity용)\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "    # 프롬프트 이후 새로 나온 블록만 반환\n",
    "    return out[:, input_ids.shape[1]:]   # shape: [1, block_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0eebf3-c09c-4b2a-b243-63fc0e481253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drafter 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ce3ef6-8272-4954-85ae-a2912eca6ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drafter 준비 완료 ✅\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# drafter: 작은 모델 (distilgpt2)\n",
    "drafter = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(\"cpu\")\n",
    "\n",
    "print(\"drafter 준비 완료 ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b893d9f4-13a3-420b-b145-a06d85132672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#첫 블록 제안 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9afb6ad-a9f0-4a45-b7c8-efe90f5c9ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draft ids: [262, 995, 318]\n",
      "draft decoded:  the world is\n"
     ]
    }
   ],
   "source": [
    "# ctx는 이전 셀에서 만든 토큰 시퀀스\n",
    "block = draft_block_greedy(drafter, ctx, block_size=3, pad_token_id=tok.eos_token_id)\n",
    "\n",
    "print(\"draft ids:\", block[0].tolist())\n",
    "print(\"draft decoded:\", tok.decode(block[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f1fb6eb-a5ab-43f9-9c5e-ae41ba86424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifier 로드 (점검 모드: drafter와 같은 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4b12156-5dc1-4e79-bc9f-7f2a9c5507a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifier 준비 완료\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "verifier = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(\"cpu\")\n",
    "print(\"verifier 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c136401-531c-4b9a-ac02-1a4925672b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifier 그리디 시퀀스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c95302-868a-4198-b582-5b14d5efe40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy ids: [262, 995, 318]\n",
      "greedy decoded:  the world is\n"
     ]
    }
   ],
   "source": [
    "greedy_seq = []\n",
    "gctx = ctx.clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(block.shape[1]):  # block 길이만큼 반복\n",
    "        out = verifier(input_ids=gctx)\n",
    "        g = out.logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        greedy_seq.append(int(g.item()))\n",
    "        gctx = torch.cat([gctx, g], dim=1)\n",
    "\n",
    "print(\"greedy ids:\", greedy_seq)\n",
    "print(\"greedy decoded:\", tok.decode(greedy_seq, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da83b377-1c5a-45fd-8bdf-f5001b5b3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#드래프트 vs 그리디를 앞에서부터 비교하며 수락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c437d1d4-47b3-447c-9171-003466dc4bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] draft=' the' vs greedy=' the' -> ACCEPT\n",
      "[1] draft=' world' vs greedy=' world' -> ACCEPT\n",
      "[2] draft=' is' vs greedy=' is' -> ACCEPT\n",
      "accepted count: 3 / 3\n"
     ]
    }
   ],
   "source": [
    "accepted_ids = []\n",
    "cur = ctx.clone()\n",
    "\n",
    "for i in range(block.shape[1]):\n",
    "    d_id = int(block[0, i].item())\n",
    "    g_id = greedy_seq[i]\n",
    "    print(f\"[{i}] draft={tok.decode([d_id])!r} vs greedy={tok.decode([g_id])!r} ->\", end=\" \")\n",
    "\n",
    "    if d_id == g_id:\n",
    "        # 일치 → draft 토큰 수락\n",
    "        accepted_ids.append(d_id)\n",
    "        cur = torch.cat([cur, block[:, i:i+1]], dim=1)\n",
    "        print(\"ACCEPT\")\n",
    "    else:\n",
    "        # 불일치 → greedy 토큰으로 대체하고 중단\n",
    "        g = torch.tensor([[g_id]], device=cur.device)\n",
    "        cur = torch.cat([cur, g], dim=1)\n",
    "        print(\"MISMATCH -> take greedy and STOP\")\n",
    "        break\n",
    "\n",
    "print(\"accepted count:\", len(accepted_ids), \"/\", block.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "189bfcaa-9887-4d9e-b50a-67d6f793afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 스텝 후 텍스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7669da2-9da6-42ca-8bda-042ecd0dd87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new text:\n",
      " In a distant future, the world is\n"
     ]
    }
   ],
   "source": [
    "print(\"new text:\\n\", tok.decode(cur[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77fe6109-874b-40d6-b737-0949b1cfd76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 스텝 함수(pva_step_once) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc0e47be-d67f-4044-bc04-1732897e920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pva_step_once(ctx, block_size=3):\n",
    "    \"\"\"\n",
    "    drafter가 block_size 토큰 제안 → verifier가 같은 길이만큼 greedy 예측 →\n",
    "    앞에서부터 일치하는 prefix만 수락, 첫 불일치에서 greedy 토큰 붙이고 종료.\n",
    "    returns: new_ctx, accepted_count\n",
    "    \"\"\"\n",
    "    # 1) draft (지금은 점검모드: 샘플링 없이 그리디)\n",
    "    block = draft_block_greedy(drafter, ctx, block_size=block_size, pad_token_id=tok.eos_token_id)\n",
    "\n",
    "    # 2) verifier greedy 시퀀스\n",
    "    greedy_seq = []\n",
    "    gctx = ctx.clone()\n",
    "    for _ in range(block.shape[1]):\n",
    "        out = verifier(input_ids=gctx)\n",
    "        g = out.logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        greedy_seq.append(int(g.item()))\n",
    "        gctx = torch.cat([gctx, g], dim=1)\n",
    "\n",
    "    # 3) 비교/수락\n",
    "    accepted = 0\n",
    "    cur = ctx.clone()\n",
    "    for i in range(block.shape[1]):\n",
    "        d_id = int(block[0, i].item())\n",
    "        g_id = greedy_seq[i]\n",
    "        if d_id == g_id:\n",
    "            cur = torch.cat([cur, block[:, i:i+1]], dim=1)\n",
    "            accepted += 1\n",
    "        else:\n",
    "            g = torch.tensor([[g_id]], device=cur.device)\n",
    "            cur = torch.cat([cur, g], dim=1)\n",
    "            break\n",
    "    return cur, accepted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfaf0b56-906b-4097-a6b8-5b9521f36f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 스텝 더 실행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97899f1d-5d20-49aa-bf24-c00ea159f417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted this step: 3\n",
      "In a distant future, the world is in a state\n"
     ]
    }
   ],
   "source": [
    "cur2, acc2 = pva_step_once(cur, block_size=3)\n",
    "print(\"accepted this step:\", acc2)\n",
    "print(tok.decode(cur2[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f6c395c-562d-4837-8f3e-45aca9ade234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#짧은 루프 (5스텝만) 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04b7baa8-bd39-4281-b9d4-5e09e6d39f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1] accepted=3, text='In a distant future, the world is'\n",
      "[step 2] accepted=3, text='In a distant future, the world is in a state'\n",
      "[step 3] accepted=3, text='In a distant future, the world is in a state of flux.'\n",
      "[step 4] accepted=3, text='In a distant future, the world is in a state of flux. The world is'\n",
      "[step 5] accepted=3, text='In a distant future, the world is in a state of flux. The world is in a state'\n"
     ]
    }
   ],
   "source": [
    "ctx_loop = ctx.clone()\n",
    "for step in range(5):\n",
    "    ctx_loop, acc = pva_step_once(ctx_loop, block_size=3)\n",
    "    print(f\"[step {step+1}] accepted={acc}, text='{tok.decode(ctx_loop[0], skip_special_tokens=True)}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17e81a57-338c-4057-bbdb-957ba9e6a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#샘플링 버전 draft 함수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbdf6c1c-f188-4396-bac0-91d115040b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def draft_block_sampled(\n",
    "    drafter, input_ids, block_size=3,\n",
    "    top_k=20, top_p=0.9, temperature=0.7,\n",
    "    pad_token_id=None, repetition_penalty=1.05, no_repeat_ngram_size=3\n",
    "):\n",
    "    input_ids = input_ids.to(\"cpu\")\n",
    "    attn = (input_ids != tok.pad_token_id)\n",
    "\n",
    "    out = drafter.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attn,\n",
    "        max_new_tokens=block_size,\n",
    "        do_sample=True,\n",
    "        top_k=top_k, top_p=top_p, temperature=temperature,\n",
    "        pad_token_id=pad_token_id,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "    )\n",
    "    return out[:, input_ids.shape[1]:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95116f72-9726-4c06-a35d-dca1404b406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#현실 모드 한 스텝(pva_step_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca38f3de-fc48-4707-a4f4-9c234f8ebf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pva_step_real(ctx, block_size=3):\n",
    "    # drafter: guided drafting 사용\n",
    "    block = draft_block_guided(\n",
    "        drafter, verifier, ctx, block_size=block_size,\n",
    "        guide_topk=20,        # 10~30 사이로 조절해 보세요\n",
    "        sample_topk=40, top_p=0.95, temperature=0.7,\n",
    "        pad_token_id=tok.eos_token_id,\n",
    "        repetition_penalty=1.05, no_repeat_ngram_size=3\n",
    "    )\n",
    "\n",
    "    # 이하 동일 (verifier greedy)\n",
    "    greedy_seq = []\n",
    "    gctx = ctx.clone()\n",
    "    for _ in range(block.shape[1]):\n",
    "        attn = (gctx != tok.pad_token_id)\n",
    "        out = verifier(input_ids=gctx, attention_mask=attn)\n",
    "        g = out.logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        greedy_seq.append(int(g.item()))\n",
    "        gctx = torch.cat([gctx, g], dim=1)\n",
    "\n",
    "    accepted = 0\n",
    "    cur = ctx.clone()\n",
    "    for i in range(block.shape[1]):\n",
    "        d_id = int(block[0, i])\n",
    "        g_id = greedy_seq[i]\n",
    "        if d_id == g_id:\n",
    "            cur = torch.cat([cur, block[:, i:i+1]], dim=1)\n",
    "            accepted += 1\n",
    "        else:\n",
    "            g = torch.tensor([[g_id]], device=cur.device)\n",
    "            cur = torch.cat([cur, g], dim=1)\n",
    "            break\n",
    "    return cur, accepted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8c04f47-4421-484e-ae2c-75d62469aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draft_block_guided 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88f87063-b98b-42ac-a37e-bc71d9321236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def draft_block_guided(\n",
    "    drafter, verifier, input_ids,\n",
    "    block_size=3,\n",
    "    guide_topk=20,            # verifier 상위 K 토큰만 허용\n",
    "    sample_topk=40, top_p=0.95, temperature=0.7,\n",
    "    pad_token_id=None, repetition_penalty=1.05, no_repeat_ngram_size=3\n",
    "):\n",
    "    \"\"\"\n",
    "    verifier의 상위-K 후보만 허용해서 drafter가 그 안에서 샘플링하도록 가이드.\n",
    "    일치 확률을 높여 acceptance를 끌어올리는 테크닉.\n",
    "    \"\"\"\n",
    "    ctx = input_ids.clone()\n",
    "\n",
    "    for _ in range(block_size):\n",
    "        # 1) verifier 분포 상위 K 토큰 집합\n",
    "        v_out = verifier(input_ids=ctx, attention_mask=(ctx != tok.pad_token_id))\n",
    "        v_logits = v_out.logits[:, -1, :]\n",
    "        v_topk = torch.topk(v_logits, k=min(guide_topk, v_logits.shape[-1]), dim=-1).indices[0]\n",
    "        v_allowed = set(v_topk.tolist())\n",
    "\n",
    "        # 2) drafter 분포\n",
    "        d_out = drafter(input_ids=ctx, attention_mask=(ctx != tok.pad_token_id))\n",
    "        d_logits = d_out.logits[:, -1, :].squeeze(0)\n",
    "\n",
    "        # 3) verifier 상위집합 외 토큰은 -inf로 마스킹\n",
    "        mask = torch.full_like(d_logits, float(\"-inf\"))\n",
    "        mask[list(v_allowed)] = 0.0\n",
    "        guided_logits = d_logits + mask\n",
    "\n",
    "        # 4) guided 분포에서 샘플링(top-k+temperature; 필요시 top_p로 대체 가능)\n",
    "        k = int(min(sample_topk, (guided_logits != float(\"-inf\")).sum().item()))\n",
    "        if k <= 0:\n",
    "            # 가끔 상위집합이 너무 작을 때 대비: drafter 그리디로 fallback\n",
    "            next_id = torch.argmax(d_logits).view(1,1)\n",
    "        else:\n",
    "            vals, idxs = torch.topk(guided_logits, k=k, dim=-1)\n",
    "            probs = torch.softmax(vals / max(temperature, 1e-6), dim=-1)\n",
    "            pick_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "            next_id = idxs[pick_idx].view(1,1)\n",
    "\n",
    "        ctx = torch.cat([ctx, next_id], dim=1)\n",
    "\n",
    "    # 프롬프트 이후 block만 반환\n",
    "    return ctx[:, input_ids.shape[1]:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "817cc4cd-fbcf-4939-a6eb-e7000a0b5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#현실 모드 한 스텝만 시험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19407c99-4993-4104-a297-e66ee1f38e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted (real step): 1\n",
      "In a distant future, the world\n"
     ]
    }
   ],
   "source": [
    "ctx_real = ctx.clone()\n",
    "ctx_real, acc_real = pva_step_real(ctx_real, block_size=3)\n",
    "print(\"accepted (real step):\", acc_real)\n",
    "print(tok.decode(ctx_real[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af4e905f-32fa-4b6f-9302-e2e80446cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#짧은 루프(현실 모드, 8스텝)로 감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dfc34d4-dadb-4904-a20f-c5e23e678c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] accepted=0, acc_rate_so_far=0.0%\n",
      "[2] accepted=0, acc_rate_so_far=0.0%\n",
      "[3] accepted=0, acc_rate_so_far=0.0%\n",
      "[4] accepted=0, acc_rate_so_far=0.0%\n",
      "[5] accepted=0, acc_rate_so_far=0.0%\n",
      "[6] accepted=0, acc_rate_so_far=0.0%\n",
      "[7] accepted=2, acc_rate_so_far=14.3%\n",
      "[8] accepted=1, acc_rate_so_far=18.8%\n",
      "text:\n",
      "In a distant future, the world is in a state of flux. The\n"
     ]
    }
   ],
   "source": [
    "def run_short_real(ctx0, steps=8, block_size=3):\n",
    "    ctx = ctx0.clone()\n",
    "    proposed = accepted = 0\n",
    "    for i in range(steps):\n",
    "        ctx, acc = pva_step_real(ctx, block_size=block_size)\n",
    "        proposed += block_size\n",
    "        accepted += acc\n",
    "        print(f\"[{i+1}] accepted={acc}, acc_rate_so_far={round(100*accepted/proposed,1)}%\")\n",
    "    print(\"text:\")\n",
    "    print(tok.decode(ctx[0], skip_special_tokens=True))\n",
    "    return ctx\n",
    "\n",
    "_ = run_short_real(ctx, steps=8, block_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a80e2-e5ed-480c-91a5-d71ac223a44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bpd_env)",
   "language": "python",
   "name": "bpd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
