{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71782ec3-a356-45e5-a653-215598104a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPipeline Overview:\\n[User Input]\\n     â†“\\n[LangGraph to manage control flow]\\n     â†“\\n[1. Toolformer style tool selection]\\n     â†“\\n[2. Tavily for Web + Wikipedia search (or custom retriever)]\\n     â†“\\n[3. CRAG for summarization + QA generation (e.g., DistilBART + FLAN-T5)]\\n     â†“\\n[4. LangChain to connect the entire pipeline]\\n     â†“\\n[5. sklearn/evaluation for results evaluation and tuning]\\n     â†“\\n[Final response output]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline Overview:\n",
    "[User Input]\n",
    "     â†“\n",
    "[LangGraph to manage control flow]\n",
    "     â†“\n",
    "[1. Toolformer style tool selection]\n",
    "     â†“\n",
    "[2. Tavily for Web + Wikipedia search (or custom retriever)]\n",
    "     â†“\n",
    "[3. CRAG for summarization + QA generation (e.g., DistilBART + FLAN-T5)]\n",
    "     â†“\n",
    "[4. LangChain to connect the entire pipeline]\n",
    "     â†“\n",
    "[5. sklearn/evaluation for results evaluation and tuning]\n",
    "     â†“\n",
    "[Final response output]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23f59933-91d3-4a43-b1ef-852f4f8dbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # .envì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "client = OpenAI()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ìžë™ ì¸ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0211820d-a28b-4fd7-825a-c96cb1a543ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chat_with_openai(messages):calls the OpenAI API and returns a response to the chat messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adc7b006-aad3-4208-9160-a5d365fd72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_openai(messages):\n",
    "    \"\"\"\n",
    "    Sends a chat completion request to OpenAI API using the provided messages\n",
    "    and returns the generated response content.\n",
    "\n",
    "    Args:\n",
    "        messages (list): A list of message dicts following OpenAI chat format,\n",
    "                         e.g., [{\"role\": \"user\", \"content\": \"Hello!\"}, ...]\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the assistant's reply or an error message if the API call fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Call the OpenAI chat completion endpoint with the specified model and messages\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0  # deterministic response\n",
    "        )\n",
    "        # Extract and return the assistant's message content from the response\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        # Return an error string if the API call raises an exception\n",
    "        return f\"[Error] OpenAI API call failed: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e0e2184-2eda-4d06-bd20-76b7f689596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ain execution block: sets up system and user prompts, calls the chat function, and prints the GPT response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d059586c-9791-4e35-90b2-e722041fb550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Response:\n",
      " Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
      "\n",
      "NLP encompasses a variety of tasks, including:\n",
      "\n",
      "1. **Text Analysis**: Understanding and extracting information from text, such as sentiment analysis, topic modeling, and named entity recognition.\n",
      "2. **Language Generation**: Creating coherent and contextually relevant text, such as in chatbots or automated content generation.\n",
      "3. **Machine Translation**: Automatically translating text from one language to another.\n",
      "4. **Speech Recognition**: Converting spoken language into text.\n",
      "5. **Text-to-Speech**: Converting written text into spoken language.\n",
      "\n",
      "NLP combines techniques from linguistics, computer science, and machine learning to process and analyze large amounts of natural language data. It has applications in various domains, including customer service, healthcare, education, and more.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    system_prompt = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "    user_prompt = {\"role\": \"user\", \"content\": \"Explain natural language processing briefly.\"}\n",
    "\n",
    "    messages = [system_prompt, user_prompt]\n",
    "\n",
    "    answer = chat_with_openai(messages)\n",
    "    print(\"GPT Response:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a661800a-9058-48ab-9982-e4043dc9115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nToolformer-style Tool Selection\\nThe LLM (e.g., GPT) autonomously decides which tool to use based on the context of the query.\\nIt can automatically determine whether to call a search tool, summarization tool, external API, or other functions.\\nLangChain provides implementations such as the Multi-Tool Agent or Router Agent that facilitate this automatic tool routing.\\nIn essence, the LLM intelligently chooses and invokes the appropriate tool (e.g., search_tool, math_tool) to handle the task.\\nThis approach enables dynamic and context-aware tool usage, making interactions more flexible and efficient.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Toolformer-style Tool Selection\n",
    "The LLM (e.g., GPT) autonomously decides which tool to use based on the context of the query.\n",
    "It can automatically determine whether to call a search tool, summarization tool, external API, or other functions.\n",
    "LangChain provides implementations such as the Multi-Tool Agent or Router Agent that facilitate this automatic tool routing.\n",
    "In essence, the LLM intelligently chooses and invokes the appropriate tool (e.g., search_tool, math_tool) to handle the task.\n",
    "This approach enables dynamic and context-aware tool usage, making interactions more flexible and efficient.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5097c19a-9d27-4511-8542-566aa9792cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define tools\n",
    "def search_tool(query: str) -> str:\n",
    "    # Simulate a search result for the given query (not an actual search)\n",
    "    return f\"[SearchResult] Search results for '{query}'. (Not a real search)\"\n",
    "\n",
    "from asteval import Interpreter\n",
    "\n",
    "aeval = Interpreter()\n",
    "\n",
    "def math_tool(expression: str) -> str:\n",
    "    try:\n",
    "        # Evaluate the mathematical expression safely\n",
    "        result = aeval(expression)\n",
    "        if aeval.error:\n",
    "            # Collect error messages if any evaluation errors occurred\n",
    "            errors = \"; \".join(str(err.get_error()) for err in aeval.error)\n",
    "            aeval.error = []  # Reset errors after collecting\n",
    "            return f\"[MathError] Expression error: {errors}\"\n",
    "        return f\"[MathResult] {expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions raised during evaluation\n",
    "        return f\"[MathError] Exception occurred: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e97d3ea-4fb3-4960-bda8-1246ade86d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping tool names to their corresponding functions\n",
    "TOOLS = {\n",
    "    \"search\": {\n",
    "        \"description\": \"Information retrieval tool (example implementation)\",\n",
    "        \"function\": search_tool,\n",
    "    },\n",
    "    \"math\": {\n",
    "        \"description\": \"Safe mathematical calculation tool\",\n",
    "        \"function\": math_tool,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e5011e-68bc-45a3-ba19-f01364f4c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66683a8a-a979-4aad-a115-ea849488d8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Tool Output:\n",
      "[SearchResult] Search results for 'OpenAI GPT models'. (Not a real search)\n",
      "\n",
      "Math Tool Output:\n",
      "[MathResult] 2 + 3 * (4 - 1) = 11\n",
      "\n",
      "Math Tool Error Output:\n",
      "[MathError] Expression error: ('SyntaxError', '2 + * 3\\nSyntaxError: invalid syntax (<unknown>, line 1)')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 + * 3\n",
      "SyntaxError: invalid syntax (<unknown>, line 1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Test search_tool\n",
    "    search_query = \"OpenAI GPT models\"\n",
    "    search_result = TOOLS[\"search\"][\"function\"](search_query)\n",
    "    print(f\"Search Tool Output:\\n{search_result}\\n\")\n",
    "\n",
    "    # Test math_tool\n",
    "    math_expression = \"2 + 3 * (4 - 1)\"\n",
    "    math_result = TOOLS[\"math\"][\"function\"](math_expression)\n",
    "    print(f\"Math Tool Output:\\n{math_result}\\n\")\n",
    "\n",
    "    # Test math_tool with an invalid expression\n",
    "    invalid_expression = \"2 + * 3\"\n",
    "    error_result = TOOLS[\"math\"][\"function\"](invalid_expression)\n",
    "    print(f\"Math Tool Error Output:\\n{error_result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ff16662-dc9e-47a6-8615-8e7e1947df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_tool(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Decide which tool to use based on the user's input by prompting the AI model.\n",
    "    Returns the tool name and argument in 'tool_name: argument' format,\n",
    "    or error messages if the format or tool is invalid.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a smart tool selector.\n",
    "User question: \"{user_input}\"\n",
    "\n",
    "Available tools: search, math\n",
    "\n",
    "Output the tool to use and its argument in the form 'tool_name: argument'.\n",
    "Example) search: latest AI news\n",
    "\"\"\".strip()\n",
    "\n",
    "    # Call the OpenAI chat completion endpoint with a system and user message\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI deciding which tool to use.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    result = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Check if the result contains ':' to separate tool and argument\n",
    "    if \":\" not in result:\n",
    "        return \"[Error] Tool selection format is incorrect.\"\n",
    "\n",
    "    # Parse the tool name and argument, stripping whitespace\n",
    "    tool_name, argument = map(str.strip, result.split(\":\", 1))\n",
    "\n",
    "    # Validate tool name against supported tools\n",
    "    if tool_name not in TOOLS:\n",
    "        return f\"[Error] Tool '{tool_name}' is not supported.\"\n",
    "\n",
    "    # Validate argument is not empty\n",
    "    if not argument:\n",
    "        return \"[Error] Tool argument is empty.\"\n",
    "\n",
    "    # Return the formatted tool name and argument\n",
    "    return f\"{tool_name}: {argument}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81901e54-852a-4861-aca0-48ebf534c72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Calculate 2 + 3 * 4\n",
      "Decided tool: math: 2 + 3 * 4\n",
      "\n",
      "Input: Find the latest news about AI\n",
      "Decided tool: search: latest news about AI\n",
      "\n",
      "Input: What is 5 / 0?\n",
      "Decided tool: math: 5 / 0\n",
      "\n",
      "Input: Tell me about LangChain\n",
      "Decided tool: search: LangChain overview and features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"Calculate 2 + 3 * 4\",\n",
    "    \"Find the latest news about AI\",\n",
    "    \"What is 5 / 0?\",\n",
    "    \"Tell me about LangChain\"\n",
    "]\n",
    "\n",
    "for user_input in test_inputs:\n",
    "    decision = decide_tool(user_input)\n",
    "    print(f\"Input: {user_input}\\nDecided tool: {decision}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35f24234-9ce4-45a3-b32e-03419ec05a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Parses the tool command string, validates the tool name and argument,\\n    executes the corresponding tool function, and returns the result.\\n    If errors occur, returns a standardized JSON-formatted error message.\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def run_tool_agent(tool_command: str) -> str:\n",
    "\"\"\"\n",
    "    Parses the tool command string, validates the tool name and argument,\n",
    "    executes the corresponding tool function, and returns the result.\n",
    "    If errors occur, returns a standardized JSON-formatted error message.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ffdf666-f794-486e-80ab-a0fc5e25841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tool_agent(tool_command: str) -> str:\n",
    "    # Check if the input command contains ':' to separate tool and argument\n",
    "    if \":\" not in tool_command:\n",
    "        return \"Input format error. Example: 'search: AI trends'\"\n",
    "\n",
    "    # Split the input into tool name and argument\n",
    "    tool_name, argument = tool_command.split(\":\", 1)\n",
    "    # Normalize tool name to lowercase to avoid case sensitivity issues\n",
    "    tool_name = tool_name.strip().lower()\n",
    "    # Remove any extra whitespace from argument\n",
    "    argument = argument.strip()\n",
    "\n",
    "    # Verify if the tool name exists in the supported tools dictionary\n",
    "    if tool_name not in TOOLS:\n",
    "        return f\"[Error] Unsupported tool: {tool_name}\"\n",
    "\n",
    "    try:\n",
    "        # Execute the function associated with the selected tool using the argument\n",
    "        result = TOOLS[tool_name][\"function\"](argument)\n",
    "        # Return the function's result\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # If an error occurs, prepare a standardized JSON-formatted error message\n",
    "        error_msg = {\n",
    "            \"error\": \"Tool execution error\",\n",
    "            \"tool\": tool_name,\n",
    "            \"message\": str(e),\n",
    "        }\n",
    "        import json\n",
    "        # Return the error message as a JSON string, preserving non-ASCII characters\n",
    "        return json.dumps(error_msg, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc4ac390-47b0-4401-bb51-2b023a32ec55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: search: Latest AI news\n",
      "Output: [SearchResult] Search results for 'Latest AI news'. (Not a real search)\n",
      "\n",
      "Command: math: 2 + 3 * 4\n",
      "Output: [MathResult] 2 + 3 * 4 = 14\n",
      "\n",
      "Command: math: 5 / 0\n",
      "Output: [MathError] Expression error: ('ZeroDivisionError', '5 / 0\\nZeroDivisionError: division by zero')\n",
      "\n",
      "Command: unknown: some argument\n",
      "Output: [Error] Unsupported tool: unknown\n",
      "\n",
      "Command: search\n",
      "Output: Input format error. Example: 'search: AI trends'\n",
      "\n",
      "Command: math: \n",
      "Output: [MathResult]  = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test cases for run_tool_agent function\n",
    "\n",
    "test_commands = [\n",
    "    \"search: Latest AI news\",\n",
    "    \"math: 2 + 3 * 4\",\n",
    "    \"math: 5 / 0\",               # Division by zero to test error handling\n",
    "    \"unknown: some argument\",    # Unsupported tool test\n",
    "    \"search\",                   # Invalid format test (missing ':')\n",
    "    \"math: \",                   # Empty argument test\n",
    "]\n",
    "\n",
    "for command in test_commands:\n",
    "    print(f\"Command: {command}\")\n",
    "    output = run_tool_agent(command)\n",
    "    print(f\"Output: {output}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91f78c90-96ef-4723-9169-1b624a1780a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_response(user_input: str, tool_result: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a friendly and easy-to-understand final response based on the user's input and the tool execution result.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): The original question or input from the user.\n",
    "        tool_result (str): The output or result returned from the selected tool.\n",
    "\n",
    "    Returns:\n",
    "        str: A polished, user-friendly response generated by the AI.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "User question: \"{user_input}\"\n",
    "Tool execution result: \"{tool_result}\"\n",
    "\n",
    "Based on the above, please provide a kind and easy-to-understand answer.\n",
    "\"\"\"\n",
    "    try:\n",
    "        # Call OpenAI's chat completion endpoint with system and user messages\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Return the AI-generated final response, stripped of extra whitespace\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        # Return error message if API call fails\n",
    "        return f\"[Error] Failed to generate final response: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b1f36e3-c7d7-49f4-aed5-c44dd16f313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final AI Response:\n",
      " The answer to 2 + 2 is 4. If you have any more questions or need help with anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_user_input = \"What is 2 + 2?\"\n",
    "    test_tool_result = \"2 + 2 = 4\"\n",
    "\n",
    "    final_answer = generate_final_response(test_user_input, test_tool_result)\n",
    "    print(\"Final AI Response:\\n\", final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77fa4ee8-53b2-4e05-820a-4ba49f9bb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Toolformer-style tool selection and execution ---\n",
    "def decide_and_use_tool(user_input: str) -> str:\n",
    "    # 1) Create a prompt asking the LLM which tool to use based on the user input\n",
    "    tool_prompt = (\n",
    "        f\"User question: \\\"{user_input}\\\"\\n\\n\"\n",
    "        \"Decide which tool to use from the list below and respond in the format:\\n\"\n",
    "        \"[TOOL: tool_name] tool_input\\n\\n\"\n",
    "        \"Example: [TOOL: math] 5 + 3 * 2\\n\"\n",
    "        \"Available tools: search, math\\n\"\n",
    "    )\n",
    "\n",
    "    # 2) Call the OpenAI API to get the tool selection from the LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a smart AI that selects and runs tools.\"},\n",
    "            {\"role\": \"user\", \"content\": tool_prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    tool_decision = response.choices[0].message.content\n",
    "\n",
    "    # 3) Parse the tool name and input from the LLM response\n",
    "    if \"[TOOL:\" in tool_decision:\n",
    "        try:\n",
    "            tool_name = tool_decision.split(\"[TOOL:\")[1].split(\"]\")[0].strip()\n",
    "            tool_input = tool_decision.split(\"]\")[1].strip()\n",
    "\n",
    "            # 4) If the tool is registered in TOOLS, execute it and return the result\n",
    "            if tool_name in TOOLS:\n",
    "                tool_output = TOOLS[tool_name][\"function\"](tool_input)\n",
    "                return f\"Tool execution result:\\n{tool_output}\"\n",
    "            else:\n",
    "                return f\"Unknown tool: {tool_name}\"\n",
    "        except Exception as e:\n",
    "            return f\"Tool parsing error: {e}\"\n",
    "    else:\n",
    "        # 5) Return a warning if tool call format is not detected\n",
    "        return f\"No tool call detected:\\n{tool_decision}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e675a92-7b2f-4390-bb03-eec466571a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bd482af-d7aa-4585-a7e8-f0947dfbdaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== User question ===\n",
      "What is artificial intelligence?\n",
      "\n",
      "--- Toolformer output ---\n",
      "Tool execution result:\n",
      "[SearchResult] Search results for 'What is artificial intelligence?'. (Not a real search)\n",
      "\n",
      "--- Final answer ---\n",
      "Artificial intelligence (AI) refers to the ability of machines or computer systems to perform tasks that typically require human intelligence. This includes things like understanding natural language, recognizing patterns, solving problems, and making decisions. \n",
      "\n",
      "AI can be found in various applications, such as virtual assistants (like Siri or Alexa), recommendation systems (like those used by Netflix or Amazon), and even in self-driving cars. Essentially, AI aims to create systems that can think and learn like humans, allowing them to improve their performance over time based on experience.\n",
      "\n",
      "=== User question ===\n",
      "Tell me features of the Python language.\n",
      "\n",
      "--- Toolformer output ---\n",
      "Tool execution result:\n",
      "[SearchResult] Search results for 'features of the Python language'. (Not a real search)\n",
      "\n",
      "--- Final answer ---\n",
      "Python is a popular programming language known for its simplicity and versatility. Here are some key features of Python:\n",
      "\n",
      "1. **Easy to Read and Write**: Python has a clean and straightforward syntax, which makes it easy for beginners to learn and for experienced programmers to read and maintain code.\n",
      "\n",
      "2. **Interpreted Language**: Python is an interpreted language, meaning that code is executed line by line. This allows for quick testing and debugging.\n",
      "\n",
      "3. **Dynamically Typed**: In Python, you donâ€™t need to declare the type of a variable when you create it. The type is determined at runtime, which makes coding faster and more flexible.\n",
      "\n",
      "4. **Extensive Standard Library**: Python comes with a large standard library that provides modules and functions for various tasks, such as file handling, web development, and data manipulation, reducing the need for external libraries.\n",
      "\n",
      "5. **Cross-Platform Compatibility**: Python can run on various operating systems, including Windows, macOS, and Linux, making it a versatile choice for developers.\n",
      "\n",
      "6. **Object-Oriented**: Python supports object-oriented programming (OOP) principles, allowing for the creation of classes and objects, which helps in organizing code and promoting reuse.\n",
      "\n",
      "7. **Large Community and Ecosystem**: Python has a vast community of developers and a rich ecosystem of third-party libraries and frameworks, such as Django for web development and NumPy for scientific computing.\n",
      "\n",
      "8. **Support for Multiple Programming Paradigms**: Python supports various programming styles, including procedural, functional, and object-oriented programming, giving developers the flexibility to choose the best approach for their projects.\n",
      "\n",
      "9. **Strong Community Support**: With a large and active community, Python users can find plenty of resources, tutorials, and forums for help and collaboration.\n",
      "\n",
      "10. **Integration Capabilities**: Python can easily integrate with other languages like C, C++, and Java, allowing developers to use Python alongside other technologies.\n",
      "\n",
      "These features make Python a great choice for a wide range of applications, from web development to data analysis and artificial intelligence.\n",
      "\n",
      "=== User question ===\n",
      "exit\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "def should_exit(user_input: str) -> bool:\n",
    "    return user_input.strip().lower() in [\"exit\", \"quit\"]\n",
    "\n",
    "def test_toolformer_agent(questions):\n",
    "    for user_input in questions:\n",
    "        print(f\"\\n=== User question ===\\n{user_input}\")\n",
    "        if should_exit(user_input):\n",
    "            print(\"Exiting program.\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # 1) ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰\n",
    "            toolformer_result = decide_and_use_tool(user_input)\n",
    "            print(f\"\\n--- Toolformer output ---\\n{toolformer_result}\")\n",
    "\n",
    "            # 2) ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "            final_answer = generate_final_response(user_input, toolformer_result)\n",
    "            print(f\"\\n--- Final answer ---\\n{final_answer}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Exception during processing: {e}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n",
    "test_questions = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Tell me features of the Python language.\",\n",
    "    \"exit\"\n",
    "]\n",
    "\n",
    "# ì‹¤í–‰\n",
    "test_toolformer_agent(test_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b72b46d-4f61-4332-b3c3-a2ee918fe56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì§ˆë¬¸: ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\n",
      "\n",
      "[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\n",
      "Tool execution result:\n",
      "[SearchResult] Search results for '\"ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\"'. (Not a real search)\n",
      "\n",
      "[ìµœì¢… ë‹µë³€]\n",
      "ì¸ê³µì§€ëŠ¥(Artificial Intelligence, AI)ì€ ì»´í“¨í„°ë‚˜ ê¸°ê³„ê°€ ì¸ê°„ì²˜ëŸ¼ ìƒê°í•˜ê³  í•™ìŠµí•  ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê¸°ìˆ ìž…ë‹ˆë‹¤. ì¦‰, ì¸ê³µì§€ëŠ¥ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , íŒ¨í„´ì„ ì¸ì‹í•˜ë©°, ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìžˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìŒì„± ì¸ì‹, ì´ë¯¸ì§€ ì¸ì‹, ìžìœ¨ì£¼í–‰ì°¨, ì±—ë´‡ ë“±ì´ ëª¨ë‘ ì¸ê³µì§€ëŠ¥ì˜ ì˜ˆìž…ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìžˆìœ¼ë©°, ìš°ë¦¬ì˜ ì¼ìƒìƒí™œì„ ë” íŽ¸ë¦¬í•˜ê²Œ ë§Œë“¤ì–´ ì£¼ê³  ìžˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì§ˆë¬¸: Python ì–¸ì–´ íŠ¹ì§• ì•Œë ¤ì¤˜\n",
      "\n",
      "[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\n",
      "Tool execution result:\n",
      "[SearchResult] Search results for 'Python ì–¸ì–´ íŠ¹ì§•'. (Not a real search)\n",
      "\n",
      "[ìµœì¢… ë‹µë³€]\n",
      "Pythonì€ ë§¤ìš° ì¸ê¸° ìžˆëŠ” í”„ë¡œê·¸ëž˜ë° ì–¸ì–´ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ë“¤ì´ ìžˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•**: Pythonì€ ì½”ë“œê°€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ì—¬, ë‹¤ë¥¸ í”„ë¡œê·¸ëž˜ë° ì–¸ì–´ì— ë¹„í•´ ë°°ìš°ê¸° ì‰½ìŠµë‹ˆë‹¤. ì´ëŠ” ì´ˆë³´ìžì—ê²Œ ë§¤ìš° ìœ ë¦¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë‹¤ì–‘í•œ ìš©ë„**: Pythonì€ ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„, ì¸ê³µì§€ëŠ¥, ë¨¸ì‹ ëŸ¬ë‹, ìžë™í™” ìŠ¤í¬ë¦½íŠ¸ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ê°•ë ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í”„ë ˆìž„ì›Œí¬**: Pythonì€ NumPy, Pandas, TensorFlow, Django ë“± ë§Žì€ ê°•ë ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í”„ë ˆìž„ì›Œí¬ë¥¼ ì§€ì›í•˜ì—¬ ê°œë°œìžë“¤ì´ íš¨ìœ¨ì ìœ¼ë¡œ ìž‘ì—…í•  ìˆ˜ ìžˆë„ë¡ ë•ìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **í”Œëž«í¼ ë…ë¦½ì„±**: Pythonì€ Windows, macOS, Linux ë“± ë‹¤ì–‘í•œ ìš´ì˜ì²´ì œì—ì„œ ì‹¤í–‰ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ëŒ€í™”í˜• í”„ë¡œê·¸ëž˜ë°**: Pythonì€ ëŒ€í™”í˜• ëª¨ë“œì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìžˆì–´, ì‹¤ì‹œê°„ìœ¼ë¡œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ë©° ê°œë°œí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ì»¤ë®¤ë‹ˆí‹°ì™€ ì§€ì›**: Pythonì€ í° ì»¤ë®¤ë‹ˆí‹°ë¥¼ ê°€ì§€ê³  ìžˆì–´, ë¬¸ì œ í•´ê²°ì´ë‚˜ í•™ìŠµ ìžë£Œë¥¼ ì°¾ê¸°ê°€ ì‰½ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ íŠ¹ì§•ë“¤ ë•ë¶„ì— Pythonì€ ì´ˆë³´ìžë¶€í„° ì „ë¬¸ê°€ê¹Œì§€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ìž…ë‹ˆë‹¤.\n",
      "\n",
      "ì§ˆë¬¸: exit\n",
      "í”„ë¡œê·¸ëž¨ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\",\n",
    "    \"Python ì–¸ì–´ íŠ¹ì§• ì•Œë ¤ì¤˜\",\n",
    "    \"exit\"\n",
    "]\n",
    "\n",
    "for user_input in test_questions:\n",
    "    print(f\"\\nì§ˆë¬¸: {user_input}\")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"í”„ë¡œê·¸ëž¨ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        break\n",
    "    toolformer_result = decide_and_use_tool(user_input)\n",
    "    print(f\"\\n[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\\n{toolformer_result}\")\n",
    "    final_answer = generate_final_response(user_input, toolformer_result)\n",
    "    print(f\"\\n[ìµœì¢… ë‹µë³€]\\n{final_answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fe967e8-5ef3-4639-99e5-368367fb2a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜ˆì‹œ ---\\nif __name__ == \"__main__\":\\n    print(\"ì¢…ë£Œí•˜ë ¤ë©´ \\'exit\\' ë˜ëŠ” \\'quit\\' ìž…ë ¥\")\\n    while True:\\n        user_input = input(\"\\nì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”: \")\\n        if user_input.lower() in [\"exit\", \"quit\"]:\\n            print(\"í”„ë¡œê·¸ëž¨ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\\n            break\\n\\n        # Toolformer ìŠ¤íƒ€ì¼ ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰\\n        toolformer_result = decide_and_use_tool(user_input)\\n        print(f\"\\n[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\\n{toolformer_result}\")\\n\\n        # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±\\n        final_answer = generate_final_response(user_input, toolformer_result)\\n        print(f\"\\n[ìµœì¢… ë‹µë³€]\\n{final_answer}\")\\n        '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜ˆì‹œ ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ìž…ë ¥\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"í”„ë¡œê·¸ëž¨ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        # Toolformer ìŠ¤íƒ€ì¼ ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰\n",
    "        toolformer_result = decide_and_use_tool(user_input)\n",
    "        print(f\"\\n[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\\n{toolformer_result}\")\n",
    "\n",
    "        # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "        final_answer = generate_final_response(user_input, toolformer_result)\n",
    "        print(f\"\\n[ìµœì¢… ë‹µë³€]\\n{final_answer}\")\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37c4a26c-cd68-490d-bb7c-6ff3a595a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare Wikipedia + RAG\n",
    "#LangChain LLM (3.5 turbo)\n",
    "#OpenAI API ì§ì ‘ í˜¸ì¶œ (gpt-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ab7191e-49b3-43b9-97ba-35c5240724a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db1ca330-4296-4ef3-8b2a-1aa12d66b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared responses from our vanilla LLM, Wikipedia API retrieval, and GPT-3.5 Turbo against the journal-defined standard for Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94193733-1d1e-42c9-8ec4-69b518f8792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant responses. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "query = \"What is Retrieval-Augmented Generation?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "openai_answer = response.choices[0].message.content\n",
    "print(openai_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d59515f6-d3d0-44a3-ba4c-e96e46dca318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_58950/3068372305.py:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n",
      "/var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_58950/3068372305.py:27: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  wiki_answer = wiki_chain.run(query)\n",
      "/var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_58950/3068372305.py:30: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  vanilla_answer = llm.predict(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Wikipedia RAG answer:\n",
      " Retrieval-augmented generation (RAG) is a technique that enhances large language models (LLMs) by allowing them to retrieve and incorporate new information from external sources before generating responses. This method helps LLMs access domain-specific or updated information that is not present in their original training data. By blending the LLM process with information retrieval, RAG helps LLMs provide more accurate and contextually relevant responses.\n",
      "\n",
      "ðŸ§  Vanilla LangChain LLM (3.5) answer:\n",
      " Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into the generation process, leading to more accurate and contextually relevant responses. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\n",
      "\n",
      "ðŸ¤– Direct OpenAI API call (3.5 turbo) answer:\n",
      " Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generation-based approaches. In this approach, a retrieval system is used to retrieve relevant information or context from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant responses. This approach has been used in various applications such as question answering, dialogue systems, and content generation.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import WikipediaRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1) Create WikipediaRetriever instance to fetch relevant Wikipedia documents\n",
    "retriever = WikipediaRetriever()\n",
    "\n",
    "# 2) Initialize LangChain LLM with GPT-3.5 Turbo model and temperature 0 for deterministic output\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 3) Create RetrievalQA chain by combining the retriever with the LLM\n",
    "#    Uses \"stuff\" chain type which directly passes retrieved documents as context\n",
    "wiki_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False  # Do not return source docs in the output\n",
    ")\n",
    "\n",
    "query = \"What is Retrieval-Augmented Generation?\"\n",
    "\n",
    "# 4) Run the Wikipedia-based RAG pipeline to get an answer augmented by Wikipedia info\n",
    "wiki_answer = wiki_chain.run(query)\n",
    "\n",
    "# 5) Get a vanilla answer by directly prompting the LangChain LLM without retrieval\n",
    "vanilla_answer = llm.predict(query)\n",
    "\n",
    "# 6) Call OpenAI API directly with the same query and model for comparison\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "openai_answer = response.choices[0].message.content\n",
    "\n",
    "# 7) Print out all three answers for comparison\n",
    "print(\"ðŸ” Wikipedia RAG answer:\\n\", wiki_answer)\n",
    "print(\"\\nðŸ§  Vanilla LangChain LLM (3.5) answer:\\n\", vanilla_answer)\n",
    "print(\"\\nðŸ¤– Direct OpenAI API call (3.5 turbo) answer:\\n\", openai_answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9189c941-e8e4-4b77-9df1-3809841c13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2516d91-d097-4b04-b9f6-bbc1236e66a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia RAG -> Characters: 458, Words: 63\n",
      "LangChain LLM (3.5) -> Characters: 629, Words: 91\n",
      "OpenAI API (3.5 turbo) -> Characters: 629, Words: 91\n"
     ]
    }
   ],
   "source": [
    "answers = {\n",
    "    \"Wikipedia RAG\": \"Retrieval-augmented generation (RAG) is a technique that enhances large language models (LLMs) by allowing them to retrieve and incorporate new information from external sources before generating responses. This method helps LLMs access domain-specific or updated information that is not present in their original training data. By blending the LLM process with information retrieval, RAG helps LLMs provide more accurate and contextually relevant responses.\",\n",
    "    \"LangChain LLM (3.5)\": \"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\",\n",
    "    \"OpenAI API (3.5 turbo)\": \"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\"\n",
    "}\n",
    "\n",
    "for name, text in answers.items():\n",
    "    char_count = len(text)\n",
    "    word_count = len(text.split())\n",
    "    print(f\"{name} -> Characters: {char_count}, Words: {word_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "772c36b3-9cf0-4301-bd99-68e36d0ba917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wikipedia RAG keyword frequencies:\n",
      "  retrieval: 2\n",
      "  generation: 1\n",
      "  model: 0\n",
      "  information: 3\n",
      "  response: 0\n",
      "\n",
      "LangChain LLM (3.5) keyword frequencies:\n",
      "  retrieval: 3\n",
      "  generation: 4\n",
      "  model: 2\n",
      "  information: 1\n",
      "  response: 1\n",
      "\n",
      "OpenAI API (3.5 turbo) keyword frequencies:\n",
      "  retrieval: 3\n",
      "  generation: 4\n",
      "  model: 2\n",
      "  information: 1\n",
      "  response: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "answers = {\n",
    "    \"Wikipedia RAG\": \"Retrieval-augmented generation (RAG) is a technique that enhances large language models (LLMs) by allowing them to retrieve and incorporate new information from external sources before generating responses. This method helps LLMs access domain-specific or updated information that is not present in their original training data. By blending the LLM process with information retrieval, RAG helps LLMs provide more accurate and contextually relevant responses.\",\n",
    "    \"LangChain LLM (3.5)\": \"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\",\n",
    "    \"OpenAI API (3.5 turbo)\": \"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\"\n",
    "}\n",
    "\n",
    "keywords = [\"retrieval\", \"generation\", \"model\", \"information\", \"response\"]\n",
    "\n",
    "for name, text in answers.items():\n",
    "    # Convert text to lowercase and extract words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    counter = Counter(words)\n",
    "    \n",
    "    print(f\"\\n{name} keyword frequencies:\")\n",
    "    for kw in keywords:\n",
    "        print(f\"  {kw}: {counter[kw]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c15286c-6902-4a29-9aff-b5f0f730c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1 similarity: 0.1706\n",
      "Answer 2 similarity: 0.2777\n",
      "Answer 3 similarity: 0.2777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Reference sentence (ground truth)\n",
    "reference = [\"Retrieval-augmented generation (RAG) is a method that combines pre-trained sequence-to-sequence models with a retrieval component, enabling the model to condition its generation on documents retrieved from a large corpus, improving performance on knowledge-intensive NLP tasks.\"]\n",
    "\n",
    "# Three LLM answers to compare\n",
    "answers = [\n",
    "    \"\"\"Retrieval-augmented generation (RAG) is a technique that enhances large language models (LLMs) by allowing them to retrieve and incorporate new information from external sources before generating responses. This method helps LLMs access domain-specific or updated information that is not present in their original training data. By blending the LLM process with information retrieval, RAG helps LLMs provide more accurate and contextually relevant responses.\"\"\",\n",
    "    \"\"\"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\"\"\",\n",
    "    \"\"\"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\"\"\"\n",
    "]\n",
    "\n",
    "# Vectorize the reference and answers using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(reference + answers)\n",
    "\n",
    "# Extract the vector for the reference sentence\n",
    "ref_vec = tfidf_matrix[0]\n",
    "\n",
    "# Calculate cosine similarity between reference and each answer\n",
    "for i in range(1, len(answers)+1):\n",
    "    sim = cosine_similarity(ref_vec, tfidf_matrix[i])[0][0]\n",
    "    print(f\"Answer {i} similarity: {sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3902897c-21bd-42e6-86b8-8c8f0d479ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1 similarity: 0.8756\n",
      "Answer 2 similarity: 0.7124\n",
      "Answer 3 similarity: 0.7124\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1) Load the pre-trained sentence embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2) Reference sentence (from the paper)\n",
    "reference = \"Retrieval-augmented generation (RAG) is a method that combines pre-trained sequence-to-sequence models with a retrieval component, enabling the model to condition its generation on documents retrieved from a large corpus, improving performance on knowledge-intensive NLP tasks.\"\n",
    "\n",
    "# 3) Candidate answers to compare\n",
    "answers = [\n",
    "    \"Retrieval-augmented generation (RAG) is a technique that enhances large language models (LLMs) by allowing them to retrieve and incorporate new information from external sources before generating responses. This method helps LLMs access domain-specific or updated information that is not present in their original training data. By blending the LLM process with information retrieval, RAG helps LLMs provide more accurate and contextually relevant responses.\",\n",
    "    \"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\",\n",
    "    \"Retrieval-augmented generation is a type of natural language processing model that combines elements of both retrieval-based and generative models. In this approach, a retrieval system is used to retrieve relevant information from a large database or knowledge base, which is then used to generate a response or output. This allows the model to incorporate external knowledge and context into its generation process, leading to more accurate and contextually relevant outputs. This approach has been shown to improve the performance of language generation tasks such as question answering, dialogue generation, and summarization.\"\n",
    "]\n",
    "\n",
    "# 4) Encode the reference and answers into embeddings\n",
    "ref_emb = model.encode(reference, convert_to_tensor=True)\n",
    "answer_embs = model.encode(answers, convert_to_tensor=True)\n",
    "\n",
    "# 5) Compute cosine similarity scores between reference and each answer\n",
    "cos_scores = util.cos_sim(ref_emb, answer_embs)[0]\n",
    "\n",
    "# 6) Print similarity results\n",
    "for i, score in enumerate(cos_scores):\n",
    "    print(f\"Answer {i+1} similarity: {score.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a4d8691-b5b3-4b82-b76c-2e8a0bf1b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed830112-7861-4c2c-badb-b18cddb838e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "answers = [\"Wikipedia RAG\", \"LangChain LLM (3.5)\", \"OpenAI API (3.5 turbo)\"]\n",
    "similarities = [0.8756, 0.7124, 0.7124]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(answers, similarities, color=['#4c72b0', '#55a868', '#c44e52'])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Similarity to Reference (0~1)\")\n",
    "plt.title(\"Answer Similarity to RAG Paper Reference\")\n",
    "\n",
    "# Add value labels above the bars\n",
    "for bar, sim in zip(bars, similarities):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.02, f\"{sim:.4f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0dbc1a0-d678-4c98-ae00-a5a2af35e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b24c9ac-0e30-4f33-a953-1acde1bbae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:\n",
      "  BLEU score: 0.0683\n",
      "  METEOR score: 0.1984\n",
      "  ROUGE-1: 0.3429\n",
      "  ROUGE-2: 0.0971\n",
      "  ROUGE-L: 0.2095\n",
      "\n",
      "Answer 2:\n",
      "  BLEU score: 0.0000\n",
      "  METEOR score: 0.2814\n",
      "  ROUGE-1: 0.3609\n",
      "  ROUGE-2: 0.1527\n",
      "  ROUGE-L: 0.2707\n",
      "\n",
      "Answer 3:\n",
      "  BLEU score: 0.0000\n",
      "  METEOR score: 0.2814\n",
      "  ROUGE-1: 0.3609\n",
      "  ROUGE-2: 0.1527\n",
      "  ROUGE-L: 0.2707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicahong/.pyenv/versions/3.11.11/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "for i, answer in enumerate(answers, 1):\n",
    "    print(f\"Answer {i}:\")\n",
    "\n",
    "    ref_tokens = reference.lower().split()\n",
    "    answer_tokens = answer.lower().split()\n",
    "\n",
    "    # BLEU score\n",
    "    bleu = sentence_bleu([ref_tokens], answer_tokens)\n",
    "    print(f\"  BLEU score: {bleu:.4f}\")\n",
    "\n",
    "    # METEOR score (referenceëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)\n",
    "    meteor = meteor_score([ref_tokens], answer_tokens)\n",
    "    print(f\"  METEOR score: {meteor:.4f}\")\n",
    "\n",
    "    # ROUGE score (string í˜•íƒœ)\n",
    "    rouge_scores = scorer.score(reference, answer)\n",
    "    print(f\"  ROUGE-1: {rouge_scores['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"  ROUGE-2: {rouge_scores['rouge2'].fmeasure:.4f}\")\n",
    "    print(f\"  ROUGE-L: {rouge_scores['rougeL'].fmeasure:.4f}\")\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f4ae0-9931-4343-a9c1-c2be90c49952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (pyenv)",
   "language": "python",
   "name": "pyenv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
