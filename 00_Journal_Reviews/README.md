# ðŸ“š Journal Reviews

This folder contains summaries and key points from academic papers reviewed as part of the NLP study.  
Each entry links to the paper (if available) and the corresponding PDF or notes in this repository.

---

## ðŸ“„ Paper List

### 1. [BERT.pdf](./BERT.pdf)  
**Title:** BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding  
- Introduced a bidirectional transformer-based pre-training model for language understanding.  
- Achieved state-of-the-art results on multiple NLP tasks.  
- **[Paper link](https://arxiv.org/abs/1810.04805)**

---

### 2. [DistilBERT.pdf](./DistilBERT.pdf)  
**Title:** DistilBERT: A distilled version of BERT â€” smaller, faster, cheaper, and lighter  
- Retains 97% of BERT's language understanding while being 40% smaller and 60% faster.  
- Suitable for resource-constrained real-world applications.  
- **[Paper link](https://arxiv.org/abs/1910.01108)**

---

### 3. [ULMFiT.pdf](./ULMFiT.pdf)  
**Title:** ULMFiT: Universal Language Model Fine-tuning for Text Classification  
- Proposed a fine-tuning method for pre-trained language models in text classification.  
- Particularly effective in low-resource and non-English datasets.  
- **[Paper link](https://arxiv.org/abs/1801.06146)**

---

### 4. [LARGE LANGUAGE MODELS FOR TEXT CLASSIFICATION â€” CASE STUDY AND COMPREHENSIVE REVIEW.pdf](./LARGE%20LANGUAGE%20MODELS%20FOR%20TEXT%20CLASSIFICATION-%20CASE%20STUDY%20AND%20COMPREHENSIVE%20REVIEW.pdf)  
- Benchmarks LLMs (LLaMA3, GPT-4, Mistral) and ML models (SVM, Naive Bayes) on binary/multiclass classification tasks.  
- Finds RoBERTa and LLaMA3 70B perform best; traditional models still viable for simpler tasks.  
- Emphasizes the importance of prompt engineering (Chain-of-Thought, Role Prompting, No-Anchor).  

---

### 5. [GPT_Clustering_2024.pdf](./GPT_Clustering_2024/GPT_Clustering_2024.pdf)  
**Title:** GPT Clustering for Large-Scale Text Data  
- Reviews clustering techniques leveraging GPT models for text grouping and semantic understanding.  
- Explores methods to combine embeddings with GPT for efficient clustering.  
- Discusses application scenarios such as document organization and topic modeling.  
- **[Paper link](https://arxiv.org/pdf/2403.15112)**

---

### 6. [Evaluation (DOUBLE-BENCH)](./Evaluation/README.md)  
**Title:** Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?  
- Introduces DOUBLE-BENCH, a large-scale multilingual & multimodal benchmark for Document RAG.  
- Provides fine-grained evaluation of RAG pipeline components (retrieval, selection, reasoning, generation).  
- Addresses data contamination and supports multiple document types.  
- **[Paper link](https://arxiv.org/abs/2508.03644)**

---

More papers and summaries will be added here as the study progresses.


