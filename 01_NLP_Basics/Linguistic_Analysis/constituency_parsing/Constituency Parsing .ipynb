{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1236f44-bf43-4dd6-8c3b-0e45029b2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicahong/.pyenv/versions/3.11.11/lib/python3.11/site-packages/nltk/metrics/association.py:26: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  from scipy.stats import fisher_exact\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5f6dcb-1b07-4556-bb54-78d927c81db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"She enjoys reading scientific papers on natural language processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b50d883-e6a3-4e96-b345-4a05fa2c38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jessicahong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jessicahong/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/jessicahong/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/jessicahong/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources for grammar and parsing\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83a046e1-9ee7-40ad-a7d4-dbf244237b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentence into words\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Perform POS tagging on the tokenized words\n",
    "pos_tags = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9c65522-bb64-448f-a408-99f767971c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple grammar for noun phrases (NP)\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\" #ã„±Regexp Grammer\n",
    "\n",
    "# Create a RegexpParser with the defined grammar\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "# Parse the POS-tagged sentence to identify noun phrases\n",
    "result = cp.parse(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b7ddbe-d57e-401b-a71c-fe371a11ce32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 S                                                        \n",
      "    _____________________________________________|_________________________________________________        \n",
      "   |        |           |            |           |        |    |              NP                   NP     \n",
      "   |        |           |            |           |        |    |       _______|_______             |       \n",
      "She/PRP enjoys/VBZ reading/VBG scientific/JJ papers/NNS on/IN ./. natural/JJ     language/NN processing/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d257d7-4575-42b8-9d52-241a88df9018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun Phrase: natural language\n",
      "Noun Phrase: processing\n"
     ]
    }
   ],
   "source": [
    "#iterate over all subtrees in the parsed result.\n",
    "#Filter subtrees to select only those labeled as 'NP'\n",
    "\n",
    "for subtree in result.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "\n",
    "    #For each noun phrase subtree, extract the leaf nodes (words and their POS tags).\n",
    "    #Join the words together to form the complete noun phrase.\n",
    "    print('Noun Phrase:', ' '.join(word for word, pos in subtree.leaves()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d668f7-ac06-4f1b-84ca-429c88d24c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (pyenv)",
   "language": "python",
   "name": "pyenv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
