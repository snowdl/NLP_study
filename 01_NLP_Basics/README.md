# üìò 01_NLP_Basics

This folder introduces **fundamental NLP concepts and preprocessing techniques**.  
It serves as the **starting point for beginners**, covering essential text processing, encoding methods, and simple models that build intuition for more advanced concepts in `02_NLP_Concepts`.

---

## üìÇ Contents

| File/Folder               | Description |
|----------------------------|-------------|
| `nlp-basic.ipynb`          | Overview notebook introducing core NLP foundations. |
| `nlp_basic_01.ipynb`       | Additional examples of basic preprocessing and text handling. |
| `integer Encoding.ipynb`   | Demonstrates integer encoding for text representation. |
| `Sigmoid Function.ipynb`   | Mathematical explanation and visualization of the sigmoid function. |
| `Lemmatization_Stemming/`  | Comparing stemming vs. lemmatization with examples. |
| `pattern_matching_analysis/` | Regex and rule-based text pattern matching. |
| `spacy_text_classification/` | Simple text classification using spaCy pipelines. |
| `vector_semantics/`        | Intro to vector space models and semantic similarity. |

---

## üß† Concepts Covered

- Tokenization & text normalization  
- Integer encoding & simple embeddings  
- Stemming & Lemmatization  
- Regex & rule-based pattern matching  
- Word embeddings (intro level) & semantic similarity  
- Basic classification with spaCy  
- Sigmoid function for logistic models  

---

## üìå Notes

- These notebooks focus on **hands-on, beginner-friendly implementations**.  
- Designed for learners transitioning from general data science into NLP.  
- For **deeper embeddings, neural architectures, and Transformer-based methods**, see [`02_NLP_Concepts`](../02_NLP_Concepts).  
- All notebooks use relative paths for portability and are written in English.

---

‚úÖ In short:  
- **01_NLP_Basics** = ‚ÄúNLP 101‚Äù ‚Üí preprocessing, encodings, simple models  
- **02_NLP_Concepts** = ‚ÄúNLP 201+‚Äù ‚Üí embeddings, attention, neural architectures, Transformer family  
