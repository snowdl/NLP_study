{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c09d803-2ade-42fa-8069-5c43d8415c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 CHUNKS_PATH: /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR/outputs/chunks.jsonl\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# A0. Set base path\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path.home() / \"NLP_study/09_Mini_Project/13_RAPTOR\"\n",
    "CHUNKS_PATH = BASE / \"outputs/chunks.jsonl\"\n",
    "#print(\"📂 CHUNKS_PATH:\", CHUNKS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f74a62e-86cd-4b1b-beff-adcf738b2396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ exists? True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# A1. Check if file exists\n",
    "# ============================================\n",
    "import os\n",
    "print(\"✅ exists?\", os.path.exists(CHUNKS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd64e32-16b0-4edc-89dc-487e60bdc70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ #chunks: 227\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl(path):\n",
    "    items = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "chunks_raw = read_jsonl(CHUNKS_PATH)\n",
    "print(\"✅ #chunks:\", len(chunks_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4ebc15-ba73-43fe-a6c2-5d396658a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ #chunks: 227\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# A2. Read JSONL file\n",
    "# - Each line is one JSON object (one chunk)\n",
    "# ============================================\n",
    "import json\n",
    "\n",
    "def read_jsonl(path):\n",
    "    items = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "chunks_raw = read_jsonl(CHUNKS_PATH)\n",
    "print(\"✅ #chunks:\", len(chunks_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741704d7-619f-4d6f-8739-e4eb798a2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# A3. Tokenizer\n",
    "# - Convert string to lowercase\n",
    "# - Extract only alphanumeric tokens (a–z, 0–9)\n",
    "# - Return as a Python set (unique tokens)\n",
    "# ============================================\n",
    "import re\n",
    "\n",
    "def tokenize(s: str):\n",
    "    return set(re.findall(r\"[a-z0-9]+\", s.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3148255-fc3c-4461-a502-f466cbcad29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample text preview: M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very m ...\n",
      " Tokens(sample): ['a', 'about', 'all', 'also', 'although', 'amount', 'and', 'another', 'any', 'anyone', 'anything', 'anywhere', 'arrived', 'as', 'at']\n"
     ]
    }
   ],
   "source": [
    "# --- Test with one sample chunk ---\n",
    "# Assuming you already loaded chunks_raw from chunks.jsonl:\n",
    "sample = chunks_raw[0]                     # take first record\n",
    "sample_text = get_chunk_text(sample)       # extract text field\n",
    "tokens = tokenize(sample_text)             # tokenize it\n",
    "\n",
    "print(\" Sample text preview:\", sample_text[:120], \"...\")\n",
    "print(\" Tokens(sample):\", list(sorted(tokens))[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "301fed95-f0d6-4b75-8f40-dda43c7014d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# A4. Overlap score\n",
    "# - Count how many tokens are shared\n",
    "#   between query and text\n",
    "# ============================================\n",
    "def overlap_score(query_tokens, text_tokens):\n",
    "    return len(query_tokens & text_tokens)   # set intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1ca9cab-f45f-4503-8d05-9cb0e641bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query tokens: {'events', 'strange', 'privet', 'drive'}\n",
      "Text tokens (sample, first 15): ['a', 'about', 'all', 'also', 'although', 'amount', 'and', 'another', 'any', 'anyone', 'anything', 'anywhere', 'arrived', 'as', 'at']\n",
      "Overlap score: 3\n"
     ]
    }
   ],
   "source": [
    "# --- Quick test with sample chunk ---\n",
    "qt = tokenize(\"Privet Drive strange events?\")    # query tokens\n",
    "tt = tokenize(get_chunk_text(sample))            # text tokens from sample chunk\n",
    "score = overlap_score(qt, tt)\n",
    "\n",
    "print(\"Query tokens:\", qt)\n",
    "print(\"Text tokens (sample, first 15):\", list(sorted(tt))[:15])\n",
    "print(\"Overlap score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc12da4a-642c-413b-abdb-960a9bc209bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# A5. Keyword Overlap Search Function\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e515b0b-89a1-40db-8d9d-027e0024476e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Search chunks using a simple keyword overlap score.\\n\\n    Steps:\\n    1. Tokenize the query.\\n    2. For each chunk:\\n       - Extract ID and text.\\n       - Tokenize the text.\\n       - Compute overlap score with query tokens.\\n    3. Keep only chunks with score > 0.\\n    4. Sort by score (descending).\\n    5. Return top-k results.\\n\\n    Args:\\n        query (str): User query text.\\n        chunks_raw (list): Raw list of chunk dicts.\\n        topk (int): How many results to return.\\n\\n    Returns:\\n        List of tuples (score, chunk_id, chunk_text).\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Search chunks using a simple keyword overlap score.\n",
    "\n",
    "    Steps:\n",
    "    1. Tokenize the query.\n",
    "    2. For each chunk:\n",
    "       - Extract ID and text.\n",
    "       - Tokenize the text.\n",
    "       - Compute overlap score with query tokens.\n",
    "    3. Keep only chunks with score > 0.\n",
    "    4. Sort by score (descending).\n",
    "    5. Return top-k results.\n",
    "\n",
    "    Args:\n",
    "        query (str): User query text.\n",
    "        chunks_raw (list): Raw list of chunk dicts.\n",
    "        topk (int): How many results to return.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples (score, chunk_id, chunk_text).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d292def5-f966-4f01-8f7b-c006ced2e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chunks_keyword_overlap(query: str, chunks_raw, topk: int = 5):\n",
    " \n",
    "    q_tokens = tokenize(query)          # tokenize query once\n",
    "    scored = []\n",
    "\n",
    "    for rec in chunks_raw:\n",
    "        cid = get_chunk_id(rec)         # extract chunk id\n",
    "        text = get_chunk_text(rec)      # extract chunk text\n",
    "        if not cid or not text:         # skip invalid chunks\n",
    "            continue\n",
    "\n",
    "        s = overlap_score(q_tokens, tokenize(text))\n",
    "        if s > 0:                       # keep only if overlap exists\n",
    "            scored.append((s, cid, text))\n",
    "\n",
    "    # sort results by score, highest first\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return scored[:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de2c3664-dcf2-4c70-a05d-cdc12c726c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. C0001 | score=5\n",
      "    M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very m...\n",
      "2. C0002 | score=4\n",
      "    Dursley on the cheek, and tried to kiss Dudley good-bye but missed, because Dudley was now having a tantrum and throwing...\n",
      "3. C0006 | score=4\n",
      "    Dursley wondered whether he dared tell her he’d heard the name “Potter.” He decided he didn’t dare. Instead he said, as ...\n"
     ]
    }
   ],
   "source": [
    "query = \"What strange events happened on Privet Drive?\"\n",
    "results = search_chunks_keyword_overlap(query, chunks_raw, topk=3)\n",
    "\n",
    "for rank, (score, cid, text) in enumerate(results, 1):\n",
    "    preview = text[:120] + (\"...\" if len(text) > 120 else \"\")\n",
    "    print(f\"{rank}. {cid} | score={score}\")\n",
    "    print(\"   \", preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e451759-b4e4-4fb8-ac40-2b97ba47d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# A6.Simple Answer Generator\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6873cd4e-a926-4c4f-80f4-1a06650d2ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Generate a simple answer by concatenating the top retrieved chunks.\\n\\n    Args:\\n        results (list): Search results in the form (score, chunk_id, chunk_text).\\n        max_chars (int): Maximum number of characters in the final answer.\\n\\n    Steps:\\n        1. Start with an empty buffer.\\n        2. Iterate through results in order.\\n        3. Take as much text as possible without exceeding max_chars.\\n        4. Concatenate all collected snippets.\\n        5. Return final string (or fallback message if empty).\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Generate a simple answer by concatenating the top retrieved chunks.\n",
    "\n",
    "    Args:\n",
    "        results (list): Search results in the form (score, chunk_id, chunk_text).\n",
    "        max_chars (int): Maximum number of characters in the final answer.\n",
    "\n",
    "    Steps:\n",
    "        1. Start with an empty buffer.\n",
    "        2. Iterate through results in order.\n",
    "        3. Take as much text as possible without exceeding max_chars.\n",
    "        4. Concatenate all collected snippets.\n",
    "        5. Return final string (or fallback message if empty).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dc94451-e835-4551-835d-1f50d039f3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Answer:\n",
      "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spy\n"
     ]
    }
   ],
   "source": [
    "def simple_answer(results, max_chars=600):\n",
    "    buf, used = [], 0\n",
    "    for score, cid, txt in results:\n",
    "        if used >= max_chars:\n",
    "            break\n",
    "        take = max_chars - used\n",
    "        snippet = txt[:take]\n",
    "        buf.append(snippet)\n",
    "        used += len(snippet)\n",
    "    return \" \".join(buf) if buf else \"No evidence found.\"\n",
    "\n",
    "print(\"\\n Answer:\")\n",
    "print(simple_answer(hits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c854ee7-6b75-4855-a41c-40b54a31e531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
