{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8347bd4e-3295-4177-be21-240abb7d7f27",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '→' (U+2192) (1255337421.py, line 19)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m배치 단위 추론 → y_pred_bert 얻기\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '→' (U+2192)\n"
     ]
    }
   ],
   "source": [
    "error_analysis.ipynb 기본 뼈대\n",
    "\n",
    "STEP 0. 모델 로드\n",
    "\n",
    "로컬에서 저장된 DistilBERT (./out_distilbert/best_model) 불러오기\n",
    "\n",
    "없다면 가장 최근 체크포인트에서 로드\n",
    "\n",
    "STEP 1. 데이터 준비\n",
    "\n",
    "BANKING77 불러오기 (load_dataset(\"PolyAI/banking77\"))\n",
    "\n",
    "label_names, X_test, y_test 준비\n",
    "\n",
    "STEP 2. DistilBERT 예측\n",
    "\n",
    "tokenizer로 X_test 토큰화\n",
    "\n",
    "배치 단위 추론 → y_pred_bert 얻기\n",
    "\n",
    "STEP 3. (선택) Word+Char TF-IDF + SVM baseline 예측\n",
    "\n",
    "y_pred_svm 생성\n",
    "\n",
    "STEP 4. 분석 파트\n",
    "\n",
    "Confusion Matrix 시각화\n",
    "\n",
    "Misclassified sample 뽑기 (y_true != y_pred)\n",
    "\n",
    "혼동 많이 된 intent 쌍 카운트\n",
    "\n",
    "잘못 분류된 예시 출력\n",
    "\n",
    "(선택) 두 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a09714-5676-4a11-a0d8-ad3d074eed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d10dbf2-680d-48be-bf04-48d26f713227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 우선 best_model 시도\n",
    "best_dir = \"./out_distilbert/best_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012566a1-21bd-4f30-b4cc-66d5e9be9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_model(pref_dir):\n",
    "    tok   = AutoTokenizer.from_pretrained(pref_dir, local_files_only=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pref_dir, local_files_only=True)\n",
    "    return tok, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93711283-1456-49bf-8205-6efb44665b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tok = model = None\n",
    "if os.path.isdir(best_dir):\n",
    "    try:\n",
    "        tok, model = load_local_model(best_dir)\n",
    "        print(\"Loaded local best model from:\", best_dir)\n",
    "    except Exception as e:\n",
    "        print(\"Best model found but failed to load:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597654d-626a-4572-a61b-0bd42e58c435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
