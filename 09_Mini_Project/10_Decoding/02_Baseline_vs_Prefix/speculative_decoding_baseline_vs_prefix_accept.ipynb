{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57cd7b58-7ca5-4af0-a066-cee687245acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports & seed\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "random.seed(42)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dd996b7-3183-4154-9f1a-39bbe32a5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tiny toy corpus\n",
    "corpus = \"the wolf ran into the forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3629d2f0-69cc-4e01-8481-3e8a5fce07b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'wolf', 'ran', 'into', 'the', 'forest']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization (very simple: lowercase + split on whitespace)\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return text.lower().split()\n",
    "\n",
    "tokens = tokenize(corpus)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d1515de-8b92-478b-9779-f80455ae8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유틸: 컨텍스트 안전 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "452293b8-1e39-4485-a42f-f9ee1e900299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: ensure we have >= 2 tokens for trigram-based backoff to work\n",
    "def ensure_two_token_context(seq: List[str]) -> List[str]:\n",
    "    if len(seq) < 2:\n",
    "        return [seq[-1], seq[-1]]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9be2056-9462-4b45-9935-c804d4ac34ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13710f8b-6519-414d-9503-361599830e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build unigram table\n",
    "def build_unigram(tokens: List[str]) -> Counter:\n",
    "    return Counter(tokens)\n",
    "\n",
    "# Initialize empty bigram/trigram structures\n",
    "def init_bigram() -> Dict[str, Counter]:\n",
    "    return defaultdict(Counter)\n",
    "\n",
    "def init_trigram() -> Dict[Tuple[str, str], Counter]:\n",
    "    return defaultdict(Counter)\n",
    "\n",
    "# Fill bigram counts\n",
    "def fill_bigram(bi: Dict[str, Counter], tokens: List[str]) -> None:\n",
    "    for a, b in zip(tokens, tokens[1:]):\n",
    "        bi[a][b] += 1\n",
    "\n",
    "# Fill trigram counts\n",
    "def fill_trigram(tri: Dict[Tuple[str, str], Counter], tokens: List[str]) -> None:\n",
    "    for a, b, c in zip(tokens, tokens[1:], tokens[2:]):\n",
    "        tri[(a, b)][c] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ebb1a7a-d116-437b-87b9-0e3f72fdd8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram   cration n execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "780b19e0-e4eb-42ee-b7e3-894595a4ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = build_unigram(tokens)\n",
    "bi  = init_bigram()\n",
    "tri = init_trigram()\n",
    "\n",
    "fill_bigram(bi, tokens)\n",
    "fill_trigram(tri, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d6b7486-b5eb-4788-9f20-75940beecf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eecfa9c9-0072-4deb-9649-86682e9bef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unigrams ===\n",
      "'the': 2\n",
      "'wolf': 1\n",
      "'ran': 1\n",
      "'into': 1\n",
      "'forest': 1\n",
      "\n",
      "=== Bigrams ===\n",
      "('the' -> 'wolf'): 1\n",
      "('the' -> 'forest'): 1\n",
      "('wolf' -> 'ran'): 1\n",
      "('ran' -> 'into'): 1\n",
      "('into' -> 'the'): 1\n",
      "\n",
      "=== Trigrams ===\n",
      "(('the', 'wolf') -> 'ran'): 1\n",
      "(('wolf', 'ran') -> 'into'): 1\n",
      "(('ran', 'into') -> 'the'): 1\n",
      "(('into', 'the') -> 'forest'): 1\n"
     ]
    }
   ],
   "source": [
    "def print_unigrams(uni: Counter) -> None:\n",
    "    print(\"=== Unigrams ===\")\n",
    "    for w, c in uni.items():\n",
    "        print(f\"{w!r}: {c}\")\n",
    "\n",
    "def print_bigrams(bi: Dict[str, Counter]) -> None:\n",
    "    print(\"\\n=== Bigrams ===\")\n",
    "    for prev, counter in bi.items():\n",
    "        for nxt, c in counter.items():\n",
    "            print(f\"({prev!r} -> {nxt!r}): {c}\")\n",
    "\n",
    "def print_trigrams(tri: Dict[Tuple[str, str], Counter]) -> None:\n",
    "    print(\"\\n=== Trigrams ===\")\n",
    "    for (w1, w2), counter in tri.items():\n",
    "        for nxt, c in counter.items():\n",
    "            print(f\"(({w1!r}, {w2!r}) -> {nxt!r}): {c}\")\n",
    "\n",
    "print_unigrams(uni)\n",
    "print_bigrams(bi)\n",
    "print_trigrams(tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc33b2b0-3f64-4066-9483-5e11083f09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backoff: try trigram -> else bigram -> else unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c01bbef-c6dd-4388-8a18-4f4b41e8315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(prev2: str, prev1: str) -> Counter:\n",
    "    d3 = tri.get((prev2, prev1))\n",
    "    if d3:\n",
    "        return d3\n",
    "    d2 = bi.get(prev1)\n",
    "    if d2:\n",
    "        return d2\n",
    "    return uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f7f3901-3d85-42f5-b888-250216129b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#샘플링 & 최빈값 선택(분리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da3270d1-b90d-4303-8abc-08610d70e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic sampling with temperature\n",
    "def sample_from_counts(dist: Counter, T: float = 1.0) -> str:\n",
    "    items  = list(dist.items())\n",
    "    toks   = [t for t, _ in items]\n",
    "    cnts   = [c for _, c in items]\n",
    "    weights = [(c if c > 0 else 1e-9) ** (1.0 / T) for c in cnts]\n",
    "    return random.choices(toks, weights=weights, k=1)[0]\n",
    "\n",
    "# Deterministic (argmax)\n",
    "def argmax_from_counts(dist: Counter) -> str:\n",
    "    return max(dist.items(), key=lambda kv: kv[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4471830-0ac5-4a6a-863d-8ea070e6dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 — 베이스라인(비교용): 한 토큰씩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9e4a382-93f3-4b79-a439-c5eb243af7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_baseline(prompt_tokens: List[str], steps: int = 5, T: float = 0.7) -> List[str]:\n",
    "    \"\"\"\n",
    "    Baseline: use backoff n-gram to sample next token step by step.\n",
    "    \"\"\"\n",
    "    out = list(prompt_tokens)\n",
    "    out = ensure_two_token_context(out)\n",
    "    prev2, prev1 = out[-2], out[-1]\n",
    "\n",
    "    for _ in range(steps):\n",
    "        dist = get_counts(prev2, prev1)\n",
    "        nxt  = sample_from_counts(dist, T)\n",
    "        out.append(nxt)\n",
    "        prev2, prev1 = prev1, nxt\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0909703-0c2b-49e2-99a4-2a69a3a74342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#셀 11 — #4 스페큘레이티브(초극단 분해)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3602d70e-e642-4a81-8485-e00495804ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Drafter (small model) ultra-split ----------\n",
    "\n",
    "def get_drafter_dist(prev1: str) -> Counter:\n",
    "    \"\"\"Return small-model dist: bigram if available, else unigram.\"\"\"\n",
    "    return bi.get(prev1, uni)\n",
    "\n",
    "def sample_drafter_token_from_dist(dist: Counter, T_draft: float) -> str:\n",
    "    \"\"\"Sample one token given a small-model distribution.\"\"\"\n",
    "    return sample_from_counts(dist, T_draft)\n",
    "\n",
    "def draft_one(prev1: str, T_draft: float) -> str:\n",
    "    \"\"\"Get drafter dist, then sample one.\"\"\"\n",
    "    dist = get_drafter_dist(prev1)\n",
    "    return sample_drafter_token_from_dist(dist, T_draft)\n",
    "\n",
    "def advance_context(prev2: str, prev1: str, new_token: str) -> tuple:\n",
    "    \"\"\"Advance (prev2, prev1) window with a new_token.\"\"\"\n",
    "    return prev1, new_token\n",
    "\n",
    "def make_draft_step(prev2: str, prev1: str, T_draft: float) -> tuple:\n",
    "    \"\"\"One drafting step: produce token and advanced context.\"\"\"\n",
    "    t = draft_one(prev1, T_draft)\n",
    "    new_prev2, new_prev1 = advance_context(prev2, prev1, t)\n",
    "    return t, new_prev2, new_prev1\n",
    "\n",
    "def build_draft(context: list, k: int, T_draft: float) -> tuple:\n",
    "    \"\"\"\n",
    "    Return:\n",
    "      draft_tokens: [t1, ...]\n",
    "      draft_trace : [(prev2, prev1, t), ...] before advancing\n",
    "    \"\"\"\n",
    "    prev2, prev1 = context[-2], context[-1]\n",
    "    draft, trace = [], []\n",
    "    for _ in range(k):\n",
    "        t, prev2, prev1 = make_draft_step(prev2, prev1, T_draft)\n",
    "        trace.append((context[-2] if not draft else draft[-1],   # 읽기 쉬운 버전 (단순표시용)\n",
    "                      context[-1] if not draft else t,           # 정확 추적 원하면 아래 주석 참고\n",
    "                      t))\n",
    "        # 정확한 컨텍스트 로그가 필요하면 위 2줄 대신:\n",
    "        # trace.append((prev2_before, prev1_before, t))  # make_draft_step 들어가기 전 값을 저장해야 함\n",
    "        draft.append(t)\n",
    "    return draft, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b577d77f-e517-4213-b123-0646b441e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Verifier (large model) ultra-split ----------\n",
    "\n",
    "def get_verifier_dist(prev2: str, prev1: str) -> Counter:\n",
    "    \"\"\"Large model backoff distribution.\"\"\"\n",
    "    return get_counts(prev2, prev1)\n",
    "\n",
    "def predict_verifier_token(prev2: str, prev1: str) -> str:\n",
    "    \"\"\"Argmax next token from large model.\"\"\"\n",
    "    dist = get_verifier_dist(prev2, prev1)\n",
    "    return argmax_from_counts(dist)\n",
    "\n",
    "def decide_accept(draft_token: str, verify_token: str) -> bool:\n",
    "    \"\"\"Return True if draft_token matches verify_token.\"\"\"\n",
    "    return draft_token == verify_token\n",
    "\n",
    "def make_verify_log_entry(prev2: str, prev1: str, draft_t: str, verify_t: str, ok: bool) -> tuple:\n",
    "    \"\"\"Pack one verification step into a tuple for logging.\"\"\"\n",
    "    return (prev2, prev1, draft_t, verify_t, ok)\n",
    "\n",
    "def apply_prefix_accept(accepted: list, prev2: str, prev1: str, chosen_token: str, ok: bool) -> tuple:\n",
    "    \"\"\"\n",
    "    Append chosen_token to accepted.\n",
    "    If ok=True, advance context; else keep context (caller will stop).\n",
    "    \"\"\"\n",
    "    accepted.append(chosen_token)\n",
    "    if ok:\n",
    "        return accepted, *advance_context(prev2, prev1, chosen_token)\n",
    "    else:\n",
    "        return accepted, prev2, prev1  # no advance on mismatch (stop afterwards)\n",
    "\n",
    "def verify_one_step(prev2: str, prev1: str, draft_t: str) -> tuple:\n",
    "    \"\"\"\n",
    "    One verification step:\n",
    "    Returns (chosen_token, ok_flag, verify_token).\n",
    "    \"\"\"\n",
    "    verify_t = predict_verifier_token(prev2, prev1)\n",
    "    ok = decide_accept(draft_t, verify_t)\n",
    "    chosen = draft_t if ok else verify_t\n",
    "    return chosen, ok, verify_t\n",
    "\n",
    "def prefix_accept_verify(context: list, draft: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Walk left->right; accept while ok; on first mismatch, replace & STOP.\n",
    "    Returns:\n",
    "      accepted_tokens\n",
    "      verify_log [(p2,p1,draft_t,verify_t,ok), ...]\n",
    "    \"\"\"\n",
    "    accepted, log = [], []\n",
    "    prev2, prev1 = context[-2], context[-1]\n",
    "\n",
    "    for draft_t in draft:\n",
    "        chosen, ok, verify_t = verify_one_step(prev2, prev1, draft_t)\n",
    "        log.append(make_verify_log_entry(prev2, prev1, draft_t, verify_t, ok))\n",
    "        accepted, prev2, prev1 = apply_prefix_accept(accepted, prev2, prev1, chosen, ok)\n",
    "        if not ok:\n",
    "            break\n",
    "    return accepted, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b5cdc30-b56d-4250-b0b0-e7a0fefcbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pretty-print (trace) ultra-split ----------\n",
    "\n",
    "def print_draft_trace(draft: list, draft_trace: list) -> None:\n",
    "    print(\"=== Draft stage (small model) ===\")\n",
    "    for i, (p2, p1, t) in enumerate(draft_trace, 1):\n",
    "        print(f\"[D{i}] prev2='{p2}' prev1='{p1}' -> draft='{t}'\")\n",
    "    if not draft_trace and draft:\n",
    "        print(\"(no trace recorded, draft =\", draft, \")\")\n",
    "\n",
    "def print_verify_log(verify_log: list) -> None:\n",
    "    print(\"\\n=== Verify stage (large model, prefix-accept) ===\")\n",
    "    for i, (p2, p1, t, v, ok) in enumerate(verify_log, 1):\n",
    "        status = \"ACCEPT\" if ok else \"REPLACE+STOP\"\n",
    "        print(f\"[V{i}] prev2='{p2}' prev1='{p1}'  draft='{t}'  verify='{v}'  ->  {status}\")\n",
    "\n",
    "def print_final(prompt_tokens: list, draft: list, accepted: list) -> None:\n",
    "    print(\"\\nDraft   :\", draft)\n",
    "    print(\"Accepted:\", accepted)\n",
    "    print(\"Final   :\", \" \".join(prompt_tokens + accepted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3532fc39-f250-4691-b715-17f025a67427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Orchestrator (speculative step) ----------\n",
    "\n",
    "def speculative_step(prompt_tokens: list, k: int = 5, T_draft: float = 0.9, trace: bool = True):\n",
    "    \"\"\"\n",
    "    Speculative (core): draft -> verify (prefix-accept)\n",
    "      - Drafter: bigram (else unigram) + higher T for diversity\n",
    "      - Verifier: trigram->bigram->unigram + argmax\n",
    "      - Rule: first mismatch => replace & STOP\n",
    "    Returns: (draft, accepted, final_sequence)\n",
    "    \"\"\"\n",
    "    context = ensure_two_token_context(list(prompt_tokens))\n",
    "\n",
    "    # 1) Build draft\n",
    "    draft, draft_trace = build_draft(context, k=k, T_draft=T_draft)\n",
    "\n",
    "    # 2) Verify with prefix-accept\n",
    "    accepted, verify_log = prefix_accept_verify(context, draft)\n",
    "\n",
    "    # 3) Optional trace\n",
    "    if trace:\n",
    "        print_draft_trace(draft, draft_trace)\n",
    "        print_verify_log(verify_log)\n",
    "        print_final(prompt_tokens, draft, accepted)\n",
    "\n",
    "    return draft, accepted, prompt_tokens + accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d3499-6959-40e8-af2b-4583f42e98e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4231a7-f3ed-4afe-a99c-5c665d2c8900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176d0c22-aeb2-4ad8-a4f5-dcad204b3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"the\", \"wolf\", \"ran\"]\n",
    "\n",
    "print(\"---- Baseline (T=0.7), next 5 tokens ----\")\n",
    "print(\"Baseline:\", \" \".join(generate_baseline(prompt, steps=5, T=0.7)))\n",
    "\n",
    "print(\"\\n---- Speculative (k=5, T_draft=0.9) ----\")\n",
    "_ = speculative_step(prompt, k=5, T_draft=0.9, trace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38585445-c9f6-40c7-92ba-c470d0ea9882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
