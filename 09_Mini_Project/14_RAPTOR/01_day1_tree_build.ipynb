{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dd37d194-9aab-4f76-96cd-7f9d18c3ac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n BASE = 13_RAPTOR/\\n ├── DATA   → 13_RAPTOR/data\\n │    └── harry_potter.txt   (원본 문서)\\n │\\n ├── SRC    → 13_RAPTOR/src\\n │    ├── chunking.py\\n │    ├── summarize_chunks.py\\n │    └── build_tree.py      (코드 모듈들)\\n │\\n └── OUT    → 13_RAPTOR/outputs\\n      ├── chunks.jsonl            (Step 1 결과: 문서 → 청크)\\n      ├── chunk_summaries.jsonl   (Step 2 결과: 청크 → 요약)\\n      ├── tree_nodes.jsonl        (Step 3 결과: 트리 구조 노드)\\n      └── tree_root.json          (Step 3 결과: 최종 루트 요약)\\n\\n'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " BASE = 13_RAPTOR/\n",
    " ├── DATA   → 13_RAPTOR/data\n",
    " │    └── harry_potter.txt   (원본 문서)\n",
    " │\n",
    " ├── SRC    → 13_RAPTOR/src\n",
    " │    ├── chunking.py\n",
    " │    ├── summarize_chunks.py\n",
    " │    └── build_tree.py      (코드 모듈들)\n",
    " │\n",
    " └── OUT    → 13_RAPTOR/outputs\n",
    "      ├── chunks.jsonl            (Step 1 결과: 문서 → 청크)\n",
    "      ├── chunk_summaries.jsonl   (Step 2 결과: 청크 → 요약)\n",
    "      ├── tree_nodes.jsonl        (Step 3 결과: 트리 구조 노드)\n",
    "      └── tree_root.json          (Step 3 결과: 최종 루트 요약)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f426e557-4b80-4320-b910-421b7494e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentencepiece tokenizers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4fec32f3-cac1-4ba0-a2fa-2fb22be934f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0. 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "77b595d9-8500-489c-95de-4783f2541a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "00afaf3c-e89e-407e-835a-e51ebbf3e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 노트북이 13_RAPTOR 안에서 열려 있으니, CWD 기준으로 고정\n",
    "BASE = Path.cwd()                 # /.../09_Mini_Project/13_RAPTOR\n",
    "DATA = BASE / \"data\"\n",
    "OUT  = BASE / \"outputs\"\n",
    "SRC  = BASE / \"src\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8480c67c-ddae-48b6-be1d-5de75a2689f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR\n",
      "DATA: /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR/data\n",
      "OUT : /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR/outputs\n"
     ]
    }
   ],
   "source": [
    "print(\"BASE:\", BASE)\n",
    "print(\"DATA:\", DATA)\n",
    "print(\"OUT :\", OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e66f6a4d-abc7-457e-b5cd-3759ade35795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "86e3f1a8-ac26-48a6-871d-f9b767c64974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 문장 분리 함수 ===\n",
    "def split_sentences(text: str):\n",
    "    \"\"\"간단한 문장 단위 분리 (마침표, 물음표, 느낌표 기준)\"\"\"\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s for s in sents if s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "531ee492-14df-454d-b70f-352212702544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 청크 생성 함수 ===\n",
    "def chunk_by_sentences(sents, max_chars=2000):\n",
    "    \"\"\"문장을 이어 붙이다가 max_chars 넘으면 새 청크 시작\"\"\"\n",
    "    chunks, cur, cur_len = [], [], 0\n",
    "    for s in sents:\n",
    "        if cur_len + len(s) > max_chars and cur:\n",
    "            chunks.append(\" \".join(cur))\n",
    "            cur, cur_len = [], 0\n",
    "        cur.append(s); cur_len += len(s) + 1\n",
    "    if cur:\n",
    "        chunks.append(\" \".join(cur))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "013ecc35-428c-4fc7-bf68-bbd719ffb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Step 1: 문서 로드 → 청크 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "95e34b4a-f367-4125-81ef-c5c03e7dbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 문서 경로 지정 (현재 위치에서 ../../11_data/ 안에 있음) ===\n",
    "# 문서 경로: 현재 위치에서 ../../11_data/ 아래에 파일이 있음\n",
    "DOC_NAME = \"01 Harry Potter and the Sorcerers Stone.txt\"\n",
    "doc_path = Path(\"../../11_data\") / DOC_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c9fa8d56-dff3-4ef3-992b-3e3c49cc5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 읽기 → 문장 분리 → 청크 생성\n",
    "text   = doc_path.read_text(encoding=\"utf-8\")\n",
    "sents  = split_sentences(text)\n",
    "chunks = chunk_by_sentences(sents, max_chars=2000)  # Jessica가 2000 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d4fcbb47-9ec1-4511-a064-56a310e7daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 문장 분리 & 청크 생성 ===\n",
    "# chunks.jsonl 저장\n",
    "chunk_path = OUT / \"chunks.jsonl\"\n",
    "with chunk_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for i, ch in enumerate(chunks, 1):\n",
    "        f.write(json.dumps({\n",
    "            \"chunk_id\": f\"C{i:04d}\",\n",
    "            \"text\": ch,\n",
    "            \"tokens\": len(ch.split())\n",
    "        }, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "db159c77-759e-44fe-9a73-9c6fbff2a132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chunks.jsonl 저장 완료: /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR/outputs/chunks.jsonl\n",
      "총 문장 수: 5003\n",
      "생성된 청크 수: 227\n",
      "첫 청크 미리보기:\n",
      " M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. Mr. Dursley was the director of a fi ...\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ chunks.jsonl 저장 완료:\", chunk_path)\n",
    "print(\"총 문장 수:\", len(sents))\n",
    "print(\"생성된 청크 수:\", len(chunks))\n",
    "print(\"첫 청크 미리보기:\\n\", chunks[0][:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bdbfbc89-9813-4024-931c-801b9a6919d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 셀 3 — PEGASUS 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ef2c18e3-aba2-4e8c-9e5c-05938904cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2d6350ef-c7b8-465b-a47a-442bd5198042",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/pegasus-xsum\"\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "04d4c1ef-a7d6-4add-94c0-b7cecc314da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e696e49721654787a8c249d433b686b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ceddb9fddaf465189415b918e5b2d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0852e585d8444baa1046e19086038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c52e126f7143c0b05b5b3db7115ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137603865fa24ba0a3fc1e9846fc92ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05473b1a3ad463caae7bdec5eba4797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9586f62e406c49969c16a1940bad9d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 로컬에 있으면 로컬로 로드, 없으면 자동 다운로드\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "238ff5db-45cf-4478-ad6a-a84292f2c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 — Chunk Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "63ece75b-3e14-4f61-81f2-e60c1861212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PEGASUS 준비 완료 (device=mps)\n"
     ]
    }
   ],
   "source": [
    "def summarize_pegasus(text, max_in=512, max_out=64, num_beams=4):\n",
    "    inputs = tok(text, return_tensors=\"pt\", truncation=True, max_length=max_in).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_out,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "        )\n",
    "    return tok.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"✅ PEGASUS 준비 완료 (device={device})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "60d02794-5adf-42db-9001-cc7ce0a38c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PEGASUS 로컬에 이미 있습니다.\n",
      "사용 장치: mps\n"
     ]
    }
   ],
   "source": [
    "if have_local_model(model_name):\n",
    "    print(\"✅ PEGASUS 로컬에 이미 있습니다.\")\n",
    "else:\n",
    "    print(\"⬇️ PEGASUS 다운로드 중… (인터넷 필요)\")\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)             # 다운로드\n",
    "    mdl = AutoModelForSeq2SeqLM.from_pretrained(model_name)     # 다운로드\n",
    "    print(\"✅ 다운로드 완료\")\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"사용 장치:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f167e5ef-4943-4cc3-9787-2d9e03a6810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) 요약 함수 (PEGASUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fd34834d-334d-450f-a4bf-d5bc47ecfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "chunks_path = OUT / \"chunks.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "27a5cd1c-01f0-4e08-af8c-a47eee15ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4-1) 스모크 테스트: 앞 5개만 ---\n",
    "summ_smoke = OUT / \"chunk_summaries_smoke.jsonl\"\n",
    "sample = []\n",
    "with open(chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        sample.append(json.loads(line))\n",
    "        if i >= 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6727da59-1b15-4f9b-ab24-8cdc28481f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52417af31c02403c9c15550c0dd87cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Smoke summarizing (5):   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 스모크 요약 저장: /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR/outputs/chunk_summaries_smoke.jsonl\n"
     ]
    }
   ],
   "source": [
    "with open(summ_smoke, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for obj in tqdm(sample, desc=\"Smoke summarizing (5)\"):\n",
    "        cid, text = obj[\"chunk_id\"], obj[\"text\"]\n",
    "        summ = summarize_pegasus(text, max_in=512, max_out=96, num_beams=4)  # 살짝 길게\n",
    "        item = {\n",
    "            \"chunk_id\": cid,\n",
    "            \"summary\": summ,\n",
    "            \"key_points\": [s.strip() for s in summ.split(\". \") if s.strip()][:4]\n",
    "        }\n",
    "        fout.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ 스모크 요약 저장:\", summ_smoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9c60908f-86d3-447c-907e-99f5e75ac819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>key_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0001</td>\n",
       "      <td>This is the story of the Dursleys and the Potters.</td>\n",
       "      <td>[This is the story of the Dursleys and the Potters.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0002</td>\n",
       "      <td>The Dursleys left the house for the day, with Mr. Dursley couldn’t bear people who dressed in funny clothes — the getups you saw on young people!</td>\n",
       "      <td>[The Dursleys left the house for the day, with Mr, Dursley couldn’t bear people who dressed in funny clothes — the getups you saw on young people!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0003</td>\n",
       "      <td>On the morning of the first day of school, Mr.</td>\n",
       "      <td>[On the morning of the first day of school, Mr.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0004</td>\n",
       "      <td>The first thing Mr.</td>\n",
       "      <td>[The first thing Mr.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0005</td>\n",
       "      <td>Dudley and Petunia Dursley had a strange day.</td>\n",
       "      <td>[Dudley and Petunia Dursley had a strange day.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunk_id  \\\n",
       "0    C0001   \n",
       "1    C0002   \n",
       "2    C0003   \n",
       "3    C0004   \n",
       "4    C0005   \n",
       "\n",
       "                                                                                                                                             summary  \\\n",
       "0                                                                                                 This is the story of the Dursleys and the Potters.   \n",
       "1  The Dursleys left the house for the day, with Mr. Dursley couldn’t bear people who dressed in funny clothes — the getups you saw on young people!   \n",
       "2                                                                                                     On the morning of the first day of school, Mr.   \n",
       "3                                                                                                                                The first thing Mr.   \n",
       "4                                                                                                      Dudley and Petunia Dursley had a strange day.   \n",
       "\n",
       "                                                                                                                                            key_points  \n",
       "0                                                                                                 [This is the story of the Dursleys and the Potters.]  \n",
       "1  [The Dursleys left the house for the day, with Mr, Dursley couldn’t bear people who dressed in funny clothes — the getups you saw on young people!]  \n",
       "2                                                                                                     [On the morning of the first day of school, Mr.]  \n",
       "3                                                                                                                                [The first thing Mr.]  \n",
       "4                                                                                                      [Dudley and Petunia Dursley had a strange day.]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df_smoke = pd.read_json(summ_smoke, lines=True)\n",
    "display(df_smoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2ba35e02-a4e9-40f5-8c4c-2db1cb1d829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ meta: pegasus-xsum(프롬프트 강화) 사용\n",
      "fanout = 2, leaves = 5\n"
     ]
    }
   ],
   "source": [
    "# 3. meta_summarize 선택 (멀티뉴스 시도 → 실패하면 XSum 폴백)\n",
    "TRY_MULTINEWS = False  # 멀티뉴스에서 에러 많이 났으니 우선 False 권장. OK면 True로 바꿔도 됨.\n",
    "\n",
    "# summarize_pegasus가 위에서 정의돼 있어야 XSum 폴백이 작동해요.\n",
    "if TRY_MULTINEWS:\n",
    "    try:\n",
    "        meta_summarize = _build_meta_with_multinews()\n",
    "        print(\"✅ meta: pegasus-multi_news 사용\")\n",
    "    except Exception as e:\n",
    "        print(f\"ℹ️ multi_news 로드 실패 → XSum으로 폴백: {e}\")\n",
    "        meta_summarize = _build_meta_with_xsum()\n",
    "        print(\"✅ meta: pegasus-xsum(프롬프트 강화) 사용\")\n",
    "else:\n",
    "    meta_summarize = _build_meta_with_xsum()\n",
    "    print(\"✅ meta: pegasus-xsum(프롬프트 강화) 사용\")\n",
    "\n",
    "# 4. fanout 설정 (스모크=2, 전량=6)\n",
    "fanout = 2 if len(leaves) <= 10 else 6\n",
    "print(f\"fanout = {fanout}, leaves = {len(leaves)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2875c2b3-42ad-4f45-a256-764e722de774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트리빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "74a5e6d4-35d0-446e-9b04-ad78795c4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 트리 빌드\n",
    "level, nodes, current = 0, [], leaves\n",
    "while len(current) > 1:\n",
    "    level += 1\n",
    "    grouped = [current[i:i+fanout] for i in range(0, len(current), fanout)]\n",
    "    next_level = []\n",
    "    for gi, group in enumerate(grouped, 1):\n",
    "        children = [cid for cid,_ in group]\n",
    "        texts    = [t   for _,t   in group]\n",
    "        summ = meta_summarize(texts)\n",
    "        node_id = f\"L{level}_N{gi:04d}\"\n",
    "        nodes.append({\"node_id\": node_id, \"level\": level, \"children\": children, \"summary\": summ})\n",
    "        next_level.append((node_id, summ))\n",
    "    current = next_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "500a6187-a217-4666-9bc1-d213f30863e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ tree_nodes.jsonl: /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR/outputs/tree_nodes.jsonl\n",
      "✅ tree_root.json : /Users/jessicahong/gitclone/NLP_study/09_Mini_Project/13_RAPTOR/outputs/tree_root.json\n",
      "\n",
      "📌 Root Summary:\n",
      " {\n",
      "  \"root_id\": \"L3_N0001\",\n",
      "  \"summary\": \"Do you think you know what is going on in the story?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## 6. 저장 + 루트 미리보기\n",
    "root_id, root_text = current[0]\n",
    "nodes_path.write_text(\"\\n\".join(json.dumps(n, ensure_ascii=False) for n in nodes), encoding=\"utf-8\")\n",
    "root_path.write_text(json.dumps({\"root_id\": root_id, \"summary\": root_text}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ tree_nodes.jsonl:\", nodes_path)\n",
    "print(\"✅ tree_root.json :\", root_path)\n",
    "print(\"\\n📌 Root Summary:\\n\", root_path.read_text(encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b4bc4da1-581b-44c6-a2cf-9d64b64131f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_meta_with_xsum():\n",
    "    # summarize_pegasus() 가 이미 정의돼 있다고 가정 (google/pegasus-xsum)\n",
    "    def _fn(texts, max_in=512, max_out=220, num_beams=8):\n",
    "        prompt = (\n",
    "            \"Summarize the following bullet points into a cohesive 4–6 sentence paragraph. \"\n",
    "            \"Write declarative sentences only (no questions, no instructions). \"\n",
    "            \"Include main characters, setting, key events/conflict, and why it matters.\\n\\n\"\n",
    "            + \"\\n\".join(f\"- {t}\" for t in texts)\n",
    "        )\n",
    "        out = summarize_pegasus(prompt, max_in=max_in, max_out=max_out, num_beams=num_beams)\n",
    "        bad = out.strip().endswith(\"?\") or out.strip().lower().startswith((\"how \", \"do you \", \"what \")) or len(out.split()) < 35\n",
    "        if bad:  # 한 번 재시도\n",
    "            out = summarize_pegasus(prompt, max_in=max_in, max_out=max_out+40, num_beams=num_beams+2)\n",
    "        return out\n",
    "    return _fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f25d4f59-8f89-4108-8c23-e62bf941d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ multi_news 로드 실패, XSum으로 폴백: Couldn't instantiate the backend tokenizer from one of: \n",
      "(1) a `tokenizers` library serialization file, \n",
      "(2) a slow tokenizer instance to convert or \n",
      "(3) an equivalent slow tokenizer class to instantiate and convert. \n",
      "You need to have sentencepiece installed to convert a slow tokenizer to a fast one.\n",
      "✅ meta: pegasus-xsum(프롬프트 강화) 사용\n"
     ]
    }
   ],
   "source": [
    "# --- meta_summarize 준비 (multi_news → 실패 시 xsum) ---\n",
    "try:\n",
    "    meta_summarize = _build_meta_with_multinews()\n",
    "    print(\"✅ meta: pegasus-multi_news 사용\")\n",
    "except Exception as e:\n",
    "    print(f\"ℹ️ multi_news 로드 실패, XSum으로 폴백: {e}\")\n",
    "    meta_summarize = _build_meta_with_xsum()\n",
    "    print(\"✅ meta: pegasus-xsum(프롬프트 강화) 사용\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "070efe1c-ffd9-4379-a81d-b3e75a5a109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAPTOR retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7f7cde94-5ddc-49a9-b4cc-c17256e1f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9008c9de-0620-4e22-8e33-9e0c5eb69759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBERT 임베딩 우선, 실패시 TF-IDF로 폴백\n",
    "_USE_SBERT = True\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception:\n",
    "    _USE_SBERT = False\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea58b7e-4b43-4137-9d84-657651d81504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d651fd9d-e109-4349-b0e4-38ca9a085ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) 파이프라인 검증: 스모크 5개로 트리 만들어보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
