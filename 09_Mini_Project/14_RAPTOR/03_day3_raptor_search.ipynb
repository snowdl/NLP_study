{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39875ed7-d801-44c2-b49b-f13770885aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1201f35b-47d6-4a2e-bb59-0d2bb91af483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. 데이터 불러오기 ===\n",
    "chunks = []\n",
    "with open(\"outputs/chunks.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        chunks.append(json.loads(line))\n",
    "\n",
    "tree = []\n",
    "with open(\"outputs/tree_nodes.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        tree.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01f21c40-13cb-4dad-bd0c-6ac809552997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. 간단 검색 함수 ===\n",
    "def raptor_search(query, tree, chunks, topk=2):\n",
    "    node_ids = [n[\"id\"] for n in tree]\n",
    "    summaries = [n[\"summary\"] for n in tree]\n",
    "\n",
    "    # TF-IDF 기반 검색\n",
    "    vec = TfidfVectorizer().fit(summaries + [query])\n",
    "    q_vec = vec.transform([query])\n",
    "    sims = cosine_similarity(q_vec, vec.transform(summaries))[0]\n",
    "\n",
    "    # 상위 노드 뽑기\n",
    "    top_idx = sims.argsort()[-topk:][::-1]\n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        node = tree[idx]\n",
    "        child_chunks = [c for c in node.get(\"children\", []) if c.startswith(\"C\")]\n",
    "        chunk_texts = [c[\"text\"] for c in chunks if c[\"id\"] in child_chunks]\n",
    "        results.append({\n",
    "            \"node\": node[\"id\"],\n",
    "            \"summary\": node[\"summary\"],\n",
    "            \"chunks\": chunk_texts\n",
    "        })\n",
    "    return results# === 3. 실행 ===\n",
    "query = \"What strange events happened on Privet Drive?\"\n",
    "res = raptor_search(query, tree, chunks)\n",
    "\n",
    "for r in res:\n",
    "    print(\"📌 Node:\", r[\"node\"])\n",
    "    print(\"📝 Summary:\", r[\"summary\"])\n",
    "    print(\"📑 Chunks:\", r[\"chunks\"][:2])  # 일부만 출력\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "026fc55f-2c9f-4ab8-be6e-756f83c88604",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# === 3. 실행 ===\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat strange events happened on Privet Drive?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mraptor_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📌 Node:\u001b[39m\u001b[38;5;124m\"\u001b[39m, r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m, in \u001b[0;36mraptor_search\u001b[0;34m(query, tree, chunks, topk)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraptor_search\u001b[39m(query, tree, chunks, topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     node_ids \u001b[38;5;241m=\u001b[39m [n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m      4\u001b[0m     summaries \u001b[38;5;241m=\u001b[39m [n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# TF-IDF 기반 검색\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraptor_search\u001b[39m(query, tree, chunks, topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     node_ids \u001b[38;5;241m=\u001b[39m [\u001b[43mn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m      4\u001b[0m     summaries \u001b[38;5;241m=\u001b[39m [n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# TF-IDF 기반 검색\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# === 3. 실행 ===\n",
    "query = \"What strange events happened on Privet Drive?\"\n",
    "res = raptor_search(query, tree, chunks)\n",
    "\n",
    "for r in res:\n",
    "    print(\"📌 Node:\", r[\"node\"])\n",
    "    print(\"📝 Summary:\", r[\"summary\"])\n",
    "    print(\"📑 Chunks:\", r[\"chunks\"][:2])  # 일부만 출력\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1038734d-18f5-432b-8a3c-78f613aea1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dadd88c-8106-4256-8bbd-0b11b5c85dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_node2chunks_from_linkfile(path):\n",
    "    \"\"\"node_chunks.jsonl 류 (node_id -> [chunk_id,...]) 형태 탐지\"\"\"\n",
    "    node2chunks = defaultdict(list)\n",
    "    try:\n",
    "        for obj in load_jsonl(path):\n",
    "            nid = obj.get(\"node_id\")\n",
    "            cids = None\n",
    "            for k in NODE_CHUNK_KEYS:\n",
    "                if k in obj:\n",
    "                    cids = obj[k]\n",
    "                    break\n",
    "            if nid and cids:\n",
    "                if not isinstance(cids, list): cids = [cids]\n",
    "                for cid in cids:\n",
    "                    if cid in chunk_by_id:\n",
    "                        node2chunks[nid].append(cid)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return dict(node2chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e17ffc59-ff6f-4dbf-bb82-a887aa0a5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_node2chunks_from_reverse_linkfile(path):\n",
    "    \"\"\"chunk_node_links.jsonl 류 (chunk_id -> node_id/...) 형태 탐지 후 역인덱스\"\"\"\n",
    "    node2chunks = defaultdict(list)\n",
    "    try:\n",
    "        for obj in load_jsonl(path):\n",
    "            cid = obj.get(\"chunk_id\")\n",
    "            if not cid or cid not in chunk_by_id: \n",
    "                continue\n",
    "            ref = None\n",
    "            for k in CHUNK_NODE_KEYS:\n",
    "                if k in obj:\n",
    "                    ref = obj[k]; break\n",
    "            if ref is None: \n",
    "                continue\n",
    "            if not isinstance(ref, list): ref = [ref]\n",
    "            for nid in ref:\n",
    "                if nid in node_by_id:\n",
    "                    node2chunks[nid].append(cid)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return dict(node2chunks)\n",
    "\n",
    "node2chunks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a1796d0-a0fb-405d-89bd-86d27993955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 링크 파일에서 먼저 찾아보기\n",
    "for lf in link_files:\n",
    "    node2chunks = detect_node2chunks_from_linkfile(lf)\n",
    "    if node2chunks:\n",
    "        print(f\"✅ 링크 감지 (node->chunks): {lf.name}\")\n",
    "        break\n",
    "    node2chunks = detect_node2chunks_from_reverse_linkfile(lf)\n",
    "    if node2chunks:\n",
    "        print(f\"✅ 링크 감지 (chunk->nodes): {lf.name}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0feac7a2-3c8f-45a0-b000-7ff4e5a5e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 링크 파일이 없거나 텅 비면, children/청크필드에서 휴리스틱 시도\n",
    "if not node2chunks:\n",
    "    # (A) children 안에 chunk_id 패턴이 섞인 경우\n",
    "    chunk_like = re.compile(r\"^c[\\w-]+\", re.I)\n",
    "    for nid, nd in node_by_id.items():\n",
    "        kids = nd.get(\"children\") or []\n",
    "        cids = [x for x in kids if isinstance(x, str) and chunk_like.match(x)]\n",
    "        if cids:\n",
    "            node2chunks[nid] = [cid for cid in cids if cid in chunk_by_id]\n",
    "\n",
    "if not node2chunks:\n",
    "    # (B) chunks.jsonl 안에 소속 노드 힌트가 들어있는 경우\n",
    "    for ch in chunks:\n",
    "        cid = ch.get(\"chunk_id\")\n",
    "        if not cid: \n",
    "            continue\n",
    "        for k in [\"node_id\",\"belongs_to\",\"owner_node\",\"nodes\",\"parents\",\"node_path\"]:\n",
    "            if k in ch:\n",
    "                ref = ch[k]\n",
    "                if not isinstance(ref, list): ref = [ref]\n",
    "                for nid in ref:\n",
    "                    if nid in node_by_id:\n",
    "                        node2chunks.setdefault(nid, []).append(cid)\n",
    "                break\n",
    "\n",
    "# 5) 보여주기: 청크가 붙은 노드 하나 찾아서 요약 + 청크 1~2개 미리보기\n",
    "def preview_text(t, n=160):\n",
    "    s = t if isinstance(t, str) else str(t)\n",
    "    return (s[:n] + \"...\") if len(s) > n else s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cb46e4f-bacc-489f-81bd-599bf7a658f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[노드]\n",
      " ID   : L1_N0001\n",
      " 레벨 : 1\n",
      " 자식 : ['C0001', 'C0002']\n",
      " 요약 : This is the story of the Dursleys and the Potters.\n",
      "\n",
      "[연결된 청크 미리보기]\n",
      " - C0001: M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d exp...\n",
      " - C0002: Dursley on the cheek, and tried to kiss Dudley good-bye but missed, because Dudley was now having a tantrum and throwing his cereal at the walls. “Little tyke,”...\n"
     ]
    }
   ],
   "source": [
    "if node2chunks:\n",
    "    # 청크 달린 노드들만\n",
    "    candidates = [(nid, cids) for nid, cids in node2chunks.items() if cids]\n",
    "    if candidates:\n",
    "        nid, cids = candidates[0]  # 첫 번째만 보여줌\n",
    "        nd = node_by_id[nid]\n",
    "        print(\"\\n[노드]\")\n",
    "        print(\" ID   :\", nid)\n",
    "        print(\" 레벨 :\", nd.get(\"level\"))\n",
    "        print(\" 자식 :\", nd.get(\"children\"))\n",
    "        print(\" 요약 :\", nd.get(\"summary\"))\n",
    "        print(\"\\n[연결된 청크 미리보기]\")\n",
    "        for cid in cids[:2]:\n",
    "            ch = chunk_by_id.get(cid, {})\n",
    "            print(f\" - {cid}:\", preview_text(ch.get(\"text\", \"\")))\n",
    "    else:\n",
    "        print(\"\\n⚠️ 링크는 감지했지만, 실제 연결된 청크 리스트가 비어있습니다.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 청크-노드 연결을 찾지 못했습니다.\")\n",
    "    print(\"   - outputs 폴더에 'node_chunks.jsonl' 또는 'chunk_node_links.jsonl' 같은 파일이 있는지 확인\")\n",
    "    print(\"   - 파일 안에서 'node_id', 'chunk_ids/chunks/sources' 등의 키가 있는지 확인\")\n",
    "    print(\"   - 키 이름이 다르면 위 NODE_CHUNK_KEYS / CHUNK_NODE_KEYS에 추가 후 다시 실행\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84efa18e-d37a-4b3b-b379-ee60fc962f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정 노드 하나만 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d771c02e-b67d-452d-9f8c-244477de42b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[노드ID] L1_N0001\n",
      "[레벨] 1\n",
      "[자식] ['C0001', 'C0002']\n",
      "[요약] This is the story of the Dursleys and the Potters.\n",
      "- C0001: M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d exp...\n",
      "- C0002: Dursley on the cheek, and tried to kiss Dudley good-bye but missed, because Dudley was now having a tantrum and throwing his cereal at the walls. “Little tyke,”...\n"
     ]
    }
   ],
   "source": [
    "nid = \"L1_N0001\"  # 보고 싶은 노드ID로 변경\n",
    "lvl, kids, summ = node_by_id[nid].get(\"level\"), node_by_id[nid].get(\"children\"), node_by_id[nid].get(\"summary\")\n",
    "print(f\"[노드ID] {nid}\\n[레벨] {lvl}\\n[자식] {kids}\\n[요약] {summ}\")\n",
    "for cid in node2chunks.get(nid, [])[:3]:  # 청크 3개 미리보기\n",
    "    print(f\"- {cid}: {chunk_by_id[cid]['text'][:160]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6bafa0b-7096-464b-8849-4652f8bcfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) “루트→자식→leaf” 따라가서 첫 청크까지 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58105140-b675-4155-90cf-8735ec5eb0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 찾은 노드: L1_N0001\n",
      "- C0001: M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d exp...\n",
      "- C0002: Dursley on the cheek, and tried to kiss Dudley good-bye but missed, because Dudley was now having a tantrum and throwing his cereal at the walls. “Little tyke,”...\n"
     ]
    }
   ],
   "source": [
    "def first_leaf_with_chunks(root_id):\n",
    "    stack = [root_id]\n",
    "    seen = set()\n",
    "    while stack:\n",
    "        nid = stack.pop()\n",
    "        if nid in seen: \n",
    "            continue\n",
    "        seen.add(nid)\n",
    "        cids = node2chunks.get(nid, [])\n",
    "        if cids:  # 청크 달린 leaf(또는 중간노드) 발견\n",
    "            return nid, cids\n",
    "        for child in node_by_id[nid].get(\"children\", [])[::-1]:\n",
    "            if child in node_by_id:\n",
    "                stack.append(child)\n",
    "    return None, []\n",
    "\n",
    "root = \"L1_N0001\"  # 시작 노드\n",
    "nid, cids = first_leaf_with_chunks(root)\n",
    "print(\"→ 찾은 노드:\", nid)\n",
    "for cid in cids[:2]:\n",
    "    print(f\"- {cid}: {chunk_by_id[cid]['text'][:160]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec70dec1-704c-4b8a-81b0-59071108e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 레벨별로 “한 노드씩” 샘플 들여다보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33c02059-b4eb-4b8a-891a-53b000a05a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 레벨 1 샘플: L1_N0001 ===\n",
      "요약: This is the story of the Dursleys and the Potters.\n",
      "- C0001: M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d exp...\n",
      "\n",
      "=== 레벨 2 샘플: L2_N0001 ===\n",
      "요약: Harry Potter and the Philosopher’s Stone by JK Rowling\n",
      "\n",
      "=== 레벨 3 샘플: L3_N0001 ===\n",
      "요약: All images are copyrighted.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "levels = defaultdict(list)\n",
    "for nid, nd in node_by_id.items():\n",
    "    levels[nd.get(\"level\")].append(nid)\n",
    "\n",
    "for lvl in sorted(levels):\n",
    "    sample = levels[lvl][0]\n",
    "    print(f\"\\n=== 레벨 {lvl} 샘플: {sample} ===\")\n",
    "    print(\"요약:\", node_by_id[sample].get(\"summary\"))\n",
    "    for cid in node2chunks.get(sample, [])[:1]:\n",
    "        print(f\"- {cid}: {chunk_by_id[cid]['text'][:160]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb038fa-0090-4706-8c1b-029368bbcefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 청크가 붙은 노드가 하나도 없음\n"
     ]
    }
   ],
   "source": [
    "# 청크가 연결된 노드를 하나 찾기\n",
    "chunked_nodes = [nid for nid, (_, _, _, cids) in node_info.items() if cids]\n",
    "\n",
    "if chunked_nodes:\n",
    "    nid = chunked_nodes[0]   # 첫 번째로 청크가 달린 노드\n",
    "    level, children, summary, node_chunks = node_info[nid]\n",
    "\n",
    "    print(f\"\\n[노드ID] {nid}\")\n",
    "    print(f\"[레벨]   {level}\")\n",
    "    print(f\"[자식]   {children}\")\n",
    "    print(f\"[요약]   {summary}\")\n",
    "\n",
    "    print(\"\\n=== 연결된 청크 예시 ===\")\n",
    "    for cid in node_chunks[:2]:  # 앞에서 2개만\n",
    "        print(f\"chunk {cid}: {chunks.get(cid,'(없음)')[:120]}...\")\n",
    "else:\n",
    "    print(\"⚠️ 청크가 붙은 노드가 하나도 없음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "483c704c-a433-4e43-be5a-3ae7f5998125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LABEL INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9910ad76-7568-4099-8b22-27fe5c911e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "levels = defaultdict(list)  # level -> [(node_id, summary)]\n",
    "for nid, (lvl, children, summ) in node_info.items():\n",
    "    levels[lvl].append((nid, summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94092e71-4786-402e-986e-afa6abc943d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF 유틸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5057afea-6758-4f2e-9f64-6b76519a8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def _fit(texts):\n",
    "    v = TfidfVectorizer(ngram_range=(1,2), max_features=60000)\n",
    "    return v, v.fit_transform(texts)\n",
    "\n",
    "def _score(M, v, q):\n",
    "    return cosine_similarity(M, v.transform([q])).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8db206d5-52ea-4865-9a50-221e680ce110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시작 레벨 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed45c5e3-aaa7-4a5d-89ce-4ee75ff0dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def select_start_level(q:str):\n",
    "    ks = sorted(levels.keys())\n",
    "    if not ks: return None\n",
    "    qn = len(re.findall(r\"\\w+\", q))\n",
    "    return (ks[-1] if qn<=5 else (ks[-2] if len(ks)>1 and qn<=12 else ks[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ffb577-1254-4b1e-a305-5051ed1128c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 — 레벨 내 노드 랭킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8c62179-a76a-4c62-ac8b-4c71a6a786f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_nodes_at_level(q, L, topk=6):\n",
    "    items = levels.get(L, [])\n",
    "    if not items: return []\n",
    "    ids  = [i for i,_ in items]\n",
    "    txts = [t for _,t in items]\n",
    "    v, M = _fit(txts); sims = _score(M, v, q)\n",
    "    idx = np.argsort(-sims)[:topk]\n",
    "    return [ids[i] for i in idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b32c184c-bdf4-407d-a23e-81b7e93eb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#확장(FIX: 공백정규화 + 폴백)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2cb6bc0-1e14-4380-87da-9fbc225595be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm_id(x):  return x.strip() if isinstance(x, str) else x\n",
    "def _is_chunk(x): return isinstance(x, str) and x.startswith(\"C\")\n",
    "\n",
    "def expand_to_leaves(seed_ids, hops=2):\n",
    "    out, fr = [], list(map(_norm_id, seed_ids))\n",
    "    for _ in range(hops):\n",
    "        nxt=[]\n",
    "        for nid in fr:\n",
    "            if _is_chunk(nid): out.append(nid)\n",
    "            elif nid in node_info: nxt += [_norm_id(c) for c in node_info[nid][1]]\n",
    "        fr = nxt\n",
    "        if not fr: break\n",
    "    if out:\n",
    "        seen, uniq = set(), []\n",
    "        for cid in out:\n",
    "            if cid not in seen: uniq.append(cid); seen.add(cid)\n",
    "        return uniq\n",
    "    # 폴백1: 한 hop 자식 반환(L2->L1 등)\n",
    "    one_hop=[]\n",
    "    for nid in map(_norm_id, seed_ids):\n",
    "        if nid in node_info: one_hop += [_norm_id(c) for c in node_info[nid][1]]\n",
    "    if one_hop: return one_hop\n",
    "    # 폴백2: seed 그대로\n",
    "    return list(map(_norm_id, seed_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d8b04f0-8bf3-44cd-9e96-54fa4dd7db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) L1 → C 강제 변환\n",
    "def to_chunks(ids, max_hops=3):\n",
    "    out, fr = [], list(ids)\n",
    "    for _ in range(max_hops):\n",
    "        nxt=[]\n",
    "        for x in fr:\n",
    "            if isinstance(x, str) and x.startswith(\"C\"):\n",
    "                out.append(x)\n",
    "            elif x in node_info:\n",
    "                nxt += node_info[x][1]\n",
    "        fr = nxt\n",
    "        if not fr: break\n",
    "    seen, uniq = set(), []\n",
    "    for c in out:\n",
    "        if c not in seen: uniq.append(c); seen.add(c)\n",
    "    return uniq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cbc17b9-aa49-4f00-95fb-b0d42ecdce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 7 — 리프 요약 로드(폴백용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea41f740-efb7-4562-bd39-e974ea959ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ leaf_summary: 5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    summ_smoke = OUT / \"chunk_summaries_smoke.jsonl\"\n",
    "    summ_all   = OUT / \"chunk_summaries.jsonl\"\n",
    "    summ_path  = summ_smoke if summ_smoke.exists() else summ_all\n",
    "    leaf_summary = {json.loads(l)[\"chunk_id\"]: json.loads(l)[\"summary\"] for l in open(summ_path, encoding=\"utf-8\")}\n",
    "except Exception:\n",
    "    leaf_summary = {}\n",
    "print(\"✅ leaf_summary:\", len(leaf_summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b93f553e-23fd-46aa-a8ba-4c907973df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 8 — 재랭킹(본문 우선, 요약 폴백)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ab81d78-5ab5-4c5b-a623-284ae20f1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_chunks_with_fallback(q, candidate_cids, topk=5):\n",
    "    # 본문 기준\n",
    "    ids, txts = [], []\n",
    "    for cid in candidate_cids:\n",
    "        if cid in chunk_text:\n",
    "            ids.append(cid); txts.append(chunk_text[cid])\n",
    "    if ids:\n",
    "        v, M = _fit(txts); sims = _score(M, v, q)\n",
    "        idx = np.argsort(-sims)[:topk]\n",
    "        return [(ids[i], float(sims[i])) for i in idx]\n",
    "    # 요약 폴백\n",
    "    ids, txts = [], []\n",
    "    for cid in candidate_cids:\n",
    "        if cid in leaf_summary:\n",
    "            ids.append(cid); txts.append(leaf_summary[cid])\n",
    "    if not ids: return []\n",
    "    v, M = _fit(txts); sims = _score(M, v, q)\n",
    "    idx = np.argsort(-sims)[:topk]\n",
    "    return [(ids[i], float(sims[i])) for i in idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc7deda4-e49b-4d1f-95b5-fea6271dafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 9 — RAPTOR 검색 + 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06374b0b-f80f-45cc-b7af-a0651c003342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raptor_search(q, topk_nodes=6, topk_chunks=5, hops=2):\n",
    "    L = select_start_level(q)\n",
    "    if L is None: return {\"level\": None, \"nodes\": [], \"chunks\": []}\n",
    "    seeds = rank_nodes_at_level(q, L, topk=topk_nodes)\n",
    "    cand  = expand_to_leaves(seeds, hops=hops) or seeds\n",
    "    cand  = to_chunks(cand, max_hops=3) or cand   # ⭐ 여기를 추가: L1 → C로 강제 변환\n",
    "    chunks = rerank_chunks_with_fallback(q, cand, topk=topk_chunks)\n",
    "    return {\"level\": L, \"nodes\": seeds, \"chunks\": chunks}\n",
    "\n",
    "def pretty_answer(q, sent_per_chunk=3):\n",
    "    res = raptor_search(q)\n",
    "    picks=[]\n",
    "    for cid,_ in res[\"chunks\"]:\n",
    "        text = chunk_text.get(cid, \"\")\n",
    "        sents = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', text) if s.strip()]\n",
    "        if not sents: continue\n",
    "        v, M = _fit(sents); sims = _score(M, v, q)\n",
    "        idx = np.argsort(-sims)[:sent_per_chunk]\n",
    "        picks.append(f\"[{cid}] \" + \" \".join(sents[i] for i in idx))\n",
    "    print(f\"🔎 Q: {q}\\n📍 start level: L{res['level']}\\n📑 nodes: {res['nodes']}\\n💬 A: {' '.join(picks) if picks else '(no matching evidence)'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c05095b1-c1fd-42ca-aabe-f6795bbf69ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Q: What strange events happened on Privet Drive?\n",
      "📍 start level: L2\n",
      "📑 nodes: ['L2_N0002', 'L2_N0001']\n",
      "💬 A: [C0002] There was a tabby cat standing on the corner of Privet Drive, but there wasn’t a map in sight. It was now reading the sign that said Privet Drive — no, looking at the sign; cats couldn’t read maps or signs. What could he have been thinking of? [C0001] Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. [C0003] It was on his way back past them, clutching a large doughnut in a bag, that he caught a few words of what they were saying. “The Potters, that’s right, that’s what I heard —”\n",
      "\n",
      "“ — yes, their son, Harry —”\n",
      "\n",
      "Mr. Dursley arrived in the Grunnings parking lot, his mind back on drills. [C0004] It was now sitting on his garden wall. On the contrary, his face split into a wide smile and he said in a squeaky voice that made passersby stare, “Don’t be sorry, my dear sir, for nothing could upset me today! He didn’t blame her — if he’d had a sister like that…but all the same, those people in cloaks.…\n",
      "\n",
      "He found it a lot harder to concentrate on drills that afternoon and when he left the building at five o’clock, he was still so worried that he walked straight into someone just outside the door. [C0005] “Why?”\n",
      "\n",
      "“Funny stuff on the news,” Mr. When Dudley had been put to bed, he went into the living room in time to catch the last report on the evening news:\n",
      "\n",
      "“And finally, bird-watchers everywhere have reported that the nation’s owls have been behaving very unusually today. “Well, I just thought…maybe…it was something to do with…you know…her crowd.”\n",
      "\n",
      "Mrs.\n",
      "🔎 Q: Describe the Dursleys and how they feel about magic.\n",
      "📍 start level: L2\n",
      "📑 nodes: ['L2_N0001', 'L2_N0002']\n",
      "💬 A: [C0001] The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. [C0004] Next Door’s problems with her daughter and how Dudley had learned a new word (“Won’t!”). She told him over dinner all about Mrs. Dursley around the middle and walked off. [C0002] They were whispering excitedly together. Dursley drove around the corner and up the road, he watched the cat in his mirror. Dursley blinked and stared at the cat. [C0005] And a whisper, a whisper about the Potters.…\n",
      "\n",
      "Mrs. Viewers as far apart as Kent, Yorkshire, and Dundee have been phoning in to tell me that instead of the rain I promised yesterday, they’ve had a downpour of shooting stars! After all, they normally pretended she didn’t have a sister. [C0003] He’d for gotten all about the people in cloaks until he passed a group of them next to the baker’s. He didn’t see the owls swooping past in broad daylight, though people down in the street did; they pointed and gazed open-mouthed as owl after owl sped overhead. He didn’t know why, but they made him uneasy.\n"
     ]
    }
   ],
   "source": [
    "pretty_answer(\"What strange events happened on Privet Drive?\")\n",
    "pretty_answer(\"Describe the Dursleys and how they feel about magic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e6c2ff8-f800-40de-b641-b092be07f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== RAPTOR Day3 : 왕초보용 검색 스켈레톤 =====================\n",
    "# 쿼리 → 관련 노드(요약) → 연결 청크 → 간단 요약 답변\n",
    "# - 외부 라이브러리 없이 동작 (정규식/중복 단어 겹침 기반)\n",
    "# - 파일: tree_nodes.jsonl, chunks.jsonl, (node_chunks.jsonl 또는 유사 링크 파일)\n",
    "# ================================================================================\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# --------------------------- 유틸: 텍스트 전처리 ---------------------------\n",
    "WORD_RE = re.compile(r\"[A-Za-z가-힣0-9']+\")\n",
    "\n",
    "def tokenize(text: str):\n",
    "    if not text:\n",
    "        return []\n",
    "    return [w.lower() for w in WORD_RE.findall(text)]\n",
    "\n",
    "def wordset(text: str):\n",
    "    return set(tokenize(text))\n",
    "\n",
    "def sent_split(text: str):\n",
    "    # 아주 단순한 문장 분리 (., !, ? 기준)\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    parts = re.split(r\"(?<=[.!?\\n])\\s+\", text.strip())\n",
    "    # 빈 문장 제거\n",
    "    return [s.strip() for s in parts if s.strip()]\n",
    "\n",
    "def overlap_score(query_ws: set, text: str):\n",
    "    if not text: \n",
    "        return 0\n",
    "    ws = wordset(text)\n",
    "    if not ws:\n",
    "        return 0\n",
    "    return len(query_ws & ws)\n",
    "\n",
    "# --------------------------- JSONL 로드 ---------------------------\n",
    "def load_jsonl(path: Path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            if line:\n",
    "                yield json.loads(line)\n",
    "\n",
    "# --------------------------- 경로 추정 ---------------------------\n",
    "def find_base():\n",
    "    CWD = Path.cwd()\n",
    "    if CWD.name == \"13_RAPTOR\":\n",
    "        return CWD\n",
    "    cands = [CWD/\"13_RAPTOR\", CWD.parent/\"13_RAPTOR\", CWD/\"09_Mini_Project\"/\"13_RAPTOR\"]\n",
    "    for p in cands:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return CWD\n",
    "\n",
    "BASE = find_base()\n",
    "OUT = BASE / \"outputs\"\n",
    "\n",
    "# --------------------------- 데이터 읽기 ---------------------------\n",
    "nodes_path  = OUT / \"tree_nodes.jsonl\"\n",
    "chunks_path = OUT / \"chunks.jsonl\"\n",
    "\n",
    "nodes  = list(load_jsonl(nodes_path))\n",
    "chunks = list(load_jsonl(chunks_path))\n",
    "\n",
    "node_by_id  = {nd[\"node_id\"]: nd for nd in nodes if \"node_id\" in nd}\n",
    "chunk_by_id = {ch[\"chunk_id\"]: ch for ch in chunks if \"chunk_id\" in ch}\n",
    "\n",
    "# --------------------------- 노드↔청크 링크 자동 감지 ---------------------------\n",
    "# (outputs 폴더에서 map/link 파일을 찾아 node2chunks를 구성)\n",
    "NODE_CHUNK_KEYS = [\"chunk_ids\", \"chunks\", \"sources\"]\n",
    "CHUNK_NODE_KEYS = [\"node_id\", \"belongs_to\", \"owner_node\", \"nodes\", \"parents\", \"node_path\"]\n",
    "\n",
    "def detect_node2chunks():\n",
    "    node2chunks = defaultdict(list)\n",
    "\n",
    "    # 1) 별도 링크 파일 스캔\n",
    "    for p in OUT.glob(\"*\"):\n",
    "        if p.suffix.lower() not in {\".jsonl\", \".json\", \".ndjson\"}:\n",
    "            continue\n",
    "        if not re.search(r\"(map|link|assign|attach|node.*chunk|chunk.*node|leaf)\", p.name, re.I):\n",
    "            continue\n",
    "        # (a) node -> chunks 구조\n",
    "        try:\n",
    "            for obj in load_jsonl(p):\n",
    "                nid = obj.get(\"node_id\")\n",
    "                if not nid:\n",
    "                    continue\n",
    "                cids = None\n",
    "                for k in NODE_CHUNK_KEYS:\n",
    "                    if k in obj:\n",
    "                        cids = obj[k]\n",
    "                        break\n",
    "                if cids:\n",
    "                    if not isinstance(cids, list):\n",
    "                        cids = [cids]\n",
    "                    for cid in cids:\n",
    "                        if cid in chunk_by_id:\n",
    "                            node2chunks[nid].append(cid)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # 링크가 생겼다면 OK\n",
    "        if node2chunks:\n",
    "            return dict(node2chunks)\n",
    "\n",
    "        # (b) chunk -> nodes 구조 (역인덱스)\n",
    "        try:\n",
    "            tmp = defaultdict(list)\n",
    "            for obj in load_jsonl(p):\n",
    "                cid = obj.get(\"chunk_id\")\n",
    "                if not cid or cid not in chunk_by_id:\n",
    "                    continue\n",
    "                ref = None\n",
    "                for k in CHUNK_NODE_KEYS:\n",
    "                    if k in obj:\n",
    "                        ref = obj[k]\n",
    "                        break\n",
    "                if ref is None:\n",
    "                    continue\n",
    "                if not isinstance(ref, list):\n",
    "                    ref = [ref]\n",
    "                for nid in ref:\n",
    "                    if nid in node_by_id:\n",
    "                        tmp[nid].append(cid)\n",
    "            if tmp:\n",
    "                return dict(tmp)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) 링크 파일이 없으면 휴리스틱들\n",
    "\n",
    "    # (A) children에 chunk_id가 섞인 경우 (예: 'C0001' 패턴)\n",
    "    chunk_like = re.compile(r\"^c[\\w-]+\", re.I)\n",
    "    for nid, nd in node_by_id.items():\n",
    "        kids = nd.get(\"children\") or []\n",
    "        cids = [x for x in kids if isinstance(x, str) and chunk_like.match(x)]\n",
    "        for cid in cids:\n",
    "            if cid in chunk_by_id:\n",
    "                node2chunks[nid].append(cid)\n",
    "\n",
    "    if node2chunks:\n",
    "        return dict(node2chunks)\n",
    "\n",
    "    # (B) 청크 쪽에 소속 노드 힌트가 있는 경우\n",
    "    tmp = defaultdict(list)\n",
    "    for ch in chunks:\n",
    "        cid = ch.get(\"chunk_id\")\n",
    "        if not cid:\n",
    "            continue\n",
    "        for k in CHUNK_NODE_KEYS:\n",
    "            if k in ch:\n",
    "                ref = ch[k]\n",
    "                if not isinstance(ref, list):\n",
    "                    ref = [ref]\n",
    "                for nid in ref:\n",
    "                    if nid in node_by_id:\n",
    "                        tmp[nid].append(cid)\n",
    "                break\n",
    "    if tmp:\n",
    "        return dict(tmp)\n",
    "\n",
    "    # 아무것도 못 찾음\n",
    "    return {}\n",
    "\n",
    "node2chunks = detect_node2chunks()\n",
    "\n",
    "# --------------------------- 노드 스코어링 (요약 기반) ---------------------------\n",
    "def rank_nodes_by_query(query: str, top_k: int = 3):\n",
    "    qset = wordset(query)\n",
    "    scored = []\n",
    "    for nid, nd in node_by_id.items():\n",
    "        summ = nd.get(\"summary\", \"\")\n",
    "        score = overlap_score(qset, summ)\n",
    "        # 보너스: 제목/요약이 짧을수록 가점 (간단한 길이 보정)\n",
    "        score += max(0, 5 - len(summ.split())//40)\n",
    "        if score > 0:\n",
    "            scored.append((score, nid))\n",
    "    scored.sort(reverse=True)\n",
    "    return [nid for _, nid in scored[:top_k]]\n",
    "\n",
    "# --------------------------- 청크 스코어링 (내용 기반) ---------------------------\n",
    "def rank_chunks_for_nodes(query: str, nids, per_node: int = 3):\n",
    "    qset = wordset(query)\n",
    "    results = []\n",
    "    for nid in nids:\n",
    "        cids = node2chunks.get(nid, [])\n",
    "        scored = []\n",
    "        for cid in cids:\n",
    "            text = chunk_by_id.get(cid, {}).get(\"text\", \"\")\n",
    "            sc = overlap_score(qset, text)\n",
    "            if sc > 0:\n",
    "                scored.append((sc, cid))\n",
    "        scored.sort(reverse=True)\n",
    "        results.extend([cid for _, cid in scored[:per_node]])\n",
    "    # 중복 제거, 간단 정렬 유지\n",
    "    seen, ordered = set(), []\n",
    "    for cid in results:\n",
    "        if cid not in seen:\n",
    "            seen.add(cid)\n",
    "            ordered.append(cid)\n",
    "    return ordered\n",
    "\n",
    "# --------------------------- 간단 요약 생성 (추출식) ---------------------------\n",
    "def make_answer(query: str, chunk_texts, max_sents: int = 5, max_chars: int = 800):\n",
    "    # 문장 단위로 나눠서, 쿼리와 겹치는 문장을 우선 선택\n",
    "    qset = wordset(query)\n",
    "    cand_sents = []\n",
    "    for txt in chunk_texts:\n",
    "        for s in sent_split(txt):\n",
    "            sc = overlap_score(qset, s)\n",
    "            cand_sents.append((sc, s))\n",
    "\n",
    "    # 점수 높은 문장부터 뽑되, 너무 비슷한 문장 반복 방지(간단 중복 제거)\n",
    "    cand_sents.sort(key=lambda x: x[0], reverse=True)\n",
    "    picked, seen = [], set()\n",
    "    for sc, s in cand_sents:\n",
    "        norm = \" \".join(tokenize(s))[:120]  # 간단한 중복 키\n",
    "        if norm in seen:\n",
    "            continue\n",
    "        picked.append(s)\n",
    "        seen.add(norm)\n",
    "        if len(picked) >= max_sents:\n",
    "            break\n",
    "\n",
    "    if not picked:\n",
    "        # 백업: 첫 청크 앞부분을 잘라서 반환\n",
    "        fallback = (chunk_texts[0] if chunk_texts else \"\").strip()\n",
    "        return (fallback[:max_chars] + \"...\") if len(fallback) > max_chars else fallback\n",
    "\n",
    "    ans = \" \".join(picked)\n",
    "    return (ans[:max_chars] + \"...\") if len(ans) > max_chars else ans\n",
    "\n",
    "# --------------------------- 메인: raptor_search ---------------------------\n",
    "def raptor_search(query: str, top_k_nodes=3, chunks_per_node=3, max_sents=5, max_chars=800):\n",
    "    # 1) 관련 노드 고르기 (요약 매칭)\n",
    "    cand_nodes = rank_nodes_by_query(query, top_k=top_k_nodes)\n",
    "    # 백업: 점수 0이면 루트/레벨 낮은 순서에서 몇 개라도 선택\n",
    "    if not cand_nodes:\n",
    "        lvl_pairs = sorted([(nd.get(\"level\", 999), nid) for nid, nd in node_by_id.items()])[:top_k_nodes]\n",
    "        cand_nodes = [nid for _, nid in lvl_pairs]\n",
    "\n",
    "    # 2) 노드에 연결된 청크 중에서 관련도 높은 것 추리기\n",
    "    cand_chunks = rank_chunks_for_nodes(query, cand_nodes, per_node=chunks_per_node)\n",
    "    if not cand_chunks:\n",
    "        # 백업: 노드에 달린 첫 청크라도 사용\n",
    "        for nid in cand_nodes:\n",
    "            for cid in node2chunks.get(nid, [])[:chunks_per_node]:\n",
    "                cand_chunks.append(cid)\n",
    "        # 그래도 없으면 전체 청크에서 일부\n",
    "        if not cand_chunks:\n",
    "            cand_chunks = list(chunk_by_id.keys())[:chunks_per_node]\n",
    "\n",
    "    # 3) 답변 만들기 (추출식)\n",
    "    chunk_texts = [chunk_by_id[cid][\"text\"] for cid in cand_chunks if cid in chunk_by_id]\n",
    "    answer = make_answer(query, chunk_texts, max_sents=max_sents, max_chars=max_chars)\n",
    "\n",
    "    # 4) 디버그/설명용 메타\n",
    "    used = {\n",
    "        \"nodes\": [{\"id\": nid, \"summary\": node_by_id[nid].get(\"summary\",\"\")} for nid in cand_nodes],\n",
    "        \"chunks\": [{\"id\": cid, \"preview\": (chunk_by_id[cid].get(\"text\",\"\")[:160] + \"...\")} for cid in cand_chunks]\n",
    "    }\n",
    "    return answer, used\n",
    "\n",
    "# ============================ 사용 예시 ============================\n",
    "# query = \"Who are the Dursleys?\"\n",
    "# ans, meta = raptor_search(query)\n",
    "# print(\"[Answer]\\n\", ans)\n",
    "# print(\"\\n[Used nodes]\")\n",
    "# for it in meta[\"nodes\"]: print(\"-\", it[\"id\"], \":\", it[\"summary\"])\n",
    "# print(\"\\n[Used chunks]\")\n",
    "# for it in meta[\"chunks\"]: print(\"-\", it[\"id\"], \":\", it[\"preview\"])\n",
    "# ==================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ac8086-a906-4ed4-a004-028c0c1d7312",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raptor_tree.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp_chunks_100tok.dedup.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraptor_tree.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     tree \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)  \u001b[38;5;66;03m# Day2에서 만든 노드-요약 구조\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# === 2. 간단 검색 함수 ===\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raptor_tree.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# === 1. 데이터 불러오기 ===\n",
    "with open(\"hp_chunks_100tok.dedup.jsonl\", \"r\") as f:\n",
    "    chunks = [json.loads(line) for line in f]\n",
    "\n",
    "with open(\"raptor_tree.json\", \"r\") as f:\n",
    "    tree = json.load(f)  # Day2에서 만든 노드-요약 구조\n",
    "\n",
    "# === 2. 간단 검색 함수 ===\n",
    "def raptor_search(query, tree, chunks, topk=2):\n",
    "    # 노드 요약 텍스트 모음\n",
    "    node_ids = list(tree.keys())\n",
    "    summaries = [tree[n][\"summary\"] for n in node_ids]\n",
    "\n",
    "    # TF-IDF 기반 검색\n",
    "    vec = TfidfVectorizer().fit(summaries + [query])\n",
    "    q_vec = vec.transform([query])\n",
    "    sims = cosine_similarity(q_vec, vec.transform(summaries))[0]\n",
    "\n",
    "    # 상위 노드 뽑기\n",
    "    top_idx = sims.argsort()[-topk:][::-1]\n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        node_id = node_ids[idx]\n",
    "        node = tree[node_id]\n",
    "        child_chunks = [c for c in node[\"children\"] if c.startswith(\"C\")]\n",
    "        chunk_texts = [c[\"text\"] for c in chunks if c[\"id\"] in child_chunks]\n",
    "        results.append({\n",
    "            \"node\": node_id,\n",
    "            \"summary\": node[\"summary\"],\n",
    "            \"chunks\": chunk_texts\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# === 3. 실행 ===\n",
    "query = \"What strange events happened on Privet Drive?\"\n",
    "res = raptor_search(query, tree, chunks)\n",
    "\n",
    "for r in res:\n",
    "    print(\"📌 Node:\", r[\"node\"])\n",
    "    print(\"📝 Summary:\", r[\"summary\"])\n",
    "    print(\"📑 Chunks:\", r[\"chunks\"][:2])  # 일부만 출력\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32382daa-1930-48d3-ab2c-979b8fbc293f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
