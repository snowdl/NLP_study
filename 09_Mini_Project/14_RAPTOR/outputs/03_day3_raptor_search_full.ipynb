{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bcb730fa-d9c7-44ae-8557-f9348500d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 ‚Äî Setup Base Path\n",
    "from pathlib import Path\n",
    "import os, json\n",
    "\n",
    "# Print current working directory\n",
    "#print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Set BASE path (up to the folder containing 'outputs')\n",
    "#BASE = Path.home() / \"/NLP_study/09_Mini_Project/13_RAPTOR\"\n",
    "#print(\"BASE path:\", BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ebdf628-7a24-4646-89d9-f1ff618d867d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef read_jsonl(path):\\n    Read a JSONL (JSON Lines) file line by line.\\n    Args:path (Path or str): File path to .jsonl file\\n     Returns:\\n        list: A list of parsed JSON objects (dicts)\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 ‚Äî JSONL Reader\n",
    "\"\"\"\n",
    "def read_jsonl(path):\n",
    "    Read a JSONL (JSON Lines) file line by line.\n",
    "    Args:path (Path or str): File path to .jsonl file\n",
    "     Returns:\n",
    "        list: A list of parsed JSON objects (dicts)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "505d08b1-f73d-4671-a2fd-f54e36f39eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path):\n",
    "    out = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            if not line: \n",
    "                continue\n",
    "            out.append(json.loads(line))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df66b15c-38ce-4b91-97b9-89dfc6978a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Number of chunks: 227\n",
      "‚úÖ Number of nodes: 6\n"
     ]
    }
   ],
   "source": [
    "# Step 2 ‚Äî Load Data Files\n",
    "\n",
    "# Load raw chunks and nodes from outputs folder\n",
    "chunks_raw = read_jsonl(BASE / \"outputs/chunks.jsonl\")\n",
    "nodes_raw  = read_jsonl(BASE / \"outputs/tree_nodes.jsonl\")\n",
    "\n",
    "# Print basic stats\n",
    "print(\"‚úÖ Number of chunks:\", len(chunks_raw))\n",
    "print(\"‚úÖ Number of nodes:\", len(nodes_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0717ab4-235b-416e-b55a-b3cc17c3ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 ‚Äî Inspect Key Structure (Sample Records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b043b5e-6ccc-4a8b-a7d1-83fea00f50d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Chunk sample: {'chunk_id': 'C0001', 'text': 'M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you‚Äôd expect to be involved in anything strange or mysterious, because they just didn‚Äôt hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere. The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn‚Äôt think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley‚Äôs sister, but they hadn‚Äôt met for several years; in fact, Mrs. Dursley pretended she didn‚Äôt have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn‚Äôt want Dudley mixing with a child like that. When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair. None of them noticed a large, tawny owl flutter past the window. At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.', 'tokens': 353}\n",
      "üîë Node sample: {'node_id': 'L1_N0001', 'level': 1, 'children': ['C0001', 'C0002'], 'summary': 'This is the story of the Dursleys and the Potters.'}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 ‚Äî Inspect Sample Records\n",
    "\n",
    "# Print one example record from chunks and nodes\n",
    "print(\"üîë Chunk sample:\", chunks_raw[0])\n",
    "print(\"üîë Node sample:\", nodes_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96418fb2-c9d4-46f0-af20-304096890dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4. Schema Standardization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e11e73c-6e1e-4f4b-90d7-64cb759ab20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4.1 ‚Äî Common Utility: Key Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd71406c-9c39-4100-b4f1-28561e3d187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_first_key(d, candidates, default=None):\n",
    "    \"\"\"\n",
    "    Find the first matching key from a list of candidate keys\n",
    "    that exists in the given dictionary.\n",
    "\n",
    "    Args:\n",
    "        d (dict): Dictionary to search.\n",
    "        candidates (list): Possible key names.\n",
    "        default: Value to return if no candidate is found.\n",
    "\n",
    "    Returns:\n",
    "        str or default: The first matching key, or the default value.\n",
    "    \"\"\"\n",
    "    for k in candidates:\n",
    "        if k in d:\n",
    "            return k\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74305f6e-e864-4e11-866f-e4a05b794fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id key found:       node_id\n",
      "summary key found:  summary\n",
      "children key found: children\n",
      " fallback (default): NONE\n"
     ]
    }
   ],
   "source": [
    "# Test dictionary\n",
    "sample_dict = {\n",
    "    \"node_id\": \"L1_N0001\",\n",
    "    \"summary\": \"This is a test summary\",\n",
    "    \"children\": [\"C0001\", \"C0002\"]\n",
    "}\n",
    "\n",
    "# Candidate lists\n",
    "id_candidates = [\"id\", \"node_id\", \"nid\"]\n",
    "summary_candidates = [\"summary\", \"text\", \"desc\"]\n",
    "children_candidates = [\"children\", \"kids\", \"child_ids\"]\n",
    "\n",
    "print(\"id key found:      \", pick_first_key(sample_dict, id_candidates))\n",
    "print(\"summary key found: \", pick_first_key(sample_dict, summary_candidates))\n",
    "print(\"children key found:\", pick_first_key(sample_dict, children_candidates))\n",
    "\n",
    "# Edge case: no matching key\n",
    "print(\" fallback (default):\", pick_first_key(sample_dict, [\"nonexistent\", \"ghost\"], default=\"NONE\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8aea1389-2bcf-4e60-a3ca-7879b12290ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Normalize a single node dictionary into a standard format.\\n    Input example (raw node may vary):\\n    {\\n        \"node_id\": \"L1_N0001\",\\n        \"summary\": \"This is a test summary\",\\n        \"children\": [\"C0001\", \"C0002\"]\\n    }\\n\\n    Output (standardized):\\n    {\\n        \"id\": \"L1_N0001\",\\n        \"summary\": \"This is a test summary\",\\n        \"children\": [\"C0001\", \"C0002\"]\\n    }\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2) Normalize a Single Node\n",
    "\"\"\"\n",
    "    Normalize a single node dictionary into a standard format.\n",
    "    Input example (raw node may vary):\n",
    "    {\n",
    "        \"node_id\": \"L1_N0001\",\n",
    "        \"summary\": \"This is a test summary\",\n",
    "        \"children\": [\"C0001\", \"C0002\"]\n",
    "    }\n",
    "\n",
    "    Output (standardized):\n",
    "    {\n",
    "        \"id\": \"L1_N0001\",\n",
    "        \"summary\": \"This is a test summary\",\n",
    "        \"children\": [\"C0001\", \"C0002\"]\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0581ce0-7def-42c5-8bb6-b8021efe71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_node(n):\n",
    "\n",
    "    # Identify possible key names\n",
    "    id_key = pick_first_key(n, ['id', 'node_id', 'nid', 'name'])\n",
    "    sum_key = pick_first_key(n, ['summary', 'text', 'desc', 'title'])\n",
    "    ch_key  = pick_first_key(n, ['children', 'child_ids', 'kids', 'links'])\n",
    "\n",
    "    # Extract values\n",
    "    node_id = n.get(id_key, None)\n",
    "    summary = n.get(sum_key, \"\")\n",
    "    children = n.get(ch_key, [])\n",
    "\n",
    "    # Fix edge cases\n",
    "    if isinstance(children, str):\n",
    "        children = [children]     # make single child into list\n",
    "    if children is None:\n",
    "        children = []             # ensure list\n",
    "\n",
    "    # Return standardized format\n",
    "    if node_id:\n",
    "        return {\"id\": node_id, \"summary\": summary, \"children\": children}\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e553d00d-e6d4-425b-9cdf-63880efc97f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Raw node:\n",
      "{'node_id': 'L1_N0001', 'summary': 'This is the story of the Dursleys and the Potters.', 'children': ['C0001', 'C0002']}\n",
      " Normalized node:\n",
      "{'id': 'L1_N0001', 'summary': 'This is the story of the Dursleys and the Potters.', 'children': ['C0001', 'C0002']}\n"
     ]
    }
   ],
   "source": [
    "# Example raw node (simulate one record)\n",
    "sample_node = {\n",
    "    \"node_id\": \"L1_N0001\",\n",
    "    \"summary\": \"This is the story of the Dursleys and the Potters.\",\n",
    "    \"children\": [\"C0001\", \"C0002\"]\n",
    "}\n",
    "\n",
    "# Run normalization\n",
    "normalized = normalize_node(sample_node)\n",
    "\n",
    "print(\" Raw node:\")\n",
    "print(sample_node)\n",
    "print(\" Normalized node:\")\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b87df40c-e133-4cc5-855d-454938456749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Standardize Multiple Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12567356-35b5-4f9e-b094-cacbae77a3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Normalize a list of raw node dictionaries into a clean list.\\n\\n    Each output node will always have:\\n      - \\'id\\' (string)\\n      - \\'summary\\' (string)\\n      - \\'children\\' (list of IDs)\\n\\n    Example Input:\\n    [\\n        {\"node_id\": \"L1_N0001\", \"summary\": \"Dursleys intro\", \"children\": [\"C0001\"]},\\n        {\"nid\": \"L1_N0002\", \"text\": \"Potters appear\", \"child_ids\": [\"C0002\", \"C0003\"]}\\n    ]\\n\\n    Example Output:\\n    [\\n        {\"id\": \"L1_N0001\", \"summary\": \"Dursleys intro\", \"children\": [\"C0001\"]},\\n        {\"id\": \"L1_N0002\", \"summary\": \"Potters appear\", \"children\": [\"C0002\", \"C0003\"]}\\n    ]\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Normalize a list of raw node dictionaries into a clean list.\n",
    "\n",
    "    Each output node will always have:\n",
    "      - 'id' (string)\n",
    "      - 'summary' (string)\n",
    "      - 'children' (list of IDs)\n",
    "\n",
    "    Example Input:\n",
    "    [\n",
    "        {\"node_id\": \"L1_N0001\", \"summary\": \"Dursleys intro\", \"children\": [\"C0001\"]},\n",
    "        {\"nid\": \"L1_N0002\", \"text\": \"Potters appear\", \"child_ids\": [\"C0002\", \"C0003\"]}\n",
    "    ]\n",
    "\n",
    "    Example Output:\n",
    "    [\n",
    "        {\"id\": \"L1_N0001\", \"summary\": \"Dursleys intro\", \"children\": [\"C0001\"]},\n",
    "        {\"id\": \"L1_N0002\", \"summary\": \"Potters appear\", \"children\": [\"C0002\", \"C0003\"]}\n",
    "    ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d375bffc-0470-4828-af26-34a5023152cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_nodes(nodes):\n",
    "    out = []\n",
    "    for n in nodes:\n",
    "        std = normalize_node(n)   # use single-node normalization\n",
    "        if std:                   # keep only valid nodes with id\n",
    "            out.append(std)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64aa2548-be91-4ecb-88e2-c42148447374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized nodes:\n",
      "{'id': 'L1_N0001', 'summary': 'Dursleys intro', 'children': ['C0001']}\n",
      "{'id': 'L1_N0002', 'summary': 'Potters appear', 'children': ['C0002', 'C0003']}\n",
      "{'id': 'L1_N0003', 'summary': 'Mysterious cat shows up', 'children': ['C0004']}\n"
     ]
    }
   ],
   "source": [
    "# Example list of raw nodes\n",
    "sample_nodes = [\n",
    "    {\"node_id\": \"L1_N0001\", \"summary\": \"Dursleys intro\", \"children\": [\"C0001\"]},\n",
    "    {\"nid\": \"L1_N0002\", \"text\": \"Potters appear\", \"child_ids\": [\"C0002\", \"C0003\"]},\n",
    "    {\"name\": \"L1_N0003\", \"desc\": \"Mysterious cat shows up\", \"kids\": [\"C0004\"]}\n",
    "]\n",
    "\n",
    "# Apply standardization\n",
    "normalized_nodes = standardize_nodes(sample_nodes)\n",
    "\n",
    "print(\"Normalized nodes:\")\n",
    "for n in normalized_nodes:\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35798f9c-6f59-44d5-8f3f-3891e24b8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)Normalize a Single Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "522efc8f-bfa9-4a4a-a81a-9f32a601955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_chunk(c):\n",
    "    # Identify possible key names\n",
    "    id_key = pick_first_key(c, ['id', 'chunk_id', 'cid'])\n",
    "    txt_key = pick_first_key(c, ['text', 'content', 'body'])\n",
    "\n",
    "    # Extract values\n",
    "    cid = c.get(id_key, None)\n",
    "    txt = c.get(txt_key, \"\")\n",
    "\n",
    "    if cid:\n",
    "        return cid, txt\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "857db4d0-8e71-472e-9b29-786b5b4eb787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw chunk: {'chunk_id': 'C0001', 'text': 'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say...'}\n",
      "Normalized output:\n",
      "ID: C0001\n",
      "Text: Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say......\n"
     ]
    }
   ],
   "source": [
    "# Example raw chunk\n",
    "sample_chunk = {\n",
    "    \"chunk_id\": \"C0001\",\n",
    "    \"text\": \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say...\"\n",
    "}\n",
    "\n",
    "# Run normalization\n",
    "cid, txt = normalize_chunk(sample_chunk)\n",
    "\n",
    "print(\"Raw chunk:\", sample_chunk)\n",
    "print(\"Normalized output:\")\n",
    "print(\"ID:\", cid)\n",
    "print(\"Text:\", txt[:80] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5825351-5ed0-4031-9bcd-6ccd34b46912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Standardize Multiple Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "683674c5-296f-4746-8b58-c9bddfcf1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_chunks(chunks):\n",
    "    out = {}\n",
    "    for c in chunks:\n",
    "        cid, txt = normalize_chunk(c)  # reuse the single-chunk normalizer\n",
    "        if cid:\n",
    "            out[cid] = txt\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e09b26bf-23f9-4196-aa35-07e6ffbef229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Standardized chunk map keys: ['C0001', 'C0002', 'C0003']\n",
      "üìù C0001 preview: Mr. and Mrs. Dursley, of number four, Privet Drive......\n",
      "üìù C0002 preview: Dudley was now having a tantrum and throwing his cereal......\n",
      "üìù C0003 preview: There was a tabby cat standing on the corner of Privet Drive......\n"
     ]
    }
   ],
   "source": [
    "# Sample raw chunks (mixed schemas)\n",
    "sample_chunks = [\n",
    "    {\"chunk_id\": \"C0001\", \"text\": \"Mr. and Mrs. Dursley, of number four, Privet Drive...\"},\n",
    "    {\"cid\": \"C0002\", \"content\": \"Dudley was now having a tantrum and throwing his cereal...\"},\n",
    "    {\"id\": \"C0003\", \"body\": \"There was a tabby cat standing on the corner of Privet Drive...\"}\n",
    "]\n",
    "\n",
    "chunk_map = standardize_chunks(sample_chunks)\n",
    "\n",
    "print(\"‚úÖ Standardized chunk map keys:\", list(chunk_map.keys()))\n",
    "print(\"üìù C0001 preview:\", chunk_map[\"C0001\"][:70] + \"...\")\n",
    "print(\"üìù C0002 preview:\", chunk_map[\"C0002\"][:70] + \"...\")\n",
    "print(\"üìù C0003 preview:\", chunk_map[\"C0003\"][:70] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c11fecf0-f09b-4638-826a-a1a996d35766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5. Run Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1511b34b-c45e-4c4d-8de8-93ec51fd4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Number of standardized nodes: 6\n",
      "‚úÖ Number of standardized chunks: 227\n",
      "\n",
      "üìù Example standardized node:\n",
      "{'id': 'L1_N0001', 'summary': 'This is the story of the Dursleys and the Potters.', 'children': ['C0001', 'C0002']}\n",
      "\n",
      "üìù Example standardized chunk:\n",
      "C0001 ‚Üí M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they...\n"
     ]
    }
   ],
   "source": [
    "# Apply normalization to raw data\n",
    "\n",
    "nodes = standardize_nodes(nodes_raw)\n",
    "chunk_map = standardize_chunks(chunks_raw)\n",
    "\n",
    "print(\"‚úÖ Number of standardized nodes:\", len(nodes))\n",
    "print(\"‚úÖ Number of standardized chunks:\", len(chunk_map))\n",
    "\n",
    "print(\"\\nüìù Example standardized node:\")\n",
    "print(nodes[0])\n",
    "\n",
    "print(\"\\nüìù Example standardized chunk:\")\n",
    "first_chunk_id = list(chunk_map.keys())[0]\n",
    "print(first_chunk_id, \"‚Üí\", chunk_map[first_chunk_id][:80] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1848a611-f061-44fb-9eca-917754091249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 2 results\n",
      "üìå Node: L1_N0003 | score: 0.1081\n",
      "üìù Summary: Dudley and Petunia Dursley had a strange day.\n",
      "üîó Chunks: ['C0005']\n",
      "------------------------------------------------------------\n",
      "üìå Node: L3_N0001 | score: 0.0\n",
      "üìù Summary: All images are copyrighted.\n",
      "üîó Chunks: []\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Collected {len(results)} results\")\n",
    "\n",
    "# save results as 'res' so it looks same as function version\n",
    "res = results\n",
    "\n",
    "for r in res:\n",
    "    print(\"üìå Node:\", r[\"node_id\"], \"| score:\", round(r[\"score\"], 4))\n",
    "    print(\"üìù Summary:\", (r[\"node_summary\"] or \"\")[:140] + (\"...\" if len(r[\"node_summary\"]) > 140 else \"\"))\n",
    "    print(\"üîó Chunks:\", r[\"linked_chunk_ids\"])\n",
    "    for i, t in enumerate(r[\"chunk_texts\"], 1):\n",
    "        print(f\"   [{i}] {t[:160]}{'...' if len(t) > 160 else ''}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "982ab29b-0727-42a5-a829-685a2040d073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Retrieve relevant RAPTOR nodes and their linked chunks using a simple TF-IDF search\\n    over node summaries.\\n\\n    Args:\\n        query: user query string\\n        nodes: standardized node list (each has keys: id, summary, children)\\n        chunk_map: dict {chunk_id: text}\\n        topk_nodes: number of top nodes to return\\n        max_chunks_per_node: max number of chunk texts to attach per node\\n        chunk_id_prefix: filter for children IDs that represent chunks (e.g., \"C\")\\n\\n    Returns:\\n        List of dicts:\\n        [\\n          {\\n            \"node_id\": str,\\n            \"node_summary\": str,\\n            \"score\": float,\\n            \"linked_chunk_ids\": [str, ...],\\n            \"chunk_texts\": [str, ...]\\n          },\\n          ...\\n        ]\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 6. RAPTOR Search Function\n",
    "\n",
    "\"\"\"\n",
    "    Retrieve relevant RAPTOR nodes and their linked chunks using a simple TF-IDF search\n",
    "    over node summaries.\n",
    "\n",
    "    Args:\n",
    "        query: user query string\n",
    "        nodes: standardized node list (each has keys: id, summary, children)\n",
    "        chunk_map: dict {chunk_id: text}\n",
    "        topk_nodes: number of top nodes to return\n",
    "        max_chunks_per_node: max number of chunk texts to attach per node\n",
    "        chunk_id_prefix: filter for children IDs that represent chunks (e.g., \"C\")\n",
    "\n",
    "    Returns:\n",
    "        List of dicts:\n",
    "        [\n",
    "          {\n",
    "            \"node_id\": str,\n",
    "            \"node_summary\": str,\n",
    "            \"score\": float,\n",
    "            \"linked_chunk_ids\": [str, ...],\n",
    "            \"chunk_texts\": [str, ...]\n",
    "          },\n",
    "          ...\n",
    "        ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2bf67-2570-40b2-8844-e9c6ff372f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162f411-7c63-4f6a-b492-a32d1e9bd89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e7757-009d-43a7-b5eb-fe3394a60e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a9f0b5ed-bfed-4cba-9f1e-b7d46ef489d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def raptor_search(\n",
    "    query: str,\n",
    "    nodes: List[Dict[str, Any]],\n",
    "    chunk_map: Dict[str, str],\n",
    "    topk_nodes: int = 2,\n",
    "    max_chunks_per_node: int = 2,\n",
    "    chunk_id_prefix: str = \"C\",\n",
    ") -> List[Dict[str, Any]]:\n",
    "    # Always return a list\n",
    "    if not nodes or not isinstance(chunk_map, dict) or not chunk_map:\n",
    "        return []\n",
    "\n",
    "    # (1) preprocess\n",
    "    triples = [(n[\"id\"], n.get(\"summary\", \"\") or \"\", n.get(\"children\", []) or []) for n in nodes]\n",
    "    node_ids       = [nid for nid, _, _ in triples]\n",
    "    node_summaries = [s for _, s, _ in triples]\n",
    "    node_children  = [ch for _, _, ch in triples]\n",
    "\n",
    "    # (2)(3) tf-idf + vectorize\n",
    "    vec  = TfidfVectorizer().fit(node_summaries + [query])\n",
    "    qvec = vec.transform([query])\n",
    "    nmat = vec.transform(node_summaries)\n",
    "\n",
    "    # (4) rank\n",
    "    sims  = cosine_similarity(qvec, nmat)[0]\n",
    "    order = sims.argsort()[::-1]\n",
    "\n",
    "    # (5) collect\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    for idx in order[:topk_nodes]:\n",
    "        nid, nsum, children = node_ids[idx], node_summaries[idx], node_children[idx]\n",
    "        child_chunk_ids = [c for c in children if isinstance(c, str) and c.startswith(chunk_id_prefix)]\n",
    "        child_chunk_ids = child_chunk_ids[:max_chunks_per_node]\n",
    "        texts = [chunk_map[cid] for cid in child_chunk_ids if cid in chunk_map]\n",
    "        results.append({\n",
    "            \"node_id\": nid,\n",
    "            \"node_summary\": nsum,\n",
    "            \"score\": float(sims[idx]),\n",
    "            \"linked_chunk_ids\": child_chunk_ids,\n",
    "            \"chunk_texts\": texts\n",
    "        })\n",
    "    return results  # ‚Üê Î∞òÎìúÏãú Î¶¨Ïä§Ìä∏ Î∞òÌôò\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b12dce13-d217-4fb7-bdf7-24e9b5767333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res type: <class 'list'> len: 2\n",
      "Node: L1_N0003 | score: 0.1081\n",
      "Summary: Dudley and Petunia Dursley had a strange day.\n",
      "Chunks: ['C0005']\n",
      "   [1] When Dudley had been put to bed, he went into the living room in time to catch the last report on the evening news:\n",
      "\n",
      "‚ÄúAnd finally, bird-watchers everywhere have...\n",
      "------------------------------------------------------------\n",
      "Node: L3_N0001 | score: 0.0\n",
      "Summary: All images are copyrighted.\n",
      "Chunks: []\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 7 ‚Äî Run RAPTOR Search & Show Results\n",
    "query = \"What strange events happened on Privet Drive?\"\n",
    "res = raptor_search(query, nodes, chunk_map, topk_nodes=2, max_chunks_per_node=2)\n",
    "\n",
    "print(\"res type:\", type(res), \"len:\", len(res))\n",
    "for r in res:\n",
    "    print(\"Node:\", r[\"node_id\"], \"| score:\", round(r[\"score\"], 4))\n",
    "    print(\"Summary:\", (r[\"node_summary\"] or \"\")[:140] + (\"...\" if len(r[\"node_summary\"]) > 140 else \"\"))\n",
    "    print(\"Chunks:\", r[\"linked_chunk_ids\"])\n",
    "    for i, t in enumerate(r[\"chunk_texts\"], 1):\n",
    "        print(f\"   [{i}] {t[:160]}{'...' if len(t) > 160 else ''}\")\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c41a9b9d-37aa-4801-9de9-e9b34071eae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes count: 6\n",
      "chunk_map type/len: <class 'dict'> 227\n",
      "raptor_search is: <function raptor_search at 0x105990040>\n",
      "raptor_search doc: None\n"
     ]
    }
   ],
   "source": [
    "print(\"nodes count:\", 0 if nodes is None else len(nodes))\n",
    "print(\"chunk_map type/len:\", type(chunk_map), 0 if not isinstance(chunk_map, dict) else len(chunk_map))\n",
    "print(\"raptor_search is:\", raptor_search)\n",
    "print(\"raptor_search doc:\", getattr(raptor_search, \"__doc__\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adbbfce-b487-4f78-92be-9a9e7b356f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22d55e-a461-4d87-a3d3-7d80a174c6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9877f-7b9c-4372-888b-2173c8773917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208931a-8ca5-46e1-864b-dbb87106910d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b65fa-98e4-4048-b6ea-5e12271c6e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
