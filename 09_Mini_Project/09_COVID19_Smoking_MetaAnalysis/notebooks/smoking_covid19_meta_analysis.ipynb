{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adfb7502-1f17-4d44-9499-37e4c51f9f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # GPU 사용 가능 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78f4fbb7-1722-4bce-9a14-4f58eda04b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "612f9032-9c97-4d9a-8f50-a63d04adb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_path = \"11_data/Smoking Status.csv\"\n",
    "df = pd.read_csv(smoking_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b63592d-371f-4b4c-8189-018c77aa5bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Date', 'Study', 'Study Link', 'Journal', 'Severe',\n",
       "       'Severe lower bound', 'Severe upper bound', 'Severe p-value',\n",
       "       'Severe Significant', 'Severe Adjusted', 'Severe Calculated',\n",
       "       'Fatality', 'Fatality lower bound', 'Fatality upper bound',\n",
       "       'Fatality p-value', 'Fatality Significant', 'Fatality Adjusted',\n",
       "       'Fatality Calculated', 'Multivariate adjustment', 'Study Type',\n",
       "       'Sample Size', 'Study Population', 'Added on', 'Critical only',\n",
       "       'Discharged vs. death?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e674bee1-8387-4f80-bc28-10d7ff72e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) 각 엔드포인트(Severe, Fatality)별 log(OR) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3245de47-856f-4906-b274-3a8742aab86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_endpoint(df, prefix):\n",
    "    lo = df[f\"{prefix} lower bound\"].astype(float)   # Convert the lower bound column to float type\n",
    "    hi = df[f\"{prefix} upper bound\"].astype(float)   # Convert the upper bound column to float type\n",
    "    pv = pd.to_numeric(df.get(f\"{prefix} p-value\"), errors=\"coerce\")  # Convert p-value column to numeric, invalid values become NaN\n",
    "\n",
    "    # Calculate log(OR): Approximate the point estimate as sqrt(lower * upper), then take the natural log\n",
    "    log_or = np.log(np.sqrt(lo * hi))\n",
    "\n",
    "    # Calculate standard error (SE) from 95% CI formula\n",
    "    se = (np.log(hi) - np.log(lo)) / (2*1.96)\n",
    "\n",
    "    # Variance = SE²\n",
    "    var = se**2\n",
    "\n",
    "    # Return as a new DataFrame\n",
    "    return pd.DataFrame({\n",
    "        \"lower\": lo,\n",
    "        \"upper\": hi,\n",
    "        \"pvalue\": pv,\n",
    "        \"log_or\": log_or,\n",
    "        \"se\": se,\n",
    "        \"var\": var\n",
    "    }).dropna(subset=[\"log_or\",\"var\"])  # Drop rows where log_or or var is NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74ea8c2c-bc46-4470-a78a-acf013b0282d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n fixed-effect model : Assumption: All studies share the same true effect.\\n → Any differences between study results are purely due to sampling error.\\nAdvantages:\\nSimple to calculate, stable with small sample sizes.\\nAppropriate when study results are highly consistent (low heterogeneity).\\nDisadvantages:\\nCan be biased if heterogeneity is high.\\n\\n\\n random-effects model: The true effect may vary across studies.\\nAssumption: The true effect may vary across studies.\\n→ Differences can come from variations in participants, settings, or study designs.\\nAdvantages:\\nAccounts for between-study variance (τ²), making it more realistic.\\nWider confidence intervals → more conservative estimates.\\nDisadvantages:\\nLess stable with small sample sizes.\\nIf heterogeneity is very low, it may unnecessarily widen the CI.\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3) pooling func\n",
    "\"\"\"\n",
    " fixed-effect model : Assumption: All studies share the same true effect.\n",
    " → Any differences between study results are purely due to sampling error.\n",
    "Advantages:\n",
    "Simple to calculate, stable with small sample sizes.\n",
    "Appropriate when study results are highly consistent (low heterogeneity).\n",
    "Disadvantages:\n",
    "Can be biased if heterogeneity is high.\n",
    "\n",
    "\n",
    " random-effects model: The true effect may vary across studies.\n",
    "Assumption: The true effect may vary across studies.\n",
    "→ Differences can come from variations in participants, settings, or study designs.\n",
    "Advantages:\n",
    "Accounts for between-study variance (τ²), making it more realistic.\n",
    "Wider confidence intervals → more conservative estimates.\n",
    "Disadvantages:\n",
    "Less stable with small sample sizes.\n",
    "If heterogeneity is very low, it may unnecessarily widen the CI.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c609e01a-4f9a-4be0-8816-523ca2ba13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_fixed(log_or, var):\n",
    "    # 1. Calculate weights for each study: inverse of variance\n",
    "    #    Smaller variance (more precise estimate) → larger weight.\n",
    "    w = 1.0 / var\n",
    "\n",
    "    # 2. Compute the weighted average of log(OR)\n",
    "    #    Sum of (log(OR) * weight) divided by total weight.\n",
    "    est = np.sum(w * log_or) / np.sum(w)\n",
    "\n",
    "    # 3. Calculate the overall Standard Error (SE)\n",
    "    #    SE = sqrt(1 / sum of weights)\n",
    "    se = np.sqrt(1.0 / np.sum(w))\n",
    "\n",
    "    # 4. Calculate the 95% Confidence Interval (CI) on the log scale\n",
    "    #    CI = estimate ± 1.96 * SE  (1.96 is the z-score for 95% CI)\n",
    "    ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "\n",
    "    # 5. Return: pooled log(OR) estimate and its 95% CI\n",
    "    return est, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a6a69f5-f76c-41e7-bcee-266b990e76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_random_DL(log_or, var):\n",
    "    # 1. Initial weights (fixed-effect weights) = inverse of variance\n",
    "    w = 1.0 / var\n",
    "\n",
    "    # 2. Number of studies\n",
    "    k = len(log_or)\n",
    "\n",
    "    # 3. Fixed-effect pooled estimate of log(OR)\n",
    "    est_fixed = np.sum(w * log_or) / np.sum(w)\n",
    "\n",
    "    # 4. Cochran’s Q statistic: measures total heterogeneity across studies\n",
    "    Q = np.sum(w * (log_or - est_fixed) ** 2)\n",
    "\n",
    "    # 5. c is a constant used in the DerSimonian–Laird tau² formula\n",
    "    c = np.sum(w) - (np.sum(w ** 2) / np.sum(w))\n",
    "\n",
    "    # 6. Between-study variance (tau²) using the DerSimonian–Laird method\n",
    "    #    If tau² < 0, set to 0 (no between-study variance).\n",
    "    tau2 = max(0.0, (Q - (k - 1)) / c) if k > 1 else 0.0\n",
    "\n",
    "    # 7. Random-effects weights: incorporate both within-study variance and between-study variance (tau²)\n",
    "    w_star = 1.0 / (var + tau2)\n",
    "\n",
    "    # 8. Random-effects pooled estimate of log(OR)\n",
    "    est = np.sum(w_star * log_or) / np.sum(w_star)\n",
    "\n",
    "    # 9. Standard Error (SE) of the pooled estimate\n",
    "    se = np.sqrt(1.0 / np.sum(w_star))\n",
    "\n",
    "    # 10. 95% Confidence Interval (log scale)\n",
    "    ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "\n",
    "    # 11. I² statistic: percentage of total variation due to between-study heterogeneity\n",
    "    I2 = max(0.0, (Q - (k - 1)) / Q) * 100 if k > 1 and Q > (k - 1) else 0.0\n",
    "\n",
    "    # Return: pooled log(OR), 95% CI, tau², and I²\n",
    "    return est, ci, tau2, I2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b0b7cc0-3736-4fd6-a77f-a8bffd9666b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Severe & Fatality 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fe685a9-09ca-4c1f-ba86-9bbb477b7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Severe] Random-effects OR=1.80 (95% CI 1.56–2.07), I²=68.5% → Smoking risk ↑\n",
      "[Fatality] Random-effects OR=1.27 (95% CI 1.12–1.44), I²=54.1% → Smoking risk ↑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_automl_env/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for ep in [\"Severe\", \"Fatality\"]:\n",
    "    # 1. Build the endpoint DataFrame (lower, upper, p-value, log_or, SE, var)\n",
    "    ep_df = build_endpoint(df, ep)\n",
    "    \n",
    "    # 2. Skip if there is no usable data for this endpoint\n",
    "    if len(ep_df) == 0:\n",
    "        print(f\"[{ep}] usable data 없음\")  # \"no usable data\"\n",
    "        continue\n",
    "\n",
    "    # 3. Calculate the fixed-effect pooled estimate (log scale)\n",
    "    est_f, ci_f = pooled_fixed(ep_df[\"log_or\"], ep_df[\"var\"])\n",
    "\n",
    "    # 4. Calculate the random-effects pooled estimate (log scale)\n",
    "    est_r, ci_r, tau2, I2 = pooled_random_DL(ep_df[\"log_or\"], ep_df[\"var\"])\n",
    "\n",
    "    # 5. Convert the random-effects log(OR) estimate and CI back to OR scale\n",
    "    or_r = np.exp(est_r)\n",
    "    lo_r, hi_r = np.exp(ci_r[0]), np.exp(ci_r[1])\n",
    "\n",
    "    # 6. Interpret the result:\n",
    "    #    - If lower CI > 1 → smoking increases risk\n",
    "    #    - If upper CI < 1 → smoking decreases risk\n",
    "    #    - Otherwise → no clear difference\n",
    "    verdict = \"Smoking risk ↑\" if lo_r > 1 else (\"Smoking risk ↓\" if hi_r < 1 else \"No clear difference\")\n",
    "\n",
    "    # 7. Print the random-effects result with OR, 95% CI, I², and interpretation\n",
    "    print(f\"[{ep}] Random-effects OR={or_r:.2f} (95% CI {lo_r:.2f}–{hi_r:.2f}), \"\n",
    "          f\"I²={I2:.1f}% → {verdict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09e6dc67-79bf-43d9-9ae4-24210a2b23d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93c9e3-8b11-4d77-a04e-ed3cd3165283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_automl_env)",
   "language": "python",
   "name": "nlp_automl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
