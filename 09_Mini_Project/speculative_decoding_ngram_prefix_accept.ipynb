{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a79245-5373-444e-9306-c553d7502dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uni–bi–tri-gram + backoff + prefix-accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e65082-721b-4a58-95a0-3d92c7851891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMini Speculative Decoding Demo (Beginner-Friendly)\\n--------------------------------------------------\\nThis notebook shows a tiny, self-contained prototype of \"speculative decoding\":\\n- A small \"drafter\" proposes a short draft of k tokens (unigram-based).\\n- A larger \"verifier\" checks the draft and accepts only a verified prefix.\\n- On the first mismatch, we replace with the verified token and stop (prefix-accept).\\n\\nWe provide two verifiers:\\n  (A) Bigram-only verifier:      uses P(next | prev1)\\n  (B) Backoff verifier (tri→bi→uni): uses P(next | prev2, prev1), else bigram, else unigram\\n\\nEverything below is plain Python with simple frequency counts.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mini Speculative Decoding Demo (Beginner-Friendly)\n",
    "--------------------------------------------------\n",
    "This notebook shows a tiny, self-contained prototype of \"speculative decoding\":\n",
    "- A small \"drafter\" proposes a short draft of k tokens (unigram-based).\n",
    "- A larger \"verifier\" checks the draft and accepts only a verified prefix.\n",
    "- On the first mismatch, we replace with the verified token and stop (prefix-accept).\n",
    "\n",
    "We provide two verifiers:\n",
    "  (A) Bigram-only verifier:      uses P(next | prev1)\n",
    "  (B) Backoff verifier (tri→bi→uni): uses P(next | prev2, prev1), else bigram, else unigram\n",
    "\n",
    "Everything below is plain Python with simple frequency counts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eda553a-034e-46dc-a5a0-c16e6ecb9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports & reproducibility\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "random.seed(42)  # Make random sampling reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c198e54-c274-4722-b1c2-660ea2d9bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Corpus & tokenization -----------------------------------------------------\n",
    "#    You can edit the corpus to try different examples.\n",
    "corpus = \"the wolf ran into the forest\"\n",
    "tokens = corpus.lower().split()  # lowercase + whitespace tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e34c4da-3ada-40c1-9438-6874032af697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Unigram frequency (for drafter & fallback) --------------------------------\n",
    "#    counts   : global token frequencies\n",
    "#    vocab    : list of unique tokens\n",
    "#    weights  : frequency-based weights aligned with vocab order\n",
    "counts  = Counter(tokens)\n",
    "vocab   = list(counts.keys())\n",
    "weights = [counts[w] for w in vocab]\n",
    "\n",
    "def draft_tokens_unigram(k=3, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Unigram drafter (small model).\n",
    "    - Samples k tokens with replacement, using frequency-based weights.\n",
    "    - alpha > 1.0: sharpen distribution (favor frequent words more)\n",
    "    - alpha < 1.0: flatten distribution (more diversity)\n",
    "    \"\"\"\n",
    "    wts = [wt ** alpha for wt in weights]  # power transform for diversity control\n",
    "    return random.choices(vocab, weights=wts, k=k)\n",
    "\n",
    "# (Optional) Display helper: remove only consecutive duplicates for cleaner output\n",
    "def dedup_consecutive(words):\n",
    "    \"\"\"\n",
    "    Remove consecutive duplicates ONLY: ['a','a','b','b'] -> ['a','b']\n",
    "    This does NOT enforce uniqueness globally.\n",
    "    Use this only for printing if you dislike repeated neighbors.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for w in words:\n",
    "        if not out or out[-1] != w:\n",
    "            out.append(w)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc4d4a1-bf3b-4527-b24b-83c5706e7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) N-gram tables (build once) ------------------------------------------------\n",
    "#    bigram_next : dict(prev1 -> Counter(next))\n",
    "#    trigram_next: dict((prev2, prev1) -> Counter(next))\n",
    "bigram_next  = defaultdict(Counter)\n",
    "trigram_next = defaultdict(Counter)\n",
    "\n",
    "# Fill bigram table\n",
    "for a, b in zip(tokens, tokens[1:]):\n",
    "    bigram_next[a][b] += 1\n",
    "\n",
    "# Fill trigram table\n",
    "for a, b, c in zip(tokens, tokens[1:], tokens[2:]):\n",
    "    trigram_next[(a, b)][c] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039d3755-74fa-4fc4-9660-6f476b282d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Verifiers -----------------------------------------------------------------\n",
    "def verify_next_bigram(prev1):\n",
    "    \"\"\"\n",
    "    Bigram verifier:\n",
    "    Return the most frequent next token given prev1 (argmax over bigram counts).\n",
    "    If there is no entry for prev1, fall back to the global unigram-most-frequent token.\n",
    "    \"\"\"\n",
    "    dist = bigram_next.get(prev1)\n",
    "    if dist:\n",
    "        return dist.most_common(1)[0][0]\n",
    "    # Unigram fallback: global argmax\n",
    "    return max(counts, key=counts.get)\n",
    "\n",
    "def verify_next_backoff(prev2, prev1):\n",
    "    \"\"\"\n",
    "    Backoff verifier (trigram -> bigram -> unigram):\n",
    "    1) If we have trigram stats for (prev2, prev1), use the most frequent next.\n",
    "    2) Else, if we have bigram stats for prev1, use the most frequent next.\n",
    "    3) Else, fall back to the global unigram-most-frequent token.\n",
    "    \"\"\"\n",
    "    dist3 = trigram_next.get((prev2, prev1))\n",
    "    if dist3:\n",
    "        return dist3.most_common(1)[0][0]\n",
    "    dist2 = bigram_next.get(prev1)\n",
    "    if dist2:\n",
    "        return dist2.most_common(1)[0][0]\n",
    "    return max(counts, key=counts.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad749465-fee1-4bef-a045-ab5b1d5828a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Speculative decoding (prefix-accept) --------------------------------------\n",
    "def spec_prefix_accept_bigram(prompt_tokens, k=5, alpha=1.0, trace=True):\n",
    "    \"\"\"\n",
    "    Speculative step using the BIGRAM verifier.\n",
    "    - Draft k tokens with the unigram drafter.\n",
    "    - Walk left→right; if a draft token matches the verifier, accept it and extend context.\n",
    "    - On the first mismatch, replace with the verified token and STOP (prefix-accept).\n",
    "    \"\"\"\n",
    "    draft = draft_tokens_unigram(k=k, alpha=alpha)\n",
    "    accepted = []\n",
    "    prev1 = prompt_tokens[-1]  # last token of the current context\n",
    "\n",
    "    steps = []\n",
    "    for t in draft:\n",
    "        v = verify_next_bigram(prev1)\n",
    "        ok = (t == v)\n",
    "        steps.append((prev1, t, v, ok))\n",
    "        if ok:\n",
    "            accepted.append(t)\n",
    "            prev1 = t  # extend context\n",
    "        else:\n",
    "            accepted.append(v)\n",
    "            break\n",
    "\n",
    "    final = prompt_tokens + accepted\n",
    "\n",
    "    if trace:\n",
    "        for i, (p1, t, v, ok) in enumerate(steps, 1):\n",
    "            print(f\"[{i}] prev1='{p1}'  draft='{t}'  verify='{v}'  ->  {'ACCEPT' if ok else 'REPLACE+STOP'}\")\n",
    "        print(\"Draft   :\", draft)\n",
    "        print(\"Accepted:\", accepted)\n",
    "        print(\"Final   :\", \" \".join(final))\n",
    "    return draft, accepted, final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61af708e-ac84-4aee-96a5-ce46a8bbab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_prefix_accept_backoff(prompt_tokens, k=5, alpha=1.0, trace=True):\n",
    "    \"\"\"\n",
    "    Speculative step using the TRIGRAM→BIGRAM→UNIGRAM backoff verifier.\n",
    "    - Same prefix-accept logic, but the verifier considers two-token context first.\n",
    "    \"\"\"\n",
    "    draft = draft_tokens_unigram(k=k, alpha=alpha)\n",
    "    accepted = []\n",
    "\n",
    "    # Initialize (prev2, prev1) from the prompt.\n",
    "    # If prompt is very short, duplicate prev1 as a minimal fallback.\n",
    "    if len(prompt_tokens) >= 2:\n",
    "        prev2, prev1 = prompt_tokens[-2], prompt_tokens[-1]\n",
    "    else:\n",
    "        prev2, prev1 = prompt_tokens[-1], prompt_tokens[-1]\n",
    "\n",
    "    steps = []\n",
    "    for t in draft:\n",
    "        v = verify_next_backoff(prev2, prev1)\n",
    "        ok = (t == v)\n",
    "        steps.append((prev2, prev1, t, v, ok))\n",
    "        if ok:\n",
    "            accepted.append(t)\n",
    "            prev2, prev1 = prev1, t  # shift context window\n",
    "        else:\n",
    "            accepted.append(v)\n",
    "            break\n",
    "\n",
    "    final = prompt_tokens + accepted\n",
    "\n",
    "    if trace:\n",
    "        for i, (p2, p1, t, v, ok) in enumerate(steps, 1):\n",
    "            print(f\"[{i}] prev2='{p2}' prev1='{p1}'  draft='{t}'  verify='{v}'  ->  {'ACCEPT' if ok else 'REPLACE+STOP'}\")\n",
    "        print(\"Draft   :\", draft)\n",
    "        print(\"Accepted:\", accepted)\n",
    "        print(\"Final   :\", \" \".join(final))\n",
    "    return draft, accepted, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5368cbbf-dcba-417d-9bda-07cac8e36617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bigram verifier demo ===\n",
      "[1] prev1='ran'  draft='ran'  verify='into'  ->  REPLACE+STOP\n",
      "Draft   : ['ran', 'the', 'the', 'the', 'into']\n",
      "Accepted: ['into']\n",
      "Final   : the wolf ran into\n",
      "\n",
      "=== Backoff verifier (tri→bi→uni) demo ===\n",
      "[1] prev2='wolf' prev1='ran'  draft='into'  verify='into'  ->  ACCEPT\n",
      "[2] prev2='ran' prev1='into'  draft='forest'  verify='the'  ->  REPLACE+STOP\n",
      "Draft   : ['into', 'forest', 'the', 'wolf', 'the']\n",
      "Accepted: ['into', 'the']\n",
      "Final   : the wolf ran into the\n"
     ]
    }
   ],
   "source": [
    "# 7) Demo runs -----------------------------------------------------------------\n",
    "prompt = [\"the\", \"wolf\", \"ran\"]\n",
    "\n",
    "print(\"=== Bigram verifier demo ===\")\n",
    "_ = spec_prefix_accept_bigram(prompt, k=5, alpha=1.0, trace=True)\n",
    "\n",
    "print(\"\\n=== Backoff verifier (tri→bi→uni) demo ===\")\n",
    "_ = spec_prefix_accept_backoff(prompt, k=5, alpha=1.0, trace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c68d6-c52e-4430-8db3-8a19276497e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
