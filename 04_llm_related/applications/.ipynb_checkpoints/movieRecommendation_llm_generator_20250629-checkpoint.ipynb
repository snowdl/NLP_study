{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a13d1a-3d8e-4e5f-989a-2c3ad1443ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jessicahong/NLP_study/04_llm_related/applications'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os; os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fcbad3-cabb-43df-93e1-d4aac3a72b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def set_project_root(levels_up=2):\n",
    "    \"\"\"\n",
    "    Add the project root directory (levels_up above current file) to sys.path\n",
    "    so Python can find modules/packages there.\n",
    "    \"\"\"\n",
    "    current_path = os.path.abspath(os.path.dirname(__file__))\n",
    "    project_root = current_path\n",
    "    for _ in range(levels_up):\n",
    "        project_root = os.path.dirname(project_root)\n",
    "\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "        print(f\"Project root set to ( {levels_up} levels up): {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b298a48e-20fd-4d98-9f93-f4b7409d2198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies 데이터 미리보기:\n",
      "   movieId                                        title\n",
      "0       31                       Dangerous Minds (1995)\n",
      "1       32    Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "2       39                              Clueless (1995)\n",
      "3       80  White Balloon, The (Badkonake sefid) (1995)\n",
      "4      177                     Lord of Illusions (1995)\n",
      "movies shape: (49, 2)\n",
      "\n",
      "ratings 데이터 미리보기:\n",
      "   userId  movieId  rating\n",
      "0     156     3167     3.0\n",
      "1     514     1258     4.0\n",
      "2      32       39     3.0\n",
      "3     305    55276     5.0\n",
      "4     603     2020     4.0\n",
      "ratings shape: (50, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# movies.json 파일 읽기\n",
    "movies = pd.read_json('../../12_data/movies.json')\n",
    "print(\"movies 데이터 미리보기:\")\n",
    "print(movies.head())\n",
    "print(\"movies shape:\", movies.shape)\n",
    "\n",
    "# ratings.json 파일 읽기\n",
    "ratings = pd.read_json('../../12_data/ratings.json')\n",
    "print(\"\\nratings 데이터 미리보기:\")\n",
    "print(ratings.head())\n",
    "print(\"ratings shape:\", ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a85b6a-c858-4612-b5e5-01c6bf2372ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "샘플링된 ratings_small:\n",
      "    userId  movieId  rating\n",
      "13     116      356     4.0\n",
      "39      80     2513     4.0\n",
      "30     183     1408     4.0\n",
      "45     438     6503     0.5\n",
      "17     409     3868     4.0\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "ratings_small = ratings.sample(n=50, random_state=42)\n",
    "print(\"\\n샘플링된 ratings_small:\")\n",
    "print(ratings_small.head())\n",
    "print(ratings_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4cecad-7769-43d8-94c5-254026d68eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                                        title\n",
      "0       31                       Dangerous Minds (1995)\n",
      "1       32    Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "2       39                              Clueless (1995)\n",
      "3       80  White Balloon, The (Badkonake sefid) (1995)\n",
      "4      177                     Lord of Illusions (1995)\n",
      "   userId  movieId  rating\n",
      "0     156     3167     3.0\n",
      "1     514     1258     4.0\n",
      "2      32       39     3.0\n",
      "3     305    55276     5.0\n",
      "4     603     2020     4.0\n"
     ]
    }
   ],
   "source": [
    "print(movies.head())\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd88a3c-52a1-41f3-b4d5-dec055013892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId  31      32      39      80      177     204     356     474     \\\n",
      "userId                                                                    \n",
      "6           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "16          0.0     0.0     0.0     0.0     0.0     2.0     0.0     0.0   \n",
      "32          0.0     0.0     3.0     0.0     0.0     0.0     0.0     0.0   \n",
      "42          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "45          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "movieId  541     587     ...  26736   42761   48394   50872   51662   55276   \\\n",
      "userId                   ...                                                   \n",
      "6           0.0     5.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "16          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "32          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "42          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "45          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "movieId  77866   111362  117590  119155  \n",
      "userId                                   \n",
      "6           0.0     0.0     0.0     0.0  \n",
      "16          0.0     0.0     0.0     0.0  \n",
      "32          0.0     0.0     0.0     0.0  \n",
      "42          0.0     0.0     0.0     0.0  \n",
      "45          0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix = ratings_small.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values='rating',\n",
    "    aggfunc='first',      # 중복 없으면 mean 대신 first\n",
    "    fill_value=0          # 결측치 0으로 대체\n",
    ")\n",
    "print(user_item_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c617b9-bcf6-47b0-84d7-3e4f22ace9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId  31      32      39      80      177     204     356     474     \\\n",
      "userId                                                                    \n",
      "6           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "16          NaN     NaN     NaN     NaN     NaN     2.0     NaN     NaN   \n",
      "32          NaN     NaN     3.0     NaN     NaN     NaN     NaN     NaN   \n",
      "42          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "45          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "movieId  541     587     ...  26736   42761   48394   50872   51662   55276   \\\n",
      "userId                   ...                                                   \n",
      "6           NaN     5.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "16          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "32          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "42          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "45          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "movieId  77866   111362  117590  119155  \n",
      "userId                                   \n",
      "6           NaN     NaN     NaN     NaN  \n",
      "16          NaN     NaN     NaN     NaN  \n",
      "32          NaN     NaN     NaN     NaN  \n",
      "42          NaN     NaN     NaN     NaN  \n",
      "45          NaN     NaN     NaN     NaN  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "#create a user-item rating matrix\n",
    "user_item_matrix = ratings.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "# pivot table=crete a matrix with userId as rows (index) movieid as columns and rating as values\n",
    "\n",
    "print(user_item_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8eab58-f089-481d-95ec-779ca2356800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movieId                                             title\n",
      "7       474                        In the Line of Fire (1993)\n",
      "15     1203                               12 Angry Men (1957)\n",
      "18     1408                  Last of the Mohicans, The (1992)\n",
      "23     2355                              Bug's Life, A (1998)\n",
      "27     3167                           Carnal Knowledge (1971)\n",
      "31     4816                                  Zoolander (2001)\n",
      "32     5065                    Mothman Prophecies, The (2002)\n",
      "41    48394  Pan's Labyrinth (Laberinto del fauno, El) (2006)\n",
      "46   111362                 X-Men: Days of Future Past (2014)\n",
      "48   119155    Night at the Museum: Secret of the Tomb (2014)\n"
     ]
    }
   ],
   "source": [
    "top_movies = ratings['movieId'].value_counts().head(10)\n",
    "print(movies[movies['movieId'].isin(top_movies.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07cdcc8-ca5f-43c6-a532-71e220cf68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the consine_similarity func from sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf54366-f836-4b3a-abae-e588626e1f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User similarity matrix shape: (48, 48)\n"
     ]
    }
   ],
   "source": [
    "#user_item_matrix.fillna(0) -> replaces all missing values (NaN) in the user-tim rating matrix with 0\n",
    "user_item_filled = user_item_matrix.fillna(0)\n",
    "\n",
    "#computes the consine similarity btw every pair of users based on their rating vectors\n",
    "user_sim = cosine_similarity(user_item_filled)\n",
    "print('User similarity matrix shape:', user_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2198a47-c2c8-4bb0-a6c6-424b6f611cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in ./.pyenv/versions/3.11.11/lib/python3.11/site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.pyenv/versions/3.11.11/lib/python3.11/site-packages (from scikit-surprise) (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.pyenv/versions/3.11.11/lib/python3.11/site-packages (from scikit-surprise) (2.3.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.pyenv/versions/3.11.11/lib/python3.11/site-packages (from scikit-surprise) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - anaconda\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-surprise\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libsqlite-3.46.0           |       hfb93653_0         811 KB  conda-forge\n",
      "    libzlib-1.2.13             |       hfb2fe0b_6          46 KB  conda-forge\n",
      "    python-3.12.2              |hdf0ec26_0_cpython        12.5 MB  conda-forge\n",
      "    python_abi-3.12            |          7_cp312           7 KB  conda-forge\n",
      "    scikit-surprise-1.1.4      |  py312h911a38c_1         332 KB  conda-forge\n",
      "    zlib-1.2.13                |       hfb2fe0b_6          76 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libexpat           conda-forge/osx-arm64::libexpat-2.6.4-h286801f_0 \n",
      "  libsqlite          conda-forge/osx-arm64::libsqlite-3.46.0-hfb93653_0 \n",
      "  libzlib            conda-forge/osx-arm64::libzlib-1.2.13-hfb2fe0b_6 \n",
      "  python_abi         conda-forge/noarch::python_abi-3.12-7_cp312 \n",
      "  scikit-surprise    conda-forge/osx-arm64::scikit-surprise-1.1.4-py312h911a38c_1 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  zlib                    pkgs/main::zlib-1.2.13-h18a0788_1 --> conda-forge::zlib-1.2.13-hfb2fe0b_6 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  python                pkgs/main::python-3.12.7-h99e199e_0 --> conda-forge::python-3.12.2-hdf0ec26_0_cpython \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "#install surprize library \n",
    "!pip install scikit-surprise\n",
    "!conda install -c conda-forge scikit-surprise\n",
    "\n",
    "\n",
    "#import required modules\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "\n",
    "#import the cross-validation func for model evaluation\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e6e99-e46d-4f07-86bf-742865968785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install surprize library \n",
    "!pip install scikit-surprise\n",
    "!conda install -c conda-forge scikit-surprise\n",
    "\n",
    "\n",
    "#import required modules\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "\n",
    "#import the cross-validation func for model evaluation\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312f9d9-c6d9-4ccd-ab08-d3fff8a31a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24dd32e9-2a06-4c19-a54f-36dcb2dd8ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:   0%|                                | 0/10 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  10%|██▍                     | 1/10 [00:01<00:12,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  30%|███████▏                | 3/10 [00:02<00:05,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  40%|█████████▌              | 4/10 [00:03<00:05,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  50%|████████████            | 5/10 [00:04<00:05,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  60%|██████████████▍         | 6/10 [00:06<00:04,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  70%|████████████████▊       | 7/10 [00:07<00:03,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  80%|███████████████████▏    | 8/10 [00:08<00:02,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts:  90%|█████████████████████▌  | 9/10 [00:09<00:01,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Processing prompts: 100%|███████████████████████| 10/10 [00:10<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample Result] First item:\n",
      "Prompt: Can you recommend a good comedy movie?\n",
      "Reference response: You might enjoy 'The Big Lebowski'. It's a classic comedy with a unique sense of humor.\n",
      "GPT-2 generated response: Can you recommend a good comedy movie? What else do you think would be interesting to watch? Leave your suggestions in the comments below.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm  # For progress bar (install with pip install tqdm if needed)\n",
    "\n",
    "MODEL_NAME = \"gpt2\"\n",
    "PROMPT_FILE = \"./12_data/movielens_prompt_response.json\"\n",
    "\n",
    "# Load prompt-response data from JSON file\n",
    "with open(PROMPT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "# Iterate through all prompts with a progress bar\n",
    "for item in tqdm(data, desc=\"Processing prompts\"):\n",
    "    try:\n",
    "        prompt = item['prompt']\n",
    "        # Tokenize the prompt and prepare input tensor\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        # Generate model response\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        # Decode the generated response\n",
    "        generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Store prompt, reference response, and model response\n",
    "        results.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"reference_response\": item['response'],\n",
    "            \"gpt2_response\": generated\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[Error] prompt: {item['prompt']}\\n{e}\")\n",
    "        errors.append({\"prompt\": item['prompt'], \"error\": str(e)})\n",
    "\n",
    "# Save results to a JSON file\n",
    "with open(\"gpt2_generated_responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save errors to a separate file if any occurred\n",
    "if errors:\n",
    "    with open(\"gpt2_generation_errors.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(errors, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\n[Notice] Errors occurred for {len(errors)} prompts, saved to gpt2_generation_errors.json.\")\n",
    "\n",
    "# Print a sample result (optional)\n",
    "if results:\n",
    "    print(\"\\n[Sample Result] First item:\")\n",
    "    print(\"Prompt:\", results[0]['prompt'])\n",
    "    print(\"Reference response:\", results[0]['reference_response'])\n",
    "    print(\"GPT-2 generated response:\", results[0]['gpt2_response'])\n",
    "else:\n",
    "    print(\"\\n[Notice] No results were generated.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919f22c-2309-41e5-9222-62cc529439a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------gpt-j-6B---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178a633-a35a-472d-8e9b-3be7a5d96206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"transformers[torch]>=4.28.1,<5\" \"torch>=1.13.1,<2\" \"accelerate>=0.16.0,<1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905132fb-7a9c-4e8a-ae2c-7ae0f38b1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"databricks/dolly-v2-3b\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b3a3a-d2a7-41e0-ad6a-37d66b71779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the prompt for the language model\n",
    "#prompt = \"Recommend a good thriller movie.\"\n",
    "\n",
    "# Tokenize the prompt and convert it to PyTorch tensors, with truncation\n",
    "#inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "# Generate a response from the model with a maximum length of 100 tokens\n",
    "#outputs = model.generate(**inputs, max_length=100)\n",
    "\n",
    "# Decode the generated tokens into a readable string and print the result\n",
    "#print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (surprise-env)",
   "language": "python",
   "name": "surprise-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
