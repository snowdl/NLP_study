{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc6ddb-b6b4-44da-85c8-71c307f3b22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb339ad-8c8e-4d33-b172-70cd7567de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf3cda5-cacd-485c-9cc5-5a0c89586934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8a6ad1-8634-4c33-83d2-b6407760ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a6fad7-5248-4ba0-bd63-b836d98e9855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4f19f34e1e424b8ef9d0345d522ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd047998055e4665a85ea1385ba85a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb314c5a0694cb0bfa223c7c1b319c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb3dd93653a464486cc94f2e2a47b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28abaa07fcba4494b2b7752af083c961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c9b582995c43a098e790ef58a3b3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5babfc114e914e9698219db9f3682fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FLAN-T5 Base 모델 불러오기\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d319afe-a833-42d0-8c1b-9a0a8070fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    # 모델과 입력 텐서를 GPU에 올리기 (가능하면)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_length=150, num_beams=5, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b4d33bf-5db6-4fd7-abcf-214583405a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment est-ce que vous?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Translate English to French: How are you?\"\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c300280d-a5db-4b2b-8a07-9c00b656e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watch the fox jump over the dog.\n"
     ]
    }
   ],
   "source": [
    "prompt2 = \"Summarize: The quick brown fox jumps over the lazy dog.\"\n",
    "print(generate_text(prompt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23ef8beb-6650-4a34-ab15-73176e75bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NLP .\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Translate English to Korean: I love learning NLP.\"\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29dedbea-546d-4b2f-bab4-e82a75ce182f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresult : \\nTraining Data Bias: FLAN-T5 has been trained on more data for widely used language pairs such as English-to-French and English-to-Spanish.\\nKorean Language Characteristics: Korean grammar, word order, and particles differ significantly from English, making translation challenging and requiring specialized tuning for Korean.\\nModel Size and Limitations: The base model is designed for general-purpose use and is not finely optimized for translation tasks like specialized translation models (e.g., Google Translate, Naver Papago).\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "result : \n",
    "Training Data Bias: FLAN-T5 has been trained on more data for widely used language pairs such as English-to-French and English-to-Spanish.\n",
    "Korean Language Characteristics: Korean grammar, word order, and particles differ significantly from English, making translation challenging and requiring specialized tuning for Korean.\n",
    "Model Size and Limitations: The base model is designed for general-purpose use and is not finely optimized for translation tasks like specialized translation models (e.g., Google Translate, Naver Papago).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141244fa-0db1-48ab-a2d7-d31832a5d234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
