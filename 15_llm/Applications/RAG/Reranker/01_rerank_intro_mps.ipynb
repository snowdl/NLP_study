{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d93103a5-0996-4b83-8bd1-13a3b537e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 0. Import & Force MPS ===\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4098ec79-36aa-4a50-a1cd-0138bbf59bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fec7276-c78e-4dfc-be05-fa89249ba63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Device fixed to: mps\n"
     ]
    }
   ],
   "source": [
    "# Force usage of Apple's Metal Performance Shaders (MPS) on macOS.\n",
    "# This will raise an error if MPS is not available (e.g., wrong PyTorch build or non-Apple device).\n",
    "assert torch.backends.mps.is_available(), \"❌ MPS not available! (Check macOS + PyTorch MPS support)\"\n",
    "device = \"mps\"  # Fix device to MPS\n",
    "print(f\"✅ Device fixed to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1e0618a-b919-4905-9373-0293f6969a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 1. Example Data ===\n",
      "- Query: New York best pizza recommendation\n",
      "  [0] New York pizza restaurant guide: Brooklyn, Manhattan highlights\n",
      "  [1] Chicago deep-dish pizza vs New York thin crust\n",
      "  [2] How to book a table at a famous pizza place in NYC\n",
      "  [3] Los Angeles vegan food tour\n",
      "  [4] Brooklyn hidden pizza gems for locals\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Step 1. Example Data ===\")\n",
    "query = \"New York best pizza recommendation\"\n",
    "docs = [\n",
    "    \"New York pizza restaurant guide: Brooklyn, Manhattan highlights\",\n",
    "    \"Chicago deep-dish pizza vs New York thin crust\",\n",
    "    \"How to book a table at a famous pizza place in NYC\",\n",
    "    \"Los Angeles vegan food tour\",\n",
    "    \"Brooklyn hidden pizza gems for locals\"\n",
    "]\n",
    "print(f\"- Query: {query}\")\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"  [{i}] {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b689ffc2-247f-4b41-a881-4bfa0dee85f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 2.1: TF-IDF transformation & similarity calculation ===\n",
      "Similarity scores: [0.18674964 0.17132846 0.0237282  0.         0.03217088]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Step 2.1: TF-IDF transformation & similarity calculation ===\")\n",
    "\n",
    "# Create a TF-IDF vectorizer using unigrams and bigrams\n",
    "tfv = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "\n",
    "# Fit the vectorizer on both the documents and the query, then transform\n",
    "X = tfv.fit_transform(docs + [query])\n",
    "\n",
    "# Separate document vectors and the query vector\n",
    "X_docs, X_q = X[:-1], X[-1]\n",
    "\n",
    "# Compute cosine similarity between each document and the query\n",
    "sims = cosine_similarity(X_docs, X_q)[:, 0]\n",
    "print(\"Similarity scores:\", sims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d195dad9-8610-4a43-a6ff-55111da5cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 2.2: Select top-k candidates ===\n",
      "  idx=0 | tfidf_sim=0.1867 | New York pizza restaurant guide: Brooklyn, Manhattan highlights\n",
      "  idx=1 | tfidf_sim=0.1713 | Chicago deep-dish pizza vs New York thin crust\n",
      "  idx=4 | tfidf_sim=0.0322 | Brooklyn hidden pizza gems for locals\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Step 2.2: Select top-k candidates ===\")\n",
    "\n",
    "# Select top-k documents with the highest similarity scores\n",
    "k = 3\n",
    "topk_idx = np.argsort(-sims)[:k].tolist()\n",
    "\n",
    "# Store candidates as (index, document, similarity score)\n",
    "candidates = [(i, docs[i], float(sims[i])) for i in topk_idx]\n",
    "\n",
    "# Print candidates with their TF-IDF similarity scores\n",
    "for i, d, s in candidates:\n",
    "    print(f\"  idx={i} | tfidf_sim={s:.4f} | {d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3e12427-3eba-4fbb-bf5c-8bf7d55a7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 3. Reranker (Cross-Encoder, MPS) ===\n",
      "- Loading model: cross-encoder/ms-marco-MiniLM-L-6-v2 (device=mps)\n",
      "✅ Reranker loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Step 3. Reranker (Cross-Encoder, MPS) ===\")\n",
    "\n",
    "# Define the Cross-Encoder model name (a lightweight reranker model)\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "# Print a message showing which model and device are being used\n",
    "print(f\"- Loading model: {model_name} (device={device})\")\n",
    "\n",
    "# Load the Cross-Encoder model onto the specified device (MPS here)\n",
    "reranker = CrossEncoder(model_name, device=device)\n",
    "\n",
    "# Confirm that the reranker is ready\n",
    "print(\"✅ Reranker loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3966bfb3-8f25-4b23-93c6-1e3dd353d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 4. Reranking Execution ===\n",
      "  idx=0 | tfidf=0.1867 | rerank=1.1501 | New York pizza restaurant guide: Brooklyn, Manhattan highlights\n",
      "  idx=1 | tfidf=0.1713 | rerank=-1.2569 | Chicago deep-dish pizza vs New York thin crust\n",
      "  idx=4 | tfidf=0.0322 | rerank=-3.9426 | Brooklyn hidden pizza gems for locals\n",
      "\n",
      "✅ Final selected document: New York pizza restaurant guide: Brooklyn, Manhattan highlights\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Step 4. Reranking Execution ===\")\n",
    "\n",
    "# Create query-document pairs for the reranker\n",
    "pairs = [(query, d) for (_, d, _) in candidates]\n",
    "\n",
    "# Use the Cross-Encoder reranker to predict relevance scores for each pair\n",
    "scores = reranker.predict(pairs)\n",
    "\n",
    "# Combine candidates with their TF-IDF score and rerank score\n",
    "# Sort by rerank score in descending order (highest relevance first)\n",
    "reranked = sorted(\n",
    "    [(i, d, tfidf_s, float(s)) for (i, d, tfidf_s), s in zip(candidates, scores)],\n",
    "    key=lambda x: -x[3]\n",
    ")\n",
    "\n",
    "# Print the reranked candidates with both TF-IDF and rerank scores\n",
    "for i, d, tfidf_s, rr_s in reranked:\n",
    "    print(f\"  idx={i} | tfidf={tfidf_s:.4f} | rerank={rr_s:.4f} | {d}\")\n",
    "\n",
    "# Select the top-ranked document as the final result\n",
    "best_doc = reranked[0][1]\n",
    "print(\"\\n✅ Final selected document:\", best_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fe12b-a6da-429f-8230-3029855ce677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
