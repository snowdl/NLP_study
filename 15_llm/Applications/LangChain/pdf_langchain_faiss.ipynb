{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666037e6-3eb7-4549-a177-3a8790f735f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Install required libraries\n",
    "!pip install --quiet langchain langchain-openai faiss-cpu python-dotenv pymupdf openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd63a47-909c-41c7-9564-3b3845fda136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 2. Import necessary packages\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61678bcb-89b5-4618-8cfe-5fafe134f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_6702/1112195790.py:6: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(openai_api_key=api_key)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "llm = OpenAI(openai_api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7982ed25-2318-4b32-a8e6-d18770e662e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c93583e-1430-4c61-b159-d73d0e794ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./pdfs/textclustering.pdf\"\n",
    "loader = PyMuPDFLoader(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a18300b-c052-4ab6-bf51-bb8c739e069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b0dc37-938f-4f09-9a72-1537855b4fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The peer-reviewed version of this paper is published in the International Journal of Cognitive Compu\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c0cedf0-9cd3-4fa7-8d9f-f2bc2a760720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0975fa-1dde-4f22-967a-23dc966fca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size: Maximum number of characters per chunk\n",
    "# chunk_overlap: Number of overlapping characters between chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26824e10-641e-4c2c-bd37-c179d8930539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the loaded documents into smaller chunks\n",
    "# Input should be a list of Document objects\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac94fb9-cc77-49b3-8781-a55008333b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 71\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of text chunks: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee4075b-3662-4f3d-9bef-78174fe661f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e475806-e6b4-48db-84fd-1a8ab60a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG Chain creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95cd3c38-c371-4a97-8f8d-6ffb086b7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8c0dcb4-3d56-42ae-ac63-df0ef5f5ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14bcfc2c-5643-4bef-9ded-964e5aab2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build RetrievalQA chain using OpenAI LLM and FAISS retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(openai_api_key=api_key),  \n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55a1edf5-3b86-4175-b399-7de522629bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_6702/3283722804.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main contributions of this paper are testing and identifying optimal combinations of embeddings and clustering algorithms for text clustering tasks, comparing the performance of embeddings derived from large language models (LLMs) with traditional embedding techniques, and evaluating the impact of model size and dimensionality reduction on clustering efficiency. \n"
     ]
    }
   ],
   "source": [
    "query = \"What are the main contributions of this paper?\"\n",
    "result = qa_chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39c8c278-beed-484c-b63b-342a3b746a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0122d072-c3da-4b8e-9d60-9110636f9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_text : cleans input text by removing page numbers, collapsing extra blank lines, and stripping unwanted line characters\n",
    "def clean_text(text):\n",
    "    # Remove page numbers, e.g., \"Page 1 of 10\"\n",
    "    text = re.sub(r\"Page \\d+ of \\d+\", \"\", text)\n",
    "    # Replace multiple newlines with a single newline\n",
    "    text = re.sub(r\"\\n\\s*\\n\", \"\\n\", text)\n",
    "    # Remove special characters except word characters, whitespace, and basic punctuation\n",
    "    text = re.sub(r\"[^\\w\\s.,?!]\", \"\", text)\n",
    "    # Trim leading and trailing whitespace\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03aa230c-1f3a-4c7b-a60d-3681d8121ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d69db819-280c-49c2-a3ee-74c00289f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loops through each document object in the documents list\n",
    "for doc in documents:\n",
    "    # Clean the text content of each document using the clean_text function\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "    #applies clean_text func to the page_content attribute of each document to remove unwanted characters, numbers, and extra blank lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdc938ac-dccb-437a-a735-40d6ca9828ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits long texts into smaller chunks, each about 1000 characters long\n",
    "# chunk_overlap=100 means each chunk overlaps the previous chunk by 100 characters\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)  # Split the cleaned documents into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37104af4-cdc1-48d5-b18e-1e2fe7d6dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAISS VECTORSTORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b01c021-bfd5-4aee-9292-20f843d72175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the FAISS vector store to local disk\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a69cc561-4cd4-46e8-82c5-ba1ebe44bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set allow_dangerous_deserialization=True ONLY IF you trust the data source\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5fc06fe-e107-410e-897c-e10262fe0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate embedding object with your OpenAI API key\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0df1cc6-a480-4139-b267-ed00b5305b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI LLM with your API key\n",
    "llm = OpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7335c55a-2d64-406f-9635-ab7115b06bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RetrievalQA chain with the vectorstore retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "472938f2-5770-4253-9134-dc21918088b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RetrievalQA chain with the vectorstore retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07c3016b-8021-4a6f-97e3-5b1ae97e1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a query against your PDF documents\n",
    "query = \"What are the main contributions of this paper?\"\n",
    "result = qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "719151ed-b23d-4378-a67d-5f526f7ecbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main contributions of this paper are: \n",
      "1. Testing and identifying optimal combinations of embeddings and clustering algorithms for text clustering tasks \n",
      "2. Evaluating the performance of LLM embeddings compared to traditional techniques \n",
      "3. Examining the impact of model size and dimensionality reduction on clustering performance \n",
      "4. Highlighting the need to balance detailed text representation with computational feasibility in text clustering tasks.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d605a000-dc30-44e8-89d8-6af66f257f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAISS Index optimization => Create IVF(Inverted File index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7904f82-fa62-49f8-bf6c-0e7a2bf6a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "822d0f7a-dc62-42a6-99b6-f6aa06e03c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18948a3d-8619-4e69-ba65-34b2190d9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d445e737-f6d3-4ea8-bb5b-157ba144e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the length of the embedding vector\n",
    "dimension = len(embeddings.embed_query(\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "862e8c13-601c-4970-a5df-7671c919d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3084f921-83cb-47b4-ab9c-928e01123491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat is IVF : used to speed up vector similarity search by partitioning the entire vector space into multiple clusters (also called centroids), and assigning each vector to its nearest cluster.\\nwhy use IVF : Searching through all vectors in a large dataset is computationally expensive and slow. IVF helps by limiting the search to only the most relevant clusters, dramatically improving search speed.\\nHow it work? \\nThe vector space is first partitioned into n clusters using k-means clustering. This step requires calling index.train(vectors).\\nEach vector is assigned to its closest centroid (cluster center).\\nDuring search, instead of scanning all clusters, only a few relevant clusters are searched, making the process much faster.\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IVF(Inverted File index)\n",
    "\"\"\"\n",
    "What is IVF : used to speed up vector similarity search by partitioning the entire vector space into multiple clusters (also called centroids), and assigning each vector to its nearest cluster.\n",
    "why use IVF : Searching through all vectors in a large dataset is computationally expensive and slow. IVF helps by limiting the search to only the most relevant clusters, dramatically improving search speed.\n",
    "How it work? \n",
    "The vector space is first partitioned into n clusters using k-means clustering. This step requires calling index.train(vectors).\n",
    "Each vector is assigned to its closest centroid (cluster center).\n",
    "During search, instead of scanning all clusters, only a few relevant clusters are searched, making the process much faster.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbc785a1-c5f4-4f1b-8b9d-4afe6c1ddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVF index setup\n",
    "nlist = 10  # num of cluster\n",
    "quantizer = faiss.IndexFlatL2(dimension)  # # Flat index for L2 distance (used as the coarse quantizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4806625b-2c53-4ff4-a685-bc8d80baf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an IVF flat index (coarse quantizer + flat index within each cluster)\n",
    "# - quantizer: used to assign vectors to clusters\n",
    "# - dimension: dimensionality of the embedding vectors\n",
    "# - nlist: number of clusters (coarse centroids)\n",
    "# - faiss.METRIC_L2: use L2 (Euclidean) distance for similarity search\n",
    "index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9f2585f-bebb-4523-8126-b0c28e6c1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve vectors from the existing FAISS index inside the vectorstore\n",
    "# reconstruct_n(start, count) returns 'count' vectors starting from index 'start'\n",
    "vectors = vectorstore.index.reconstruct_n(0, vectorstore.index.ntotal)  # (ntotal, dimension) ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30b5f7fb-64cd-49d6-8173-63371ff21fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (70, 1536)\n"
     ]
    }
   ],
   "source": [
    "# debugging\n",
    "print(type(vectors), vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c8c1325-c3a9-4978-9c65-2eeb6c9d6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # vectors가 ndarray임을 확인했으면 별도 변환 불필요\n",
    "# 만약 리스트라면 numpy array로 변환\n",
    "if not isinstance(vectors, np.ndarray):\n",
    "    vectors = np.array(vectors).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f29a84b7-1967-4851-8e39-a5988bf66da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is not trained. Training now...\n",
      "Vectors added successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 70 points to 10 centroids: please provide at least 390 training points\n"
     ]
    }
   ],
   "source": [
    "# 인덱스 학습 확인 후 학습\n",
    "if not index.is_trained:\n",
    "    print(\"Index is not trained. Training now...\")\n",
    "    index.train(vectors)   # 인덱스가 학습되지 않았으면 벡터로 학습함\n",
    "index.add(vectors)        # 학습된 인덱스에 벡터 추가\n",
    "print(\"Vectors added successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b793c-08c5-4bde-8624-7190f1f59ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (pyenv)",
   "language": "python",
   "name": "pyenv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
