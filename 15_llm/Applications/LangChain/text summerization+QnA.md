```python
import os
os.environ["OPENAI_API_KEY"] = "OPENAI_API_KEY"
```


```python
"""
multilang_doc_pipeline/
â”œâ”€â”€ translate_chain.py      âœ… 1. ì˜ì–´ â†’ í•œêµ­ì–´ â†’ ì¼ë³¸ì–´
â”œâ”€â”€ summarize_chain.py      âœ… 2. ì¼ë³¸ì–´ ìš”ì•½
â”œâ”€â”€ embed_store.py          âœ… 3. ë²¡í„° ì €ìž¥ì†Œ ì €ìž¥
â”œâ”€â”€ qa_chain.py             âœ… 4. ì‚¬ìš©ìž Q&A ì²˜ë¦¬
â”œâ”€â”€ cli.py                  âœ… 5. ì „ì²´ ì‹¤í–‰ CLI
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ document_loader.py  âœ… ë¬¸ì„œ ë¡œë”© (txt/pdf)
â””â”€â”€ data/
    â””â”€â”€ harry_potter.txt    âœ… í…ŒìŠ¤íŠ¸ìš© ì›ë¬¸
"""
```




    '\nmultilang_doc_pipeline/\nâ”œâ”€â”€ translate_chain.py      âœ… 1. ì˜ì–´ â†’ í•œêµ­ì–´ â†’ ì¼ë³¸ì–´\nâ”œâ”€â”€ summarize_chain.py      âœ… 2. ì¼ë³¸ì–´ ìš”ì•½\nâ”œâ”€â”€ embed_store.py          âœ… 3. ë²¡í„° ì €ìž¥ì†Œ ì €ìž¥\nâ”œâ”€â”€ qa_chain.py             âœ… 4. ì‚¬ìš©ìž Q&A ì²˜ë¦¬\nâ”œâ”€â”€ cli.py                  âœ… 5. ì „ì²´ ì‹¤í–‰ CLI\nâ”œâ”€â”€ utils/\nâ”‚   â””â”€â”€ document_loader.py  âœ… ë¬¸ì„œ ë¡œë”© (txt/pdf)\nâ””â”€â”€ data/\n    â””â”€â”€ harry_potter.txt    âœ… í…ŒìŠ¤íŠ¸ìš© ì›ë¬¸\n'




```python
import re
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.document_loaders import TextLoader
```


```python
# 1. load textfiles
loader = TextLoader("11_data/01 Harry Potter and the Sorcerers Stone.txt")
docs = loader.load()
```


```python
#model setting
llm = ChatOpenAI(model="gpt-4o", temperature=0)
```


```python
#Function to split text into sentences without breaking abbreviations
def split_into_sentences_safe(text):
    abbreviations = ["Mr.", "Mrs.", "Dr.", "Ms.", "Prof.", "Sr.", "Jr.", "St.", "vs.", "etc."]
    for abbr in abbreviations:
        text = text.replace(abbr, abbr.replace('.', '[dot]')) # "Mr." -> "Mr[dot]" 
     #Split sentences at the end of '.', '!' or '?' followed by whitespace   
    sentences = re.split(r'(?<=[.!?])\s+', text)
    #Split sentences at the end of '.', '!' or '?' followed by whitespace
    sentences = [s.replace('[dot]', '.') for s in sentences]
    #Trim whitespace and remove empty sentence
    return [s.strip() for s in sentences if s.strip()]
```


```python
# 4. Preprocess text
cleaned_text = docs[0].page_content.replace("M r.", "Mr.")  # Fix spacing issue in "Mr."
sample_text = cleaned_text[:1000]  # Take the first 1000 characters for sampling
sentences = split_into_sentences_safe(sample_text)  # Split the text into sentences safely
first_sentence = sentences[0]  # Get the first sentence

print("ðŸ“– First sentence (English):\n", first_sentence)

```

    ðŸ“– First sentence (English):
     Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.



```python
# Prompt settings: ENG -> KOR
prompt_eng_to_kor = PromptTemplate(
    input_variables=["text"],
    template="Please translate the following English sentence into natural Korean:\n\n{text}"
)

# Prompt settings: KOR -> JAP
prompt_kor_to_jap = PromptTemplate(
    input_variables=["text"],
    template="Please translate the following Korean sentence into natural Japanese:\n\n{text}"
)

```


```python
# Create LLM chains for translation
```


```python
chain_eng_to_kor = LLMChain(llm=llm, prompt=prompt_eng_to_kor)
chain_kor_to_jap = LLMChain(llm=llm, prompt=prompt_kor_to_jap)
```


```python
# 7. Translation pipeline
kor_translation = chain_eng_to_kor.run(text=first_sentence)
jap_translation = chain_kor_to_jap.run(text=kor_translation)

print("\nðŸ‡°ðŸ‡· Korean translation:\n", kor_translation)
print("\nðŸ‡¯ðŸ‡µ Japanese translation:\n", jap_translation)
```

    
    ðŸ‡°ðŸ‡· Korean translation:
     í”„ë¦¬ë²³ê°€ 4ë²ˆì§€ì— ì‚¬ëŠ” ë”ì¦ë¦¬ ë¶€ë¶€ëŠ” ìžì‹ ë“¤ì´ ì™„ë²½ížˆ ì •ìƒì ì´ë¼ê³  ìžë¶€í–ˆìŠµë‹ˆë‹¤, ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤.
    
    ðŸ‡¯ðŸ‡µ Japanese translation:
     ãƒ—ãƒªãƒ™ãƒƒãƒˆé€šã‚Š4ç•ªåœ°ã«ä½ã‚€ãƒ€ãƒ¼ã‚ºãƒªãƒ¼å¤«å¦»ã¯ã€è‡ªåˆ†ãŸã¡ãŒå®Œå…¨ã«æ™®é€šã ã¨è‡ªè² ã—ã¦ã„ã¾ã—ãŸã€‚æœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚



```python
#text summerization
```


```python
# Prompt templates for summarization in different languages

prompt_eng_summary = PromptTemplate(
    input_variables=["text"],
    template="Please provide a concise summary of the following English text:\n\n{text}"
)

prompt_kor_summary = PromptTemplate(
    input_variables=["text"],
    template="Please provide a concise summary of the following Korean text:\n\n{text}"
)

prompt_jap_summary = PromptTemplate(
    input_variables=["text"],
    template="Please provide a concise summary of the following Japanese text:\n\n{text}"
)

```


```python
# Create an LLM chain for English text summarization
chain_eng_summary = LLMChain(llm=llm, prompt=prompt_eng_summary)

# Generate a summary of the first 3000 characters of the cleaned text (example)
eng_summary = chain_eng_summary.run(text=cleaned_text[:3000])

```


```python
# Create an LLM chain for English to Korean translation
chain_eng_to_kor = LLMChain(llm=llm, prompt=prompt_eng_to_kor)

# Translate the English summary into Korean
kor_summary = chain_eng_to_kor.run(text=eng_summary)

```


```python
# Create an LLM chain for Korean to Japanese translation
chain_kor_to_jap = LLMChain(llm=llm, prompt=prompt_kor_to_jap)

# Translate the Korean summary into Japanese
jap_summary = chain_kor_to_jap.run(text=kor_summary)

```


```python
print("ðŸ‡ºðŸ‡¸ English Summary:\n", eng_summary)
```

    ðŸ‡ºðŸ‡¸ English Summary:
     Mr. and Mrs. Dursley of Privet Drive were proud of their normalcy and avoided anything strange. Mr. Dursley was a director at a drill company, and Mrs. Dursley spent her time spying on neighbors. They had a son named Dudley, whom they adored. However, they harbored a secret fear of being associated with the Potters, Mrs. Dursley's estranged sister's family, who were very different from them. On a seemingly ordinary day, Mr. Dursley noticed odd occurrences, such as a cat reading a map, hinting at the onset of mysterious events.



```python
print("ðŸ‡°ðŸ‡· Korean Summary:\n", kor_summary)
```

    ðŸ‡°ðŸ‡· Korean Summary:
     í”„ë¦¬ë²³ ë“œë¼ì´ë¸Œì— ì‚¬ëŠ” ë”ì¦ë¦¬ ë¶€ë¶€ëŠ” ê·¸ë“¤ì˜ í‰ë²”í•¨ì„ ìžëž‘ìŠ¤ëŸ¬ì›Œí•˜ë©° ì´ìƒí•œ ê²ƒë“¤ì„ í”¼í–ˆìŠµë‹ˆë‹¤. ë”ì¦ë¦¬ ì”¨ëŠ” ë“œë¦´ íšŒì‚¬ì˜ ì´ì‚¬ì˜€ê³ , ë”ì¦ë¦¬ ë¶€ì¸ì€ ì´ì›ƒì„ ì—¼íƒí•˜ë©° ì‹œê°„ì„ ë³´ëƒˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ë”ë“¤ë¦¬ë¼ëŠ” ì•„ë“¤ì„ ë‘ê³  ìžˆì—ˆê³ , ê·¸ë¥¼ ë§¤ìš° ì‚¬ëž‘í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ë“¤ì€ ë”ì¦ë¦¬ ë¶€ì¸ì˜ ì†Œì›í•´ì§„ ì—¬ë™ìƒ ê°€ì¡±ì¸ í¬í„° ê°€ì¡±ê³¼ ì—°ê´€ë˜ëŠ” ê²ƒì„ ë¹„ë°€ìŠ¤ëŸ½ê²Œ ë‘ë ¤ì›Œí–ˆìŠµë‹ˆë‹¤. í¬í„° ê°€ì¡±ì€ ê·¸ë“¤ê³¼ ë§¤ìš° ë‹¬ëžìŠµë‹ˆë‹¤. ê²‰ë³´ê¸°ì—ëŠ” í‰ë²”í•œ ì–´ëŠ ë‚ , ë”ì¦ë¦¬ ì”¨ëŠ” ê³ ì–‘ì´ê°€ ì§€ë„ë¥¼ ì½ëŠ” ê²ƒê³¼ ê°™ì€ ì´ìƒí•œ ì¼ë“¤ì„ ëª©ê²©í–ˆê³ , ì´ëŠ” ì‹ ë¹„ë¡œìš´ ì‚¬ê±´ì˜ ì‹œìž‘ì„ ì•”ì‹œí–ˆìŠµë‹ˆë‹¤.



```python
print("ðŸ‡¯ðŸ‡µ Japanese Summary:\n", jap_summary)
```

    ðŸ‡¯ðŸ‡µ Japanese Summary:
     ãƒ—ãƒªãƒ™ãƒƒãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒ–ã«ä½ã‚€ãƒ€ãƒ¼ã‚ºãƒªãƒ¼å¤«å¦»ã¯ã€è‡ªåˆ†ãŸã¡ã®å¹³å‡¡ã•ã‚’èª‡ã‚Šã«æ€ã„ã€å¥‡å¦™ãªã“ã¨ã‚’é¿ã‘ã¦ã„ã¾ã—ãŸã€‚ãƒ€ãƒ¼ã‚ºãƒªãƒ¼æ°ã¯ãƒ‰ãƒªãƒ«ä¼šç¤¾ã®å–ç· å½¹ã§ã€ãƒ€ãƒ¼ã‚ºãƒªãƒ¼å¤«äººã¯è¿‘æ‰€ã‚’è¦—ãè¦‹ã—ã¦æ™‚é–“ã‚’éŽã”ã—ã¦ã„ã¾ã—ãŸã€‚å½¼ã‚‰ã«ã¯ãƒ€ãƒ‰ãƒªãƒ¼ã¨ã„ã†æ¯å­ãŒã„ã¦ã€å½¼ã‚’ã¨ã¦ã‚‚æ„›ã—ã¦ã„ã¾ã—ãŸã€‚ã—ã‹ã—ã€ãƒ€ãƒ¼ã‚ºãƒªãƒ¼å¤«äººã®ç–Žé ã«ãªã£ã¦ã„ã‚‹å¦¹å®¶æ—ã§ã‚ã‚‹ãƒãƒƒã‚¿ãƒ¼å®¶ã¨é–¢ã‚ã‚‹ã“ã¨ã‚’å¯†ã‹ã«æã‚Œã¦ã„ã¾ã—ãŸã€‚ãƒãƒƒã‚¿ãƒ¼å®¶ã¯å½¼ã‚‰ã¨ã¯å¤§ã„ã«ç•°ãªã£ã¦ã„ã¾ã—ãŸã€‚è¦‹ãŸç›®ã«ã¯æ™®é€šã®ã‚ã‚‹æ—¥ã€ãƒ€ãƒ¼ã‚ºãƒªãƒ¼æ°ã¯çŒ«ãŒåœ°å›³ã‚’èª­ã‚“ã§ã„ã‚‹ã¨ã„ã£ãŸå¥‡å¦™ãªå‡ºæ¥äº‹ã‚’ç›®æ’ƒã—ã€ãã‚Œã¯ä¸æ€è­°ãªäº‹ä»¶ã®å§‹ã¾ã‚Šã‚’ç¤ºå”†ã—ã¦ã„ã¾ã—ãŸã€‚



```python
#Named Entity Recognition (NER) 
```


```python
import spacy
nlp = spacy.load("en_core_web_sm")
```


```python
# Function to extract named entities from text using spaCy
def extract_entities(text):
    doc = nlp(text)
    return [(ent.text, ent.label_) for ent in doc.ents]  # Return list of (entity text, entity label)
```


```python
entities = extract_entities(first_sentence)
print("ðŸ” Named Entities:", entities)
```

    ðŸ” Named Entities: [('Dursley', 'PERSON'), ('four', 'CARDINAL'), ('Privet Drive', 'PERSON')]



```python
for ent, label in entities:
    kor = chain_eng_to_kor.run(text=ent)
    jap = chain_kor_to_jap.run(text=kor)
    print(f"{label} | {ent} â†’ {kor} â†’ {jap}")
```

    PERSON | Dursley â†’ ë”ì¦ë¦¬ â†’ ãƒ€ãƒ¼ã‚ºãƒªãƒ¼
    CARDINAL | four â†’ ë„¤ ê°œ â†’ 4ã¤
    PERSON | Privet Drive â†’ í”„ë¦¬ë²³ ë“œë¼ì´ë¸Œ â†’ ãƒ—ãƒªãƒ™ãƒƒãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒ–



```python
#QnA =>Chroma + OpenAIEmbeddings)
```


```python
from langchain.chains import RetrievalQA
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import OpenAI
from langchain.document_loaders import TextLoader
import spacy
```


```python
# loading data
loader = TextLoader("/Users/jessicahong/gitclone/NLP_study/11_data/01 Harry Potter and the Sorcerers Stone.txt")
docs = loader.load()
```


```python
#Split the document into smaller chunks for processing
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)  # Split text into 1000-character chunks with 200-character overlap
splits = splitter.split_documents(docs)  # Apply splitting to loaded documents

```


```python
#Create Chroma vector store with OpenAI embeddings
embeddings = OpenAIEmbeddings()  # Initialize OpenAI embeddings model
vectorstore = Chroma.from_documents(splits, embeddings)  # Generate and store embeddings for document chunks
```


```python
#Create a RetrievalQA chain for question answering
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,  # Language model to generate answers
    retriever=vectorstore.as_retriever(),  # Retriever to fetch relevant document chunks
    chain_type="stuff"  # Chain type that stuffs retrieved documents into the prompt
)

```


```python
# Named Entity Recognition (NER) on a sample text
nlp = spacy.load("en_core_web_sm")  # Load English spaCy model
text_sample = docs[0].page_content  # Take text from the first document chunk
doc_spacy = nlp(text_sample)  # Process text with spaCy to detect entities
entities = list(set(ent.text for ent in doc_spacy.ents))  # Extract unique entity texts
```


```python
# Print the top 5 extracted entities
for e in entities[:5]:
    print("-", e)
```

    - Potter
    - Voldemort
    - Emeric Switch
    - squashy
    - Egg



```python
print("\n[Entity-based Q&A]")
```

    
    [Entity-based Q&A]



```python
# 1. Initialize the language model (LLM) and create the question-answering (QA) chain
llm = OpenAI(temperature=0)  # Initialize LLM with deterministic output
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,  # Language model to generate answers
    retriever=vectorstore.as_retriever(),  # Retriever to fetch relevant document chunks
    chain_type="stuff"  # Chain type that stuffs retrieved documents into the prompt
)

```

    /var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_51924/1945856242.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.
      llm = OpenAI(temperature=0)  # Initialize LLM with deterministic output



```python
# 2. Extract entities using NER 
entities = ["Harry Potter", "Hogwarts", "Ron Weasley"]
```


```python
for entity in entities:
    question = f"Tell me more about {entity}"
    answer = qa_chain.run(question)
    print(f"\nQ: {question}\nA: {answer}")
```

    
    Q: Tell me more about Harry Potter
    A:  Harry Potter is the main character in the Harry Potter series by J.K. Rowling. He is a young wizard who discovers he is famous in the wizarding world for surviving an attack by the dark wizard, Lord Voldemort, when he was just a baby. He attends Hogwarts School of Witchcraft and Wizardry, where he learns about magic and makes friends with Ron Weasley and Hermione Granger. He also discovers his talent for playing Quidditch, a popular sport in the wizarding world. Throughout the series, Harry faces challenges and battles against Lord Voldemort and his followers, ultimately fulfilling his destiny as the "Chosen One."
    
    Q: Tell me more about Hogwarts
    A:  Hogwarts is a magical school located in Scotland, where young witches and wizards from all over the United Kingdom come to learn and hone their magical abilities. It is divided into four houses: Gryffindor, Hufflepuff, Ravenclaw, and Slytherin, each with its own unique traits and characteristics. The students live in their respective house dormitories and have classes with their housemates. The school is also home to ghosts, enchanted objects, and various magical creatures. The students earn points for their house through academic and extracurricular achievements, and at the end of the year, the house with the most points is awarded the prestigious House Cup.
    
    Q: Tell me more about Ron Weasley
    A:  Ron Weasley is a student at Hogwarts School of Witchcraft and Wizardry and is in the same year as Harry Potter. He comes from a large wizarding family, with five older brothers and one younger sister. Ron is known for his red hair and freckles, and is often seen with his pet rat, Scabbers. He is also a member of the Gryffindor house and becomes good friends with Harry and Hermione. Ron is often insecure about his family's financial situation and feels overshadowed by his older brothers' achievements. He is also known for his sense of humor and loyalty to his friends.



```python
# 4. User input loop for questions (console)
print("\nType 'exit' to quit.")
while True:
    user_question = input("\nYour question: ")
    if user_question.lower() == "exit":
        print("Goodbye!")
        break
    answer = qa_chain.run(user_question)  # Generate answer using QA chain
    print("Answer:", answer)
```

    
    Type 'exit' to quit.



```python

```
