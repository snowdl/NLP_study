{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d23801-18b5-498f-bfa1-fa2df5e35c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers: 4.43.3\n",
      "peft: 0.13.2\n",
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 0. Version & Device check\n",
    "# -----------------------------------------------------------\n",
    "import torch, transformers, peft\n",
    "\n",
    "print(\"transformers:\", transformers.__version__)  # should be 4.43.3\n",
    "print(\"peft:\", peft.__version__)                  # should be 0.13.2\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"   # Apple Silicon\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"  # NVIDIA GPU\n",
    "else:\n",
    "    device = \"cpu\"   # fallback\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6658151b-55f9-49df-b3ac-1b4d2634136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using python: /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/bin/python\n",
      "\n",
      "$ /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/bin/python -m pip uninstall -y peft transformers accelerate\n",
      "Found existing installation: peft 0.13.2\n",
      "Uninstalling peft-0.13.2:\n",
      "  Successfully uninstalled peft-0.13.2\n",
      "Found existing installation: transformers 4.43.3\n",
      "Uninstalling transformers-4.43.3:\n",
      "  Successfully uninstalled transformers-4.43.3\n",
      "Found existing installation: accelerate 0.33.0\n",
      "Uninstalling accelerate-0.33.0:\n",
      "  Successfully uninstalled accelerate-0.33.0\n",
      "\n",
      "$ /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/bin/python -m pip install transformers==4.43.3 peft==0.13.2 accelerate==0.33.0 datasets>=2.19 evaluate>=0.4 scikit-learn matplotlib torch\n",
      "Collecting transformers==4.43.3\n",
      "  Using cached transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting peft==0.13.2\n",
      "  Using cached peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting accelerate==0.33.0\n",
      "  Using cached accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: datasets>=2.19 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: evaluate>=0.4 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: torch in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (2022.10.31)\n",
      "Requirement already satisfied: requests in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from transformers==4.43.3) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from peft==0.13.2) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (1.1.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from datasets>=2.19) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from datasets>=2.19) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from datasets>=2.19) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from datasets>=2.19) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from datasets>=2.19) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (0.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from requests->transformers==4.43.3) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from requests->transformers==4.43.3) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from requests->transformers==4.43.3) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from pandas->datasets>=2.19) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages (from pandas->datasets>=2.19) (2025.2)\n",
      "Using cached transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "Using cached peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Using cached accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "Installing collected packages: accelerate, transformers, peft\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [peft][32m1/3\u001b[0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-0.33.0 peft-0.13.2 transformers-4.43.3\n",
      "\n",
      "[Done] ✅ Please restart your Python kernel/terminal if in Jupyter.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. Simple script to install exact versions that work well\n",
    "#    with Prefix-Tuning.\n",
    "# -----------------------------------------------------------\n",
    "import sys, subprocess\n",
    "\n",
    "py = sys.executable\n",
    "print(\"Using python:\", py)\n",
    "\n",
    "def run(cmd):\n",
    "    \"\"\"Run a shell command and print it (super simple).\"\"\"\n",
    "    print(\"\\n$\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# Step 1: uninstall old versions (safe cleanup)\n",
    "run([py, \"-m\", \"pip\", \"uninstall\", \"-y\",\n",
    "     \"peft\", \"transformers\", \"accelerate\"])\n",
    "\n",
    "# Step 2: install a known-good combo\n",
    "run([py, \"-m\", \"pip\", \"install\",\n",
    "     \"transformers==4.43.3\",\n",
    "     \"peft==0.13.2\",\n",
    "     \"accelerate==0.33.0\",\n",
    "     \"datasets>=2.19\",\n",
    "     \"evaluate>=0.4\",\n",
    "     \"scikit-learn\",\n",
    "     \"matplotlib\",\n",
    "     \"torch\"])  # torch will auto-select build (CPU/CUDA/MPS)\n",
    "\n",
    "print(\"\\n[Done] ✅ Please restart your Python kernel/terminal if in Jupyter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36cba12c-1b6c-4960-a029-ccf00e0d1de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python exe: /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/bin/python\n",
      "transformers: 4.43.3 | file: /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/transformers/__init__.py\n",
      "peft: 0.13.2 | file: /Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/peft/__init__.py\n",
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib, transformers, peft, torch\n",
    "print(\"python exe:\", sys.executable)\n",
    "print(\"transformers:\", transformers.__version__, \"| file:\", importlib.import_module(\"transformers\").__file__)\n",
    "print(\"peft:\", peft.__version__, \"| file:\", importlib.import_module(\"peft\").__file__)\n",
    "print(\"device:\", \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca353c7c-ca8a-4c99-830c-dabccf496d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Imports =====\n",
    "import torch, transformers, peft, random, numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "# ===== Seed & Device =====\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c95b944-a2dc-4c2a-ab47-abe558a498dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14084444-5903-48e2-8962-0a9fd686b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Dataset & Model =====\n",
    "MODEL = \"t5-small\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00a87c5-3e22-42f4-bcd5-1483c5c8814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since PolyAI/banking77 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/jessicahong/.cache/huggingface/datasets/PolyAI___banking77/default/1.1.0/17ffc2ed47c2ed928bee64127ff1dbc97204cb974c2f980becae7c864007aed9 (last modified on Sat Aug 30 22:48:44 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: 77 | train/test: 10003 / 3080\n"
     ]
    }
   ],
   "source": [
    "# 1) Dataset\n",
    "ds = load_dataset(\"PolyAI/banking77\")\n",
    "label_names = ds[\"train\"].features[\"label\"].names\n",
    "print(\"labels:\", len(label_names), \"| train/test:\", len(ds[\"train\"]), \"/\", len(ds[\"test\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c89c574f-6049-46ff-b603-b3b22ab78147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Tokenizer / Model\n",
    "tok  = AutoTokenizer.from_pretrained(MODEL)\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(MODEL)  # fp32 권장 (mps)\n",
    "base.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c66689-ab6a-42c9-86ad-9128915ffa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3 — Prefix-Tuning wrapping =====\n",
    "from peft import PrefixTuningConfig, get_peft_model, TaskType\n",
    "\n",
    "peft_cfg = PrefixTuningConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,  # T5 models are Seq2Seq\n",
    "    num_virtual_tokens=16,            # recommended to start with 8–16\n",
    ")\n",
    "\n",
    "model = get_peft_model(base, peft_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b7759a-a87e-492c-b025-3c2d7612e7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 98,304 || all params: 60,604,928 || trainable%: 0.1622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PrefixEncoder(\n",
       "      (embedding): Embedding(16, 6144)\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(32128, 512)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which parameters are trainable\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Move the model to device (MPS / CUDA / CPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c6837db0-b3fa-4530-b438-40309a60632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 4 — Preprocess & tokenize for T5 (Banking77) =====\n",
    "# This function turns raw Banking77 examples into T5-friendly inputs/targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ac8bda-ed3d-4503-b0f4-d0ad99887f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "#   * T5 is a text-to-text model => we feed a short instruction (\"classify intent:\")\n",
    "#     plus the sentence, and ask it to generate the label name as text.\n",
    "#   * We use `text_target=...` which is the correct way to tokenize targets for\n",
    "#     seq2seq models in recent Transformers versions.\n",
    "#   * We set only `truncation=True` here (no padding yet); padding will be handled\n",
    "#     by a DataCollator at DataLoader time (dynamic per-batch padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d3e17bb-c113-47e3-9f2c-48cd8713a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def preprocess(batch):\n",
    "    # 1) Build the *source* strings with a simple instruction prefix\n",
    "    inputs  = [f\"classify intent: {t}\" for t in batch[\"text\"]]\n",
    "\n",
    "    # 2) Convert numeric labels -> label names (strings), which T5 can generate\n",
    "    targets = [label_names[i] for i in batch[\"label\"]]\n",
    "\n",
    "    # 3) Tokenize sources (encoder side)\n",
    "    enc_in = tok(inputs, truncation=True)\n",
    "\n",
    "    # 4) Tokenize targets (decoder side)\n",
    "    #    Using `text_target` ensures special handling of labels for seq2seq.\n",
    "    lab = tok(text_target=targets, truncation=True)\n",
    "\n",
    "    # 5) Attach tokenized targets as \"labels\" (what the model should generate)\n",
    "    enc_in[\"labels\"] = lab[\"input_ids\"]\n",
    "    return enc_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65c6596a-cd76-4512-a768-84c4e6c0c6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3ad12d88ac46c587495fbe8411c8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a23dd65d41420ab73d2defe3c88935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply preprocessing to the whole dataset (batched for speed).\n",
    "# We drop the original \"text\" and \"label\" columns because we've converted them.\n",
    "ds_tok = ds.map(preprocess, batched=True, remove_columns=[\"text\", \"label\"])\n",
    "\n",
    "# Make the dataset return PyTorch tensors for each example.\n",
    "# (Each example can have variable-length tensors; batching will pad later.)\n",
    "ds_tok.set_format(type=\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24985fe0-a232-4f19-9c08-bc7ce00f19ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized columns: {'input_ids': List(Value('int32')), 'attention_mask': List(Value('int8')), 'labels': List(Value('int64'))}\n",
      "Train/Test sizes: 10003 / 3080\n"
     ]
    }
   ],
   "source": [
    "#Quick check\n",
    "print(\"Tokenized columns:\", ds_tok[\"train\"].features)\n",
    "print(\"Train/Test sizes:\", len(ds_tok[\"train\"]), \"/\", len(ds_tok[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cca204ef-4198-4c0e-8101-f72ca617eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5 — DataLoader with padding and label masking ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e397c15b-9839-4c18-a91f-05592d20f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   1) Pads \"input_ids\" and \"attention_mask\" dynamically per batch.\n",
    "#   2) Pads \"labels\" (decoder targets) dynamically as well.\n",
    "#   3) Replaces all PAD tokens in labels with -100.\n",
    "#        → -100 is the default ignore index for loss computation in PyTorch,\n",
    "#          so the model will NOT be penalized for predicting PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26c8ce84-f055-4207-87a8-b717dd439a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(features):\n",
    "    # Separate encoder inputs (input_ids, attention_mask)\n",
    "    ins = [\n",
    "        {\"input_ids\": f[\"input_ids\"], \"attention_mask\": f[\"attention_mask\"]}\n",
    "        for f in features\n",
    "    ]\n",
    "    # Separate decoder labels\n",
    "    labs = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "\n",
    "    # Pad encoder inputs → returns dict with input_ids + attention_mask\n",
    "    batch = tok.pad(ins, return_tensors=\"pt\")\n",
    "\n",
    "    # Pad decoder labels\n",
    "    lab = tok.pad(labs, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    # Replace PAD token ids with -100 (ignored in loss calculation)\n",
    "    lab[lab == tok.pad_token_id] = -100\n",
    "    batch[\"labels\"] = lab\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b30c6592-3d22-48c0-8d32-e965c92f7cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in batch: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "input_ids shape: torch.Size([3, 23])\n",
      "attention_mask shape: torch.Size([3, 23])\n",
      "labels shape: torch.Size([3, 5])\n",
      "labels (first row): tensor([  895,   834,   291, 25295,     1])\n"
     ]
    }
   ],
   "source": [
    "# ===== Quick sanity check for collate_fn =====\n",
    "sample_batch = [ds_tok[\"train\"][i] for i in range(3)]  # take 3 examples\n",
    "collated = collate_fn(sample_batch)\n",
    "\n",
    "print(\"Keys in batch:\", collated.keys())\n",
    "print(\"input_ids shape:\", collated[\"input_ids\"].shape)\n",
    "print(\"attention_mask shape:\", collated[\"attention_mask\"].shape)\n",
    "print(\"labels shape:\", collated[\"labels\"].shape)\n",
    "\n",
    "# Check that PAD tokens in labels are replaced by -100\n",
    "print(\"labels (first row):\", collated[\"labels\"][0][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "543a935c-f5f3-4188-9787-caad0be8bcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 626 | test batches: 193\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# * batch_size = 16 (small and safe for most setups)\n",
    "# * train_dl uses shuffle=True for stochasticity\n",
    "# * test_dl uses shuffle=False for deterministic evaluation\n",
    "# -----------------------------------------------------------------------------\n",
    "train_dl = DataLoader(\n",
    "    ds_tok[\"train\"], batch_size=16, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    ds_tok[\"test\"], batch_size=16, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Quick check: how many batches in each split?\n",
    "print(\"train batches:\", len(train_dl), \"| test batches:\", len(test_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f9a28f3-97c8-44b4-a6c0-0795b1adb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 6 — Sanity check (single forward pass with loss) =====\n",
    "# We already have:\n",
    "#   - Prefix-wrapped model: `model`\n",
    "#   - DataLoader: `train_dl`\n",
    "#   - Selected device in `device` and model moved to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f1a9a03-eab5-4002-92aa-74586c5f3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()  # enable training mode (dropout etc.)\n",
    "batch = next(iter(train_dl))  # take a single batch\n",
    "\n",
    "# Move tensors to the selected device (MPS / CUDA / CPU)\n",
    "batch = {k: v.to(device) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d89bf568-f83b-4d80-a29e-1e1ed433fc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity loss: 6.557995796203613\n",
      "logits shape: (16, 21, 32128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/xtl4b0cx1cs9zrr9n5y814_h0000gn/T/ipykernel_80632/3054933449.py:8: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(\"sanity loss:\", float(out.loss))  # if you see a finite number, you're good!\n"
     ]
    }
   ],
   "source": [
    "#NOTE:\n",
    "# - On MPS, autocast is limited; on CPU it’s different; to avoid dtype surprises,\n",
    "#   we simply DISABLE autocast here for the sanity check.\n",
    "# - If you're on CUDA and want speed later, enable autocast only for CUDA.\n",
    "with torch.autocast(device_type=(\"cpu\" if device == \"cpu\" else device), enabled=False):\n",
    "    out = model(**batch)  # forward pass computes loss because batch has `labels`\n",
    "\n",
    "print(\"sanity loss:\", float(out.loss))  # if you see a finite number, you're good!\n",
    "print(\"logits shape:\", tuple(out.logits.shape))  # optional: (B, T, vocab_size) for T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ca92104-6647-43d8-9400-4fef3335df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 7 — Training preparation (optimizer & hyperparameters) =====\n",
    "import torch\n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26fabcdc-5095-42da-9be8-b18483b6f265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 98304\n"
     ]
    }
   ],
   "source": [
    "# Collect only the parameters that require gradients\n",
    "# ---------------------------------------------------------------------------\n",
    "# In Prefix-Tuning, the base model is frozen and only the prefix parameters\n",
    "# are trainable. So we filter with `requires_grad=True`.\n",
    "# ---------------------------------------------------------------------------\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(\"trainable params:\", sum(p.numel() for p in trainable_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a3668b5-cf0a-4790-a673-b5e8562700af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54fa6adb-ae88-4e37-8a53-7e8f55d8a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# AdamW is a common choice for transformer fine-tuning.\n",
    "# Learning rate here is set to 5e-4 (safe starting point).\n",
    "# ---------------------------------------------------------------------------\n",
    "optim = torch.optim.AdamW(trainable_params, lr=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c609a97-4c40-456d-8267-6bc361a950cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad586153-4c41-4d3b-b823-702df1a61448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PrefixEncoder(\n",
       "      (embedding): Embedding(16, 6144)\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(32128, 512)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "epochs = 2       # run 2 epochs first (reduce to 1 for a very quick test)\n",
    "log_every = 100  # log the average loss every 100 steps\n",
    "grad_clip = 1.0  # clip gradients at 1.0 to prevent exploding gradients\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Set model to training mode\n",
    "# (important for dropout, layer norm, etc. to behave correctly)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50ee6108-85b4-4170-87eb-4700957cc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 8 — Training loop ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e8dea17-e6a8-43de-92fa-6d6da013b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] start\n"
     ]
    }
   ],
   "source": [
    "# Assumes:\n",
    "#   - `model`, `device` already set\n",
    "#   - `train_dl` is a DataLoader yielding batches with input_ids/attention_mask/labels\n",
    "#   - `optim`, `epochs`, `log_every`, `grad_clip` defined in the previous cellimport math\n",
    "from statistics import mean\n",
    "\n",
    "global_step = 0\n",
    "print(\"[Train] start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68dc92d5-7d89-48ae-8b5c-15d86ed71b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ep 1] step 100/626  loss 4.4890\n",
      "[ep 1] step 200/626  loss 4.3414\n",
      "[ep 1] step 300/626  loss 4.1939\n",
      "[ep 1] step 400/626  loss 4.0593\n",
      "[ep 1] step 500/626  loss 3.9101\n",
      "[ep 1] step 600/626  loss 3.8191\n",
      "[ep 1] epoch_avg_loss 4.1214\n",
      "[ep 2] step 100/626  loss 3.6778\n",
      "[ep 2] step 200/626  loss 3.6308\n",
      "[ep 2] step 300/626  loss 3.5387\n",
      "[ep 2] step 400/626  loss 3.4567\n",
      "[ep 2] step 500/626  loss 3.4296\n",
      "[ep 2] step 600/626  loss 3.3384\n",
      "[ep 2] epoch_avg_loss 3.5064\n",
      "[Train] done\n"
     ]
    }
   ],
   "source": [
    "for ep in range(1, epochs + 1):\n",
    "    running_losses = []  # keep per-step losses to compute averages\n",
    "    for step, batch in enumerate(train_dl, start=1):\n",
    "        # 1) Move tensors to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # 2) Forward pass (we keep it simple: no mixed precision to avoid surprises)\n",
    "        out = model(**batch)\n",
    "        loss = out.loss\n",
    "\n",
    "        # 3) Backward pass\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # 4) (Optional) Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n",
    "\n",
    "        # 5) Optimizer step\n",
    "        optim.step()\n",
    "\n",
    "        # 6) Logging\n",
    "        running_losses.append(loss.item())\n",
    "        global_step += 1\n",
    "        if step % log_every == 0:\n",
    "            avg = mean(running_losses[-log_every:])  # average over recent window\n",
    "            print(f\"[ep {ep}] step {step}/{len(train_dl)}  loss {avg:.4f}\")\n",
    "\n",
    "    # End of epoch summary\n",
    "    epoch_avg = mean(running_losses) if running_losses else math.nan\n",
    "    print(f\"[ep {ep}] epoch_avg_loss {epoch_avg:.4f}\")\n",
    "\n",
    "print(\"[Train] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b95b313-b6bd-4710-b463-97988102da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model.eval()\n",
    "gen_preds, gen_labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75c78524-6ec8-483e-aaf1-a59ba13cedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_dl:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attn_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        # generate short label strings\n",
    "        gen_out = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            max_new_tokens=6,          # labels are short\n",
    "            num_beams=1,               # greedy is fine\n",
    "        )\n",
    "        # decode predictions\n",
    "        gen_texts = tok.batch_decode(gen_out, skip_special_tokens=True)\n",
    "        gen_preds.extend(gen_texts)\n",
    "\n",
    "        # prepare gold labels (undo -100 -> pad)\n",
    "        gold = batch[\"labels\"].clone()\n",
    "        gold[gold == -100] = tok.pad_token_id\n",
    "        gold_texts = tok.batch_decode(gold, skip_special_tokens=True)\n",
    "        gen_labels.extend(gold_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc92ca33-2779-4cc0-9425-aeff6a39852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval:generate] accuracy=0.0006  macro_F1=0.0001\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(gen_labels, gen_preds)\n",
    "f1  = f1_score(gen_labels, gen_preds, average=\"macro\")\n",
    "print(f\"[Eval:generate] accuracy={acc:.4f}  macro_F1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3adeb7ed-e13a-48bb-b7b6-e1cc2f327081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] accuracy=0.0003  macro_F1=0.0000\n",
      "\n",
      "Sample predictions:\n",
      "Text : How do I locate my card?\n",
      "True : 'card_arrival'\n",
      "Pred : '_card_'\n",
      "---\n",
      "Text : I still have not received my new card, I ordered over a week ago.\n",
      "True : 'card_arrival'\n",
      "Pred : 'new_card_'\n",
      "---\n",
      "Text : I ordered a card but it has not arrived. Help please!\n",
      "True : 'card_arrival'\n",
      "Pred : 'card_rebitled'\n",
      "---\n",
      "Text : Is there a way to know when my card will arrive?\n",
      "True : 'card_arrival'\n",
      "Pred : 'card_cardbitled'\n",
      "---\n",
      "Text : My card has not arrived yet.\n",
      "True : 'card_arrival'\n",
      "Pred : 'card_card_'\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "/Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "/Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "/Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "/Users/jessicahong/.pyenv/versions/3.10.12/envs/nlp_env/lib/python3.10/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 9 (fixed) — Evaluation with proper label decoding =====\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dl:\n",
    "        # move to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        out = model(**batch)  # teacher forcing logits\n",
    "\n",
    "        # token-level argmax (simple baseline)\n",
    "        preds = torch.argmax(out.logits, dim=-1)              # [B, T_dec]\n",
    "        labels = batch[\"labels\"].clone()                      # [B, T_dec]\n",
    "        labels[labels == -100] = tok.pad_token_id             # 🔧 undo ignore index\n",
    "\n",
    "        # collect as python lists\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "# decode to strings (now all IDs are non-negative)\n",
    "decoded_preds  = tok.batch_decode(all_preds,  skip_special_tokens=True)\n",
    "decoded_labels = tok.batch_decode(all_labels, skip_special_tokens=True)\n",
    "\n",
    "# compute metrics (label strings vs predicted strings)\n",
    "acc = accuracy_score(decoded_labels, decoded_preds)\n",
    "f1  = f1_score(decoded_labels, decoded_preds, average=\"macro\")\n",
    "\n",
    "print(f\"[Eval] accuracy={acc:.4f}  macro_F1={f1:.4f}\")\n",
    "\n",
    "# show a few qualitative samples\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"Text : {ds['test'][i]['text']}\")\n",
    "    print(f\"True : {decoded_labels[i]!r}\")\n",
    "    print(f\"Pred : {decoded_preds[i]!r}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335a94a-59c4-4472-aaf1-5b6575bceeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
